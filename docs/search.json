[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\n            Public Economics: Taxation\n        ",
    "section": "",
    "text": "The Economics of Taxation\n        \n        \n            EC313 • Fall 2025Department of EconomicsLazaridis School of Business and EconomicsWilfrid Laurier University\n        \n    \n    \n      \n        \n        \n        \n      \n    \n\n\n\n\n\n\nInstructor\n\n   Prof. Justin Smith\n   Lazaridis Hall 3091\n   jusmith@wlu.ca\n\n\n\nCourse details\n\n   Tue/Thu\n   Sept-Dec 2025\n   4:00 - 5:20 PM\n   LH2066\n\n\n\nOffice Hours\n\n   Thur 12:30 PM - 2:30 PM\n   Schedule an appointment"
  },
  {
    "objectID": "content/index.html",
    "href": "content/index.html",
    "title": "Summary",
    "section": "",
    "text": "Here you will find lecture notes, recommended readings, and other useful materials for each section of the course. Use the sidebar to navigate to the appropriate section. You can go through the lecture slides directly on the page, or pop them out to a separate page. Please review each section before the lecture to familiarize yourself with the material.",
    "crumbs": [
      "Content",
      "Overview",
      "Summary"
    ]
  },
  {
    "objectID": "content/matrixrev.html#slides",
    "href": "content/matrixrev.html#slides",
    "title": "Matrix Algebra Review",
    "section": "Slides",
    "text": "Slides\nThe slides are embedded in this page, and you can scroll through them with the arrow keys. If you prefer you can instead pop them out in a new window"
  },
  {
    "objectID": "slides/index.html#introduction-1",
    "href": "slides/index.html#introduction-1",
    "title": "Matrix Review",
    "section": "Introduction",
    "text": "Introduction\n\nUndergrad metrics normally uses scalar notation\n\nMore accessible for students without advanced math background\n\nAt the graduate level, it is often taught using matrix algebra\nSome advantages to matrix notation\n\nMore compact\nEasier to express some estimators\n\nIn this section, we review matrix algebra essentials for econometrics\n\nNot a comprehensive review\n\nWe will switch between scalar and matrix notation in the course\n\nDepending on which is clearer in each context"
  },
  {
    "objectID": "slides/index.html#matrix",
    "href": "slides/index.html#matrix",
    "title": "Matrix Review",
    "section": "Matrix",
    "text": "Matrix\n\nA matrix is a rectangular array of numbers organized in rows and columns\nFor example, matrix \\(\\mathbf{A}\\) with 2 rows and 3 columns could be\n\n\\[\\mathbf{A} =\n\\begin{bmatrix}\n1 & 2  & 3 \\\\\n4 &5 & 6\n\\end{bmatrix}\\]\n\nMore generally, matrix \\(\\mathbf{A}\\) with m rows and n columns is\n\n\\[\\mathbf{A}=\n\\begin{bmatrix}\na_{11}& a_{12} &\\cdots & a_{1n} \\\\\na_{21}& a_{22} &\\cdots & a_{2n} \\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\na_{m1}& a_{m2} &\\cdots & a_{mn}\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/index.html#vectors",
    "href": "slides/index.html#vectors",
    "title": "Matrix Review",
    "section": "Vectors",
    "text": "Vectors\n\nA vector is a matrix with one column or one row\nA row vector \\(\\mathbf{a}\\) with n elements is\n\n\\[\\mathbf{a}=\n\\begin{bmatrix}\na_{1}& a_{2} &\\cdots & a_{n}\n\\end{bmatrix}\\]\n\nA .red[column vector] \\(\\mathbf{a}\\) with m elements is\n\n\\[\\mathbf{a}=\n\\begin{bmatrix}\na_{1}\\\\\na_{2}\\\\\n\\vdots \\\\\na_{m}\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/index.html#special-matrices",
    "href": "slides/index.html#special-matrices",
    "title": "Matrix Review",
    "section": "Special Matrices",
    "text": "Special Matrices\n\nA Square Matrix has the same number of rows and columns\n\n\\[\\mathbf{A}=\n\\begin{bmatrix}\na_{11}& a_{12} &\\cdots & a_{1m} \\\\\na_{21}& a_{22} &\\cdots & a_{2m} \\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\na_{m1}& a_{m2} &\\cdots & a_{mm}\n\\end{bmatrix}\\]\n\nA Diagonal Matrix is a square matrix with zeroes for all off-diagonal elements\n\n\\[\\mathbf{A}=\n\\begin{bmatrix}\na_{11}& 0&\\cdots & 0 \\\\\n0& a_{22} &\\cdots & 0 \\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\n0& 0&\\cdots & a_{mm}\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/index.html#special-matrices-1",
    "href": "slides/index.html#special-matrices-1",
    "title": "Matrix Review",
    "section": "Special Matrices",
    "text": "Special Matrices\n\nThe Identity Matrix is a square matrix with ones on the diagonal and zeroes on the off-diagonals\n\n\\[\\mathbf{I}=\n\\begin{bmatrix}\n1& 0&\\cdots & 0 \\\\\n0& 1 &\\cdots & 0 \\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\n0& 0&\\cdots & 1\n\\end{bmatrix}\\]\n\nThe Zero Matrix is a matrix with zeroes for all elements\n\n\\[\\mathbf{0}=\n\\begin{bmatrix}\n0& 0&\\cdots & 0 \\\\\n0& 0 &\\cdots & 0 \\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\n0& 0&\\cdots & 0\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/index.html#matrix-addition",
    "href": "slides/index.html#matrix-addition",
    "title": "Matrix Review",
    "section": "Matrix Addition",
    "text": "Matrix Addition\n\nYou can add and subtract matrices with the same dimensions\n\nMatrices with different dimensions are not conformable for addition or subtraction\n\nThe sum of matrices \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\) with dimension \\(m \\times n\\) is\n\n\\[\\mathbf{A} + \\mathbf{B}=\n\\begin{bmatrix}\na_{11}& a_{12} &\\cdots & a_{1n} \\\\\na_{21}& a_{22} &\\cdots & a_{2n} \\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\na_{m1}& a_{m2} &\\cdots & a_{mn}\n\\end{bmatrix}\n+\n\\begin{bmatrix}\nb_{11}& b_{12} &\\cdots & b_{1n} \\\\\nb_{21}& b_{22} &\\cdots & b_{2n} \\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\nb_{m1}& b_{m2} &\\cdots & b_{mn}\n\\end{bmatrix}\\]\n\\[=\n\\begin{bmatrix}\na_{11} + b_{11}& a_{12} + b_{12} &\\cdots & a_{1n}+ b_{1n} \\\\\na_{21} + b_{21}& a_{22} + b_{22} &\\cdots & a_{2n}+ b_{2n} \\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\na_{m1} + b_{m1}& a_{m2} +b_{m2} &\\cdots & a_{mn}+ b_{mn} \\\\\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/index.html#matrix-subtraction",
    "href": "slides/index.html#matrix-subtraction",
    "title": "Matrix Review",
    "section": "Matrix Subtraction",
    "text": "Matrix Subtraction\n\nSimilarly, the difference between matrices \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\) is\n\n\\[\\mathbf{A} - \\mathbf{B}=\n\\begin{bmatrix}\na_{11}& a_{12} &\\cdots & a_{1n} \\\\\na_{21}& a_{22} &\\cdots & a_{2n} \\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\na_{m1}& a_{m2} &\\cdots & a_{mn}\n\\end{bmatrix}\n-\n\\begin{bmatrix}\nb_{11}& b_{12} &\\cdots & b_{1n} \\\\\nb_{21}& b_{22} &\\cdots & b_{2n} \\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\nb_{m1}& b_{m2} &\\cdots & b_{mn}\n\\end{bmatrix}\\]\n\\[=\n\\begin{bmatrix}\na_{11} - b_{11}& a_{12} - b_{12} &\\cdots & a_{1n}- b_{1n} \\\\\na_{21} - b_{21}& a_{22} - b_{22} &\\cdots & a_{2n}- b_{2n} \\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\na_{m1} - b_{m1}& a_{m2} -b_{m2} &\\cdots & a_{mn}- b_{mn} \\\\\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/index.html#rules-for-addition-and-subtraction",
    "href": "slides/index.html#rules-for-addition-and-subtraction",
    "title": "Matrix Review",
    "section": "Rules for Addition and Subtraction",
    "text": "Rules for Addition and Subtraction\n\nThe following rules apply to matrix addition and subtraction\n\nCommutativity \\[\\mathbf{A + B = B + A}\\]\nAssociativity \\[\\mathbf{A + (B + C) = (A+B) + C}\\]\n\nEffectively, both rules mean order does not matter\n\nSimilar to scalar math\n\nFor subtraction, replace plus sign with minus sign and same rules apply"
  },
  {
    "objectID": "slides/index.html#matrix-multiplication",
    "href": "slides/index.html#matrix-multiplication",
    "title": "Matrix Review",
    "section": "Matrix Multiplication",
    "text": "Matrix Multiplication\n\nTo multiply matrix \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\), the number of columns in \\(\\mathbf{A}\\) must equal the number of rows in \\(\\mathbf{B}\\)\nSuppose matrix \\(\\mathbf{A}\\) is \\(m \\times n\\) and matrix \\(\\mathbf{B}\\) is \\(n \\times p\\)\nDefine product as \\(\\mathbf{C}\\)= \\(\\mathbf{AB}\\)\n\nThe \\(ij\\) element of \\(\\mathbf{C}\\) is the sum of the product of the corresponding elements along the \\(i\\)th row of \\(\\mathbf{A}\\) and \\(j\\)th column of \\(\\mathbf{B}\\)\n\\[c_{ij} = \\sum_{k} a_{ik}b_{kj}\\]\nThe product matrix \\(\\mathbf{C}\\) will have dimension \\(m \\times p\\)\n\nThe number of rows of \\(\\textbf{A}\\) and number of columns of \\(\\textbf{B}\\)"
  },
  {
    "objectID": "slides/index.html#matrix-multiplication-1",
    "href": "slides/index.html#matrix-multiplication-1",
    "title": "Matrix Review",
    "section": "Matrix Multiplication",
    "text": "Matrix Multiplication\n\nThe product \\(\\mathbf{AB}\\) is\n\n\\[\\mathbf{AB}=\n    \\begin{bmatrix}\n    a_{11}& a_{12} &\\cdots & a_{1n} \\\\\n    a_{21}& a_{22} &\\cdots & a_{2n} \\\\\n    \\vdots & \\vdots &\\ddots & \\vdots \\\\\n    a_{m1}& a_{m2} &\\cdots & a_{mn}\n    \\end{bmatrix}\n    \\times\n    \\begin{bmatrix}\n    b_{11}& b_{12} &\\cdots & b_{1p} \\\\\n    b_{21}& b_{22} &\\cdots & b_{2p} \\\\\n    \\vdots & \\vdots &\\ddots & \\vdots \\\\\n    b_{n1}& b_{n2} &\\cdots & b_{np}\n    \\end{bmatrix}\\]\n\n\\[=\n\\begin{bmatrix}\na_{11} b_{11} + a_{12} b_{21}  + \\cdots + a_{1n} b_{n1}  &a_{11} b_{12} + a_{12} b_{22}  + \\cdots + a_{1n} b_{n2} &\\cdots&a_{11} b_{1p} + a_{12} b_{2p}  + \\cdots + a_{1n} b_{np}\\\\\na_{21} b_{11} + a_{22} b_{21}  + \\cdots + a_{2n} b_{n1}  &a_{21} b_{12} + a_{22} b_{22}  + \\cdots + a_{2n} b_{n2} &\\cdots&a_{21} b_{1p} + a_{22} b_{2p}  + \\cdots + a_{2n} b_{np}\\\\\n\\vdots &\\ddots & \\vdots \\\\\na_{m1} b_{11} + a_{m2} b_{21}  + \\cdots + a_{mn} b_{n1}  &a_{m1} b_{12} + a_{m2} b_{22}  + \\cdots + a_{mn} b_{n2} &\\cdots&a_{m1} b_{1p} + a_{m2} b_{2p}  + \\cdots + a_{mn} b_{np}\\\\\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/index.html#matrix-multiplication-2",
    "href": "slides/index.html#matrix-multiplication-2",
    "title": "Matrix Review",
    "section": "Matrix Multiplication",
    "text": "Matrix Multiplication\n\nAs an illustration suppose we have the following matrices \\[\\mathbf{A}=\n\\begin{bmatrix}\n1& 2\\\\\n3& 4 \\\\\n\\end{bmatrix}\n\\mathbf{B}=\n\\begin{bmatrix}\n5&6&7  \\\\\n8&9 &10\n\\end{bmatrix}\\]\nWe can multiply \\(\\mathbf{AB}\\) because \\(\\mathbf{A}\\) has 2 columns, and \\(\\mathbf{B}\\) has 2 rows\nThe product \\(\\mathbf{C}\\) = \\(\\mathbf{AB}\\) is\n\n\\[\\mathbf{C}=\n\\begin{bmatrix}\n1& 2\\\\\n3& 4 \\\\\n\\end{bmatrix}\n\\times\n\\begin{bmatrix}\n5&6&7  \\\\\n8&9 &10\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n1 \\times 5 + 2\\times 8&1 \\times 6 + 2 \\times 9 & 1 \\times 7 + 2 \\times 10  \\\\\n3 \\times 5 + 4\\times 8&3 \\times 6 + 4 \\times 9 & 3 \\times 7 + 4 \\times 10  \n\\end{bmatrix}\\]\n\\[=\n\\begin{bmatrix}\n21& 24& 27 \\\\\n47&54&  61\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/index.html#scalar-multiplication",
    "href": "slides/index.html#scalar-multiplication",
    "title": "Matrix Review",
    "section": "Scalar Multiplication",
    "text": "Scalar Multiplication\n\nA scalar is a single real number\nYou can also multiply a scalar by a matrix\nIf \\(\\gamma\\) is a scalar, and \\(\\mathbf{A}\\) is a matrix, then\n\n\\[\\mathbf{\\gamma A}= \\gamma\n\\begin{bmatrix}\na_{11}& a_{12} &\\cdots & a_{1n} \\\\\na_{21}& a_{22} &\\cdots & a_{2n} \\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\na_{m1}& a_{m2} &\\cdots & a_{mn}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\gamma a_{11}&\\gamma  a_{12} &\\cdots & \\gamma a_{1n} \\\\\n\\gamma a_{21}& \\gamma a_{22} &\\cdots & \\gamma a_{2n} \\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\n\\gamma a_{m1}& \\gamma a_{m2} &\\cdots & \\gamma a_{mn}\n\\end{bmatrix}\\]\n\nYou multiply the scalar by each element of the matrix"
  },
  {
    "objectID": "slides/index.html#transpose",
    "href": "slides/index.html#transpose",
    "title": "Matrix Review",
    "section": "Transpose",
    "text": "Transpose\n\nThe transpose of a matrix is one where the rows and columns are switched\nSuppose matrix \\(\\mathbf{A}\\) is\n\n\\[\\mathbf{A}=\n    \\begin{bmatrix}\n    a_{11}& a_{12} &\\cdots & a_{1n} \\\\\n    a_{21}& a_{22} &\\cdots & a_{2n} \\\\\n    \\vdots & \\vdots &\\ddots & \\vdots \\\\\n    a_{m1}& a_{m2} &\\cdots & a_{mn}\n    \\end{bmatrix}\\]\n\nThen its transpose \\(\\mathbf{A'}\\) is\n\n\\[\\mathbf{A'}=\n\\begin{bmatrix}\na_{11}& a_{21} &\\cdots & a_{m1} \\\\\na_{12}& a_{22} &\\cdots & a_{m2} \\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\na_{1n}& a_{2n} &\\cdots & a_{mn}\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/index.html#transpose-1",
    "href": "slides/index.html#transpose-1",
    "title": "Matrix Review",
    "section": "Transpose",
    "text": "Transpose\n\nThe transpose has the following properties\n\n\\[\\mathbf{(A')' = A }\\] \\[\\mathbf{(\\alpha A)' = \\alpha A' }\\] \\[\\mathbf{(A + B)' = A' + B' }\\] \\[\\mathbf{(AB)' = B'A' }\\]\n\nThere are additional rules for different types of matrices that we will cover below"
  },
  {
    "objectID": "slides/index.html#partitioned-matrix-multiplication",
    "href": "slides/index.html#partitioned-matrix-multiplication",
    "title": "Matrix Review",
    "section": "Partitioned Matrix Multiplication",
    "text": "Partitioned Matrix Multiplication\n\nYou may sometimes want to break matrices into vectors before you multiply\nMultiplication works the same way, but notation can be cleaner and more intuitive\nSuppose we have the following matrices \\[\\mathbf{A}=\n\\begin{bmatrix}\na_{11}& a_{12} &\\cdots & a_{1n} \\\\\na_{21}& a_{22} &\\cdots & a_{2n} \\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\na_{m1}& a_{m2} &\\cdots & a_{mn}\n\\end{bmatrix}\n\\mathbf{B}=\n\\begin{bmatrix}\nb_{11}& b_{12} &\\cdots & b_{1p} \\\\\nb_{21}& b_{22} &\\cdots & b_{2p} \\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\nb_{n1}& b_{n2} &\\cdots & b_{np}\n\\end{bmatrix}\\]\nWe are interested in the product \\(\\mathbf{AB}\\)"
  },
  {
    "objectID": "slides/index.html#partitioned-matrix-multiplication-1",
    "href": "slides/index.html#partitioned-matrix-multiplication-1",
    "title": "Matrix Review",
    "section": "Partitioned Matrix Multiplication",
    "text": "Partitioned Matrix Multiplication\n\nBreak these matrices into vectors conformable for multiplication\n\n\\[\\mathbf{A}=\n\\begin{bmatrix}\n\\mathbf{a_{1}}&\\mathbf{a_{2}} & \\cdots & \\mathbf{a_{n}}\n\\end{bmatrix}\n\\mathbf{B}=\n\\begin{bmatrix}\n\\mathbf{b_{1}}\\\\\n\\mathbf{b_{2} }\\\\\n\\vdots  \\\\\n\\mathbf{b_{n}}\n\\end{bmatrix}\\]\n\nWhere\n\n\\[\\mathbf{a_{1}}=\n\\begin{bmatrix}\na_{11}\\\\\na_{21}\\\\\n\\cdots\\\\\na_{m1}\n\\end{bmatrix}\n\\mathbf{b_{1}}=\n\\begin{bmatrix}\nb_{11}&b_{12} & \\cdots & b_{1p}\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/index.html#partitioned-matrix-multiplication-2",
    "href": "slides/index.html#partitioned-matrix-multiplication-2",
    "title": "Matrix Review",
    "section": "Partitioned Matrix Multiplication",
    "text": "Partitioned Matrix Multiplication\n\nMultiply the vectors to get\n\n\\[\\mathbf{AB} = \\sum_{i=1}^{n} \\mathbf{a_{i}b_{i}}\\]\n\nThis breaks the product \\(\\mathbf{AB}\\) into the sum of \\(n\\) sub-matrices\n\nEach sub-matrix is product of corresponding vectors\nAlso each sub-matrix will have dimension \\(m \\times p\\)\n\nThis will be useful for some econometric estimators we derive\n\nMakes notation simpler and more intuitive\n\nAgain, note that you get the same answer as doing straight matrix multiplication"
  },
  {
    "objectID": "slides/index.html#rules-for-matrix-multiplication",
    "href": "slides/index.html#rules-for-matrix-multiplication",
    "title": "Matrix Review",
    "section": "Rules for Matrix Multiplication",
    "text": "Rules for Matrix Multiplication\n\nThere are several useful properties for matrix (and scalar) multiplication\n\n\\[(\\alpha + \\beta)\\mathbf{A} = \\alpha \\mathbf{A} + \\beta\\mathbf{A}\\] \\[\\alpha (\\mathbf{A} +\\mathbf{B}) =\\alpha \\mathbf{A} +\\alpha\\mathbf{B}\\] \\[(\\alpha\\beta) \\mathbf{A}  =\\alpha(\\beta \\mathbf{A})\\] \\[\\alpha (\\mathbf{A}\\mathbf{B}) =(\\alpha \\mathbf{A}) \\mathbf{B}\\] \\[(\\mathbf{A}\\mathbf{B} )\\mathbf{C} =\\mathbf{A}(\\mathbf{B} \\mathbf{C})\\] \\[\\mathbf{A}(\\mathbf{B} +\\mathbf{C}) =\\mathbf{A}\\mathbf{B} +\\mathbf{A} \\mathbf{C}\\] \\[(\\mathbf{A}+\\mathbf{B} )\\mathbf{C} =\\mathbf{A}\\mathbf{C} +\\mathbf{B} \\mathbf{C}\\] \\[\\mathbf{A}\\mathbf{I}  =\\mathbf{I}\\mathbf{A} = \\mathbf{A}\\] \\[\\mathbf{A}\\mathbf{0}  =\\mathbf{0}\\mathbf{A} = \\mathbf{0}\\] \\[\\mathbf{A}\\mathbf{B}  \\neq\\mathbf{B}\\mathbf{A}\\] —"
  },
  {
    "objectID": "slides/index.html#trace",
    "href": "slides/index.html#trace",
    "title": "Matrix Review",
    "section": "Trace",
    "text": "Trace\n\nThe trace of a square matrix is the sum of the diagonal elements\nIf square matrix \\(\\mathbf{A}\\) is\n\n\\[\\mathbf{A}=\n    \\begin{bmatrix}\n    a_{11}& a_{12} &\\cdots & a_{1n} \\\\\n    a_{21}& a_{22} &\\cdots & a_{2n} \\\\\n    \\vdots & \\vdots &\\ddots & \\vdots \\\\\n    a_{n1}& a_{n2} &\\cdots & a_{nn}\n    \\end{bmatrix}\\]\n\nThen its trace is\n\n\\[tr(\\mathbf{A})= \\sum_{i=1}^{n} a_{ii}\\]"
  },
  {
    "objectID": "slides/index.html#trace-1",
    "href": "slides/index.html#trace-1",
    "title": "Matrix Review",
    "section": "Trace",
    "text": "Trace\n\nImportant properties of the trace are\n\n\\[tr(\\mathbf{I_{n}})= n\\] \\[tr(\\mathbf{A}')=tr(\\mathbf{A})\\] \\[tr(\\mathbf{A +B})=tr(\\mathbf{A}) + tr(\\mathbf{B})\\] \\[tr(\\alpha \\mathbf{A})=\\alpha tr(\\mathbf{A})\\] \\[tr(\\mathbf{AB})=tr(\\mathbf{BA})\\]"
  },
  {
    "objectID": "slides/index.html#marix-determinant",
    "href": "slides/index.html#marix-determinant",
    "title": "Matrix Review",
    "section": "Marix Determinant",
    "text": "Marix Determinant\n\nThe determinant is a scalar value associated with a square matrix\n\nHelpful concept for several things in matrix algebra\nFor econometrics, most useful for solving systems of equations and finding inverse of a matrix\n\nFor \\(2 \\times 2\\) matrix \\(\\mathbf{A}\\) \\[\\mathbf{A}=\n\\begin{bmatrix}\na_{11}& a_{12} \\\\\na_{21}& a_{22}  \\\\\n\\end{bmatrix}\\]\nThe determinant is\n\n\\[|\\mathbf{A}|=a_{11}a_{22} - a_{12}a_{21}\\]"
  },
  {
    "objectID": "slides/index.html#marix-determinant-1",
    "href": "slides/index.html#marix-determinant-1",
    "title": "Matrix Review",
    "section": "Marix Determinant",
    "text": "Marix Determinant\n\nFor \\(3 \\times 3\\) matrix \\(\\mathbf{A}\\)\n\n\\[\\mathbf{A}=\n\\begin{bmatrix}\na_{11}& a_{12} & a_{13} \\\\\na_{21}& a_{22} & a_{23} \\\\\na_{31}& a_{32} & a_{33} \\\\\n\\end{bmatrix}\\]\n\nThe determinant is\n\n\\[|\\mathbf{A}|=a_{11}a_{22}a_{33} + a_{12}a_{23}a_{31} +a_{13}a_{21}a_{32}\\] \\[-(a_{12}a_{21}a_{33} + a_{11}a_{23}a_{32} +a_{13}a_{22}a_{31})\\]\n\\[=a_{11}(a_{22}a_{33} - a_{23}a_{32}) + a_{12}(a_{23}a_{31} -a_{21}a_{33} )  +a_{13}(a_{21}a_{32} - a_{22}a_{31} )\\]"
  },
  {
    "objectID": "slides/index.html#marix-determinant-2",
    "href": "slides/index.html#marix-determinant-2",
    "title": "Matrix Review",
    "section": "Marix Determinant",
    "text": "Marix Determinant\n\nFor \\(n \\times n\\) matrix \\(\\mathbf{A}\\) the determinant is\n\n\\[|\\mathbf{A}|=a_{i1}c_{i1} + a_{i2}c_{i2} + \\cdots + a_{in}c_{in} \\text{   for choice of any row i}\\]\n\nWhere\n\n\\(a_{ij}\\) is the \\(ij\\) element of matrix \\(\\mathbf{A}\\)\n\\(c_{ij}\\) is the \\(ij\\) cofactor of matrix \\(\\mathbf{A}\\) defined as \\[c_{ij} = (-1)^{i+j}|\\mathbf{A}_{ij}|\\]\n\\(|\\mathbf{A}_{ij}|\\) is the minor of matrix \\(\\mathbf{A}\\)\n\nDeterminant of the sub-matrix formed by deleting the \\(i\\)th row and \\(j\\)th column of \\(\\mathbf{A}\\)\n\n\nProcess is long and tedious for large matrices"
  },
  {
    "objectID": "slides/index.html#marix-determinant-3",
    "href": "slides/index.html#marix-determinant-3",
    "title": "Matrix Review",
    "section": "Marix Determinant",
    "text": "Marix Determinant\n\nExample of \\(3 \\times 3\\) matrix\n\n\\[\\mathbf{A}=\n\\begin{bmatrix}\n1& 2 & 3 \\\\\n4& 5&6   \\\\\n7& 8 &9  \n\\end{bmatrix}\\]\n\nChoose any row to find cofactors and compute determinant\n\nDoes not matter which\n\nLet us expand along row 1\n\n\\[|\\mathbf{A}|=1(-1)^{1+1}\n\\begin{vmatrix}\n  5&6   \\\\\n8 &9  \n\\end{vmatrix}\n+2(-1)^{1+2}\n\\begin{vmatrix}\n  4&6   \\\\\n7 &9  \n\\end{vmatrix}\n+3(-1)^{1+3}\n\\begin{vmatrix}\n  4&5   \\\\\n7 &8  \n\\end{vmatrix}\\]\n\\[|\\mathbf{A}|= -3 +12 -9 = 0\\]"
  },
  {
    "objectID": "slides/index.html#matrix-inverse",
    "href": "slides/index.html#matrix-inverse",
    "title": "Matrix Review",
    "section": "Matrix Inverse",
    "text": "Matrix Inverse\n\nThe inverse of a square matrix \\(\\mathbf{A}\\) is defined such that\n\n\\[\\mathbf{A}\\mathbf{A}^{-1} = \\mathbf{A}^{-1}\\mathbf{A} = \\mathbf{I}\\]\n\nIt is roughly the equivalent of taking the reciprocal in scalar math\n\nBut it is not generally the reciprocal of the elements of a matrix\n\nThe formula for the inverse is\n\n\\[\\mathbf{A}^{-1}= \\frac{1}{|\\mathbf{A}|}\n\\begin{bmatrix}\nc_{11}& c_{12} &\\cdots & c_{1n} \\\\\nc_{21}& c_{22} &\\cdots & c_{2n} \\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\nc_{n1}& c_{n2} &\\cdots & c_{nn}\n\\end{bmatrix}\\]\n\nwhere \\(c_{ij}\\) are the cofactors defined above"
  },
  {
    "objectID": "slides/index.html#matrix-inverse-1",
    "href": "slides/index.html#matrix-inverse-1",
    "title": "Matrix Review",
    "section": "Matrix Inverse",
    "text": "Matrix Inverse\n\nThe inverse exists only when \\(|\\mathbf{A}| \\neq 0\\)\n\nThis is why it is important to know the determinant\nIn example above, inverse does not exist\n\nWe will see later that it is because the columns are linearly dependent\n\n\nA matrix that cannot be inverted is singular\nA matrix that has an inverse is nonsingular\nInverse matrices have the following properties\n\n\\[\\mathbf{(\\alpha A)^{-1} = \\frac{1}{\\alpha} A^{-1} }\\] \\[\\mathbf{(A')^{-1}} = \\mathbf{(A^{-1})' }\\] \\[\\mathbf{(A^{-1})^{-1}} = \\mathbf{A}\\] \\[\\mathbf{(AB)^{-1}= B^{-1}A^{-1} }\\]"
  },
  {
    "objectID": "slides/index.html#summary",
    "href": "slides/index.html#summary",
    "title": "Matrix Review",
    "section": "Summary",
    "text": "Summary\n\nNow that we can manipulate matrices, we can move to more advanced topics\nMatrix algebra is useful for expressing and solving systems of equations\n\nThis is how we will use it in econometrics\n\nWe will learn you can solve for the OLS estimator when regressors are linearly independent\n\nThey are not linear functions of one another\n\nTo check linear independence, we use the concept of rank\nThe rank of a matrix is the maximum number of independent rows or columns\n\nFor non-square matrices, the maximum rank is the lesser of the number or rows or columns"
  },
  {
    "objectID": "slides/index.html#linear-independence",
    "href": "slides/index.html#linear-independence",
    "title": "Matrix Review",
    "section": "Linear Independence",
    "text": "Linear Independence\n\nA set of vectors are linearly independent if you cannot express any of them as linear functions the others\nMathematically, suppose that \\(\\mathbf{A}=\\begin{bmatrix} \\mathbf{a}_{1}& \\mathbf{a}_{2} &\\cdots & \\mathbf{a}_{m} \\end{bmatrix}\\)\n\nwhere \\(\\mathbf{a}_{1}, \\mathbf{a}_{2}, \\cdots,\\mathbf{a}_{m}\\) are \\(n \\times 1\\) vectors\n\nThe vectors are independent if the only solution to\n\n\\[\\alpha_{1}\\mathbf{a}_{1}+ \\alpha_{2}\\mathbf{a}_{2}+ \\cdots+\\alpha_{m}\\mathbf{a}_{m}= 0\\]\n\nis\n\n\\[\\alpha_{1} = \\alpha_{2}= \\cdots=\\alpha_{m}= 0\\] - If at least one \\(\\alpha_{i} \\neq 0\\), then the vectors are linearly dependent"
  },
  {
    "objectID": "slides/index.html#rank-of-a-matrix",
    "href": "slides/index.html#rank-of-a-matrix",
    "title": "Matrix Review",
    "section": "Rank of a Matrix",
    "text": "Rank of a Matrix\n\nThe rank of a matrix is the maximum number of linearly independent rows or columns\n\nThe rank of the rows will always equal the rank of the columns\nIf the number of rows is less than columns, the highest rank is the number of rows\nVice versa if the number of columns is less than the number of rows\n\nA matrix has full rank if rank equals the minimum of the number of rows/columns\nIn econometrics, we mostly deal with matrices with more rows than columns\n\nSo the matrix will be full rank if the rank equals the number of columns\n\nWe will see later we need our matrix of regressors to have full rank\n\nNone of the regressors can be linear functions of each other (no multicollinearity)"
  },
  {
    "objectID": "slides/index.html#rank-of-a-matrix-1",
    "href": "slides/index.html#rank-of-a-matrix-1",
    "title": "Matrix Review",
    "section": "Rank of a Matrix",
    "text": "Rank of a Matrix\n\nSome useful properties of the rank of a matrix\n\nThe rank of a matrix and transpose are the same \\[rank(\\mathbf{A'}) = rank(\\mathbf{A})\\]\nIf \\(\\mathbf{A}\\) is \\(n \\times m\\) then \\[rank(\\mathbf{A}) \\le min(n,m)\\]\nIf \\(\\mathbf{A}\\) is \\(n \\times n\\) and \\(rank(\\mathbf{A}) =n\\) then \\(\\mathbf{A}\\) is nonsingular (invertible)"
  },
  {
    "objectID": "slides/index.html#quadratic-form",
    "href": "slides/index.html#quadratic-form",
    "title": "Matrix Review",
    "section": "Quadratic Form",
    "text": "Quadratic Form\n\nIf \\(\\mathbf{A}\\) is \\(n \\times n\\) and symmetric, and \\(\\mathbf{x}\\) is \\(n \\times 1\\), the quadratic form for \\(\\mathbf{A}\\) is\n\n\\[\\mathbf{x'Ax}=\n\\begin{bmatrix}\nx_{1}& x_{2} &\\cdots & x_{n}\n\\end{bmatrix}\n\\begin{bmatrix}\na_{11}& a_{12} &\\cdots & a_{1n} \\\\\na_{21}& a_{22} &\\cdots & a_{2n} \\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\na_{n1}& a_{n2} &\\cdots & a_{nn}\n\\end{bmatrix}\n\\begin{bmatrix}\nx_{1}\\\\\nx_{2} \\\\\n\\vdots \\\\\n  x_{n}\n\\end{bmatrix}\\]\n\\[=\\sum_{i=1}^n a_{ii}x_{i}^2 + 2\\sum_{i=1}^n \\sum_{j&gt;i}a_{ij}x_{i}x_{j}\\]\n\nA matrix is positive definite if for all \\(\\mathbf{x} \\neq 0\\)\n\n\\[\\mathbf{x'Ax} &gt; 0\\]"
  },
  {
    "objectID": "slides/index.html#positive-definite-matrices",
    "href": "slides/index.html#positive-definite-matrices",
    "title": "Matrix Review",
    "section": "Positive Definite Matrices",
    "text": "Positive Definite Matrices\n\nA matrix is positive semidefinite if for all \\(\\mathbf{x} \\neq 0\\)\n\n\\[\\mathbf{x'Ax} \\ge 0\\] - Positive definite matrices have diagonal elements that are strictly positive\n\nPositive semidefinite matrices have diagonal elements that are nonnegative\nSome other useful properties of positive definite/semidefinite matrices\n\nIf \\(\\mathbf{A}\\) is positive definite, then \\(\\mathbf{A}^{-1}\\) exists and is also positive definite\nIf \\(\\mathbf{A}\\) is \\(n \\times m\\), then \\(\\mathbf{A'A}\\) and \\(\\mathbf{AA'}\\) are positive definite\nIf \\(\\mathbf{A}\\) is \\(n \\times m\\) and \\(rank(\\mathbf{A}) = m\\) then \\(\\mathbf{A'A}\\) is positive definite\n\nThese concepts are used mostly for variance-covariance matrices in econometrics"
  },
  {
    "objectID": "slides/index.html#idempotent-matrices",
    "href": "slides/index.html#idempotent-matrices",
    "title": "Matrix Review",
    "section": "Idempotent Matrices",
    "text": "Idempotent Matrices\n\nAn idempotent matrix is one that does not change when multiplied by itself\nMathematically, \\(\\mathbf{A}\\) is idempotent when\n\n\\[\\mathbf{AA} = \\mathbf{A}\\]\n\nWhen we discuss OLS, we will work with the following idempotent matrices\n\nSuppose \\(\\mathbf{X}\\) is \\(n \\times k\\) with full rank. Define\n\n\n\\[\\mathbf{P} = \\mathbf{X(X'X)^{-1}X'}\\] \\[\\mathbf{M} =\\mathbf{I_{n}} - \\mathbf{X(X'X)^{-1}X'}\\]\n\nYou can verify they are idempotent my multiplying each by itself\nSome important properties of idempotent matrices are\n\n\\(rank(\\mathbf{A}) = tr(\\mathbf{A})\\)\n\\(\\mathbf{A}\\) is positive semidefinite"
  },
  {
    "objectID": "slides/index.html#expected-value",
    "href": "slides/index.html#expected-value",
    "title": "Matrix Review",
    "section": "Expected Value",
    "text": "Expected Value\n\nThe expected value of a random matrix is the matrix of expected values\nIf \\(\\mathbf{X}\\) is an \\(n \\times m\\) matrix, then\n\n\\[\\mathbf{E}(\\mathbf{X})=\n\\begin{bmatrix}\n\\mathbf{E}(x_{11}) & \\mathbf{E}(x_{12}) & \\cdots & \\mathbf{E}(x_{1m})\\\\\n\\mathbf{E}(x_{21}) & \\mathbf{E}(x_{22}) & \\cdots &\\mathbf{E}(x_{2m})\\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\n\\mathbf{E}(x_{n1}) & \\mathbf{E}(x_{n2}) & \\cdots &\\mathbf{E}(x_{nm})\\\\\n\\end{bmatrix}\\]\n\nProperties of expected values are similar to those in scalar math\n\nIf \\(\\mathbf{x}\\) is a random vector, \\(\\mathbf{b}\\) is a nonrandom vector, and \\(\\mathbf{A}\\) is a nonrandom matrix, then \\(\\mathbf{E}(\\mathbf{Ax+b}) = \\mathbf{A}\\mathbf{E}(\\mathbf{x})+\\mathbf{b}\\)\nIf \\(\\mathbf{X}\\) is a random matrix, and \\(\\mathbf{B}\\) and \\(\\mathbf{A}\\) are nonrandom matrices, then \\(\\mathbf{E}(\\mathbf{AXB}) = \\mathbf{A}\\mathbf{E}(\\mathbf{X})\\mathbf{B}\\)"
  },
  {
    "objectID": "slides/index.html#variance-covariance-matrix",
    "href": "slides/index.html#variance-covariance-matrix",
    "title": "Matrix Review",
    "section": "Variance-Covariance Matrix",
    "text": "Variance-Covariance Matrix\n\nThe variance-covariance matrix of random vector \\(\\mathbf{y}\\) has variances on the diagonal, covariances in the off-diagonal\nIf \\(\\mathbf{y}\\) is an \\(n \\times 1\\) random vector, then\n\n\\[var(\\mathbf{y})= \\mathbf{\\sigma_{y}} = \\mathbf{E[(y-E[y])(y-E[y])']}\\] \\[=\n\\begin{bmatrix}\n\\text{var}(y_{1}) & \\text{cov}(y_{1},y_{2}) & \\cdots &\\text{cov}(y_{1},y_{n}) \\\\\n\\text{cov}(y_{2},y_{1}) & \\text{var}(y_{2}) & \\cdots &\\text{cov}(y_{2},y_{n}) \\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\n\\text{cov}(y_{n},y_{1})  & \\text{cov}(y_{n},y_{2}) & \\cdots &\\text{var}(y_{n})\\\\\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/index.html#variance-covariance-matrix-1",
    "href": "slides/index.html#variance-covariance-matrix-1",
    "title": "Matrix Review",
    "section": "Variance-Covariance Matrix",
    "text": "Variance-Covariance Matrix\n\nUseful properties of variance-covariance matrices are\n\nIf \\(\\mathbf{a}\\) is a nonrandom vector, then \\(\\text{var}(\\mathbf{a'y}) =\\mathbf{a'}\\text{var}\\mathbf{(y)a}\\)\nIf \\(\\text{var}(\\mathbf{a'y})&gt;0\\) for all \\(\\mathbf{a&gt;0}\\), \\(\\text{var}(\\mathbf{y})\\) is positive definite\nIf \\(\\mathbf{A}\\) is a nonrandom matrix, \\(\\mathbf{b}\\) is a nonrandom vector, then \\(\\text{var}(\\mathbf{Ay + b}) =\\mathbf{A'}\\text{var}\\mathbf{(y)A}\\)\nIf \\(\\text{var}(y_{j})=\\sigma^{2}\\) for all \\(j=1,2,...,n\\), and the elements of \\(\\textbf{y}\\) are uncorrelated, then \\(\\text{var}(\\mathbf{y})=\\sigma^{2}\\mathbf{I_{n}}\\)"
  },
  {
    "objectID": "slides/index.html#scalar-functions",
    "href": "slides/index.html#scalar-functions",
    "title": "Matrix Review",
    "section": "Scalar Functions",
    "text": "Scalar Functions\n\nA scalar function of a vector is a single function with respect to several variables\n\nA vector function is a set of one or more scalar functions, each with respect to several variables\nWe will not cover these\n\nConsider the scalar function \\(y = f(\\mathbf{x}) =f(x_{1}, x_{2},...,x_{n})\\)\n\nThe function takes the vector \\(\\mathbf{x}\\) and returns a scalar\nThis is just another way to write a multivariate function\n\nThe derivative of this function is\n\n\\[\\frac{\\partial f(\\mathbf{x})}{\\mathbf{x}}=\n\\begin{bmatrix}\n\\frac{\\partial f(\\mathbf{x})}{x_{1}} & \\frac{\\partial f(\\mathbf{x})}{x_{2}} & \\cdots & \\frac{\\partial f(\\mathbf{x})}{x_{n}}  \n\\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/index.html#derivative-of-scalar-function",
    "href": "slides/index.html#derivative-of-scalar-function",
    "title": "Matrix Review",
    "section": "Derivative of Scalar Function",
    "text": "Derivative of Scalar Function\n\nWe simply collect the derivative with respect to each element of \\(\\mathbf{x}\\) in a vector\nEx: linear function of \\(\\mathbf{x}\\)\n\nSuppose \\(\\mathbf{a}\\) is an \\(n \\times 1\\) vector and \\[y = f(\\mathbf{x}) = \\mathbf{a'x} = \\sum_{i=1}^{n} a_{i}x_{i}\\]\nThe derivative is\n\n\\[\\frac{\\partial f(\\mathbf{x})}{\\partial \\mathbf{x}}=\\frac{\\partial \\mathbf{a'x} }{\\partial \\mathbf{x}}= \\mathbf{a'} =\n    \\begin{bmatrix}\n    a_{1}& a_{2}& \\cdots & a_{n}\n    \\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/index.html#derivative-of-scalar-function-1",
    "href": "slides/index.html#derivative-of-scalar-function-1",
    "title": "Matrix Review",
    "section": "Derivative of Scalar Function",
    "text": "Derivative of Scalar Function\n\nEx: Quadratic form of \\(\\mathbf{x}\\)\n\nSuppose \\(\\mathbf{A}\\) is an \\(n \\times n\\) symmetric matrix. The quadratic form is \\[y = f(\\mathbf{x}) = \\mathbf{x'Ax} =\\sum_{i=1}^n a_{ii}x_{i}^2 + 2\\sum_{i=1}^n \\sum_{j&gt;i}a_{ij}x_{i}x_{j}\\]\nThe derivative is \\[\\frac{\\partial f(\\mathbf{x})}{\\partial \\mathbf{x}}=\\frac{\\partial \\mathbf{x'Ax} }{\\partial \\mathbf{x}}= \\mathbf{2x'A}\\]"
  },
  {
    "objectID": "slides/index.html#population-regression-model",
    "href": "slides/index.html#population-regression-model",
    "title": "Matrix Review",
    "section": "Population Regression Model",
    "text": "Population Regression Model\n\nIn undergraduate textbooks, the population linear regression model is written as\n\n\\[y= \\beta_{0} + \\beta_{1}x_{1} + \\beta_{2}x_{2} + \\cdots + \\beta_{k}x_{k} + u\\]\n\n\\(y\\) and \\(x_{1},...,x_{k}\\) are observable random variables\n\\(u\\) is an unobservable random variable\nWe can write more compactly in vector form as\n\n\\[y=  \\mathbf{x}\\boldsymbol{\\beta}  + u\\]\n\n\\(\\mathbf{x}\\) is a \\(1 \\times (k+1)\\) vector of independent variables\n\nThere are \\(k\\) independent variables, plus an intercept\n\n\\(\\boldsymbol{\\beta}\\) is a \\((k+1) \\times 1\\) vector of slope parameters"
  },
  {
    "objectID": "slides/index.html#population-regression-model-1",
    "href": "slides/index.html#population-regression-model-1",
    "title": "Matrix Review",
    "section": "Population Regression Model",
    "text": "Population Regression Model\n\nNow suppose we take a random sample of \\(n\\) people from the population\nThe population model holds for each member of the sample\n\n\\[y_{i}=  \\mathbf{x_{i}}\\boldsymbol{\\beta}  + u_{i}, \\forall i=1,...,n\\]\n\nWe can express this more compactly with full matrix notation\n\n\\[\\mathbf{y}=  \\mathbf{X}\\boldsymbol{\\beta}  + \\mathbf{u}\\]\n\n\\(\\mathbf{X}\\) is an \\(n \\times (k+1)\\) matrix of observations on each regressor\n\\(\\boldsymbol{\\beta}\\) is still a \\((k+1) \\times 1\\) vector of slope parameters\n\\(\\mathbf{y}\\) is an \\(n \\times 1\\) vector of observations on the dependent variable\n\\(\\mathbf{u}\\) is an \\(n \\times 1\\) vector of error terms"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "EC313 Syllabus",
    "section": "",
    "text": "Prof. Justin Smith\n   Lazaridis Hall 3091\n   jusmith@wlu.ca\n\n\n\n\n\n   Tue/Thu\n   Sept-Dec 2025\n   4:00 - 5:20 PM\n   LH2066\n\n\n\n\n\n   Thur 12:30 PM - 2:30 PM\n   Schedule an appointment"
  },
  {
    "objectID": "syllabus.html#course-description",
    "href": "syllabus.html#course-description",
    "title": "EC313 Syllabus",
    "section": "Course Description",
    "text": "Course Description\nThis course examines the economics of taxation through both theoretical and empirical lenses. Using tools from microeconomics and econometrics, we analyze how different forms of taxation affect individual behavior, economic efficiency, and the distribution of resources. The course introduces key concepts in tax incidence, optimal taxation, pigouvian taxes, and the trade-offs between equity and efficiency. Students will engage with current research to understand how economists estimate the behavioral and welfare effects of tax policy. They are also asked to apply their knowledge to data based assignments. While the course is centered on the Canadian tax system, the main concepts are applicable more widely. By the end of the course, students will be equipped to critically assess tax policy using the theoretical and empirical techniques in public economics."
  },
  {
    "objectID": "syllabus.html#lectures",
    "href": "syllabus.html#lectures",
    "title": "Syllabus",
    "section": "Lectures",
    "text": "Lectures\nThe scheduling details of the course are as follows\n\n\n\nSection\nTime\nLocation\n\n\n\n\nA\nTR 4:00-5:20pm\nLH2066"
  },
  {
    "objectID": "syllabus.html#course-material",
    "href": "syllabus.html#course-material",
    "title": "EC313 Syllabus",
    "section": "Course Material",
    "text": "Course Material\n\nTextbook\nThe required textbook for the course is\nRosen, Harvey S., and Lindsay M. Tedds, and Trevor Tombe, and Jean-Francois Wen, and Tracy Snoddon. Public Finance in Canada. 6th Canadian edition. McGraw-Hill Ryerson, 2023.\nThis book is available in various locations, including but not limited to the Laurier Bookstore, Amazon, and direct fom the publisher, McGraw Hill. Here are the approximate prices you can expect\n\n\n\nSource\nBook Type\nPrice\n\n\n\n\nWLU Bookstore\nPhysical, Paperback\nTBD\n\n\nAmazon\nPhysical, Paperback\n$157\n\n\nMcGraw Hill\nPhysical, Paperback\n$129\n\n\nMcGraw Hill\nOnline, 180 Day Rental\n$69\n\n\nMcGraw Hill\nOnline, Lifetime\n$99\n\n\n\nMake sure to buy the book on its own, and not the version that comes bundled with Connect, as we will not use Connect in this course\n\n\nSoftware\nThe assignments will ask you to manipulate data with the statistical software Stata. The university has a site licence for this software, which you can access from the in-person or virtual computer labs. To access the virtual labs, follow the instructions outlined here\nhttps://students.wlu.ca/services-and-spaces/tech-services/computers-and-equipment/virtual-computer-labs.html\nIf you would like to purchase a copy of Stata for home use (not required), there are various options you can explore here: https://www.stata.com/order/dl/. The cheapest option is student license for Stata/BE, which costs USD 49.\n\n\nCourse GPT\nI have created a GPT specific to this course that you can use if you wish, linked here. While my opinion is that the best way to succeed in this course is to engage with the lectures, lecture notes, textbook, and to ask questions in office hours, I recognize that people will use AI. To make the AI experience as closely linked to EC313 as possible, I have trained a GPT on some of the course materials.\nYou are permitted to use generative AI for your assignments. In all submissions in which you use generative AI, you must cite its usage. Failing to cite the use of generative AI is a form of academic misconduct and Senate Policy 12.2 Student Code of Conduct: Academic Misconduct will be applied. Treat the AI as you would any other source, meaning that you cannot directly copy and paste AI output into your assignments.\nUse this tool with caution. As we all know, generative AI does not always produce reliable output, and as such you may get wrong answers to your questions even though it is trained on the course material."
  },
  {
    "objectID": "syllabus.html#evaluation",
    "href": "syllabus.html#evaluation",
    "title": "EC313 Syllabus",
    "section": "Evaluation",
    "text": "Evaluation\nYou will be evaluated on two equally weighted assignments, one midterm, and one final exam. The weights and due dates for each assessment are as follows:\n\n\n\nAssessment\nDue Date\nWeight\n\n\n\n\nAssignment 1\nFriday, October 3, 2025 at 9:00pm\n5%\n\n\nAssignment 2\nFriday, November 21, 2025 at 9:00pm\n5%\n\n\nMidterm\nThursday, October 30, 2025, in class\n40%\n\n\nFinal Exam\nTBA\n50%\n\n\n\nAssignments will ask you to manipulate and interpret data, and answer some short answer or mathematical questions. Instructions will be posted to MyLearningSpace one week prior to the due date.\nBoth the midterm and final exam will be in person. The midterm will take place in the classroom where the lectures take place at the scheduled lecture time. The final exam schedule is posted roughly half way through the term.\nIn the past I have placed more weight on the assignments and less weight on the in-person exams, but the pervasive use of generative AI has made it impossible to verify that assessments done outside of the classroom were actually completed by the student. So while take-home assignments are still part of the course, they do not constitute a large proportion of the grade."
  },
  {
    "objectID": "syllabus.html#topics",
    "href": "syllabus.html#topics",
    "title": "EC313 Syllabus",
    "section": "Topics",
    "text": "Topics\nBelow is a list of tentative topics covered in the course. I may add or remove items depending on how quickly the course proceeds. A reading list for each topic is available at the end of this syllabus.\n\n\n\nTopic\nReadings\n\n\n\n\nIntroduction to Public Finance\nRTTWS Chapter 1\n\n\nTax Incidence\nRTTWS Chapter 14\n\n\nTaxation and Efficiency\nRTTWS Chapter 15\n\n\nEfficient and Equitable Taxation\nRTTWS Chapter 16\n\n\nThe Personal Income Tax\nRTTWS Chapter 17\n\n\nPersonal Income Taxation and Behaviour\nRTTWS Chapter 18\n\n\nConsumption Taxation\nRTTWS Chapter 19\n\n\nExternalities and Pigouvian Taxes\nRTTWS Chapter 5\n\n\nTaxes on Wealth and Property\nRTTWS Chapter 20\n\n\nThe Corporation Tax\nRTTWS Chapter 21"
  },
  {
    "objectID": "syllabus.html#missed-midterms",
    "href": "syllabus.html#missed-midterms",
    "title": "EC313 Syllabus",
    "section": "Missed Midterms",
    "text": "Missed Midterms\nStudents who miss a midterm will be given deferred midterm for the following reasons:\n\nReligious conflict: If you have a religious commitment that interferes with the midterm exam, fill out the Student Request for Accommodation for Religious Observances form within two weeks of the start of the first day of classes.\nCourse conflict: If your midterm overlaps with another scheduled course, file a petition with the Lazaridis School Petitions Coordinator within two weeks of the start of the first day of classes.\nVarsity Sports: If a varsity sporting event interferes with the midterm, file a petition with the Lazaridis School Petitions Coordinator and contact the Department of Athletics within two weeks of the start of the first day of classes. Note that this policy applies only to varsity sports; students who have non-varsity sports conflicts are not eligible for a deferred midterm\n\nStudents who miss a midterm and have an acceptable medical or compassionate reason will have the weight of the midterm transferred to the final exam. In the case of medical reasons, I require that students complete the Absence for Medical Reasons Self-Declaration Form. Note that no medical notes are required or requested.\nIn all other circumstances, students who miss a midterm will receive a grade of zero on the test."
  },
  {
    "objectID": "content/introtor.html",
    "href": "content/introtor.html",
    "title": "Introduction to R",
    "section": "",
    "text": "Hanck, C., Arnold, M., Gerber, A., & Schmelzer, M. (2019). Introduction to Econometrics with R. University of Duisburg-Essen. Url: https://www.econometrics-with-r.org\nOswald, F., Viers, V., Robin, J.- M., Villedieu, P., Kenedi, G. (2020). Introduction to Econometrics with R. Department of Economics, Sciences Po. Url: https://scpoecon.github.io/ScPoEconometrics/"
  },
  {
    "objectID": "content/introtor.html#readings",
    "href": "content/introtor.html#readings",
    "title": "Introduction to R",
    "section": "",
    "text": "Hanck, C., Arnold, M., Gerber, A., & Schmelzer, M. (2019). Introduction to Econometrics with R. University of Duisburg-Essen. Url: https://www.econometrics-with-r.org\nOswald, F., Viers, V., Robin, J.- M., Villedieu, P., Kenedi, G. (2020). Introduction to Econometrics with R. Department of Economics, Sciences Po. Url: https://scpoecon.github.io/ScPoEconometrics/"
  },
  {
    "objectID": "content/introtor.html#slides",
    "href": "content/introtor.html#slides",
    "title": "Introduction to R",
    "section": "Slides",
    "text": "Slides\nThe slides are embedded in this page, and you can scroll through them with the arrow keys. If you prefer you can instead pop them out in a new window"
  },
  {
    "objectID": "content/introtor.html#other-resources",
    "href": "content/introtor.html#other-resources",
    "title": "Introduction to R",
    "section": "Other Resources",
    "text": "Other Resources\n\nR Studio Cheat Sheets\n\nThese provide a quick reference sheet for common packages in R, with examples on how to use them. A very valuable resources for both beginners and more advanced users.\n\nSwirl Package\n\nThis package is designed to help you learn R within R itself. There are several tutorials available that guide you throught the various topics."
  },
  {
    "objectID": "content/introtor.html#videos",
    "href": "content/introtor.html#videos",
    "title": "Introduction to R",
    "section": "Videos",
    "text": "Videos\n\nIntroduction to R by Nick Huntington-Klein\nEconomist Nick Huntington-Klein has produced a series of videos that cover how to use R for economists. The series is broken into beginner, intermediate, and advanced levels."
  },
  {
    "objectID": "content/introtor.html#tutorial",
    "href": "content/introtor.html#tutorial",
    "title": "Introduction to R",
    "section": "Tutorial",
    "text": "Tutorial\nThe .zip file below contains the files to run a learnr interactive tutorial. To use it, first ensure that you have installed the learnr and shiny packages. Then, download the file, unpack it, open the .Rmd file in RStudio, and click “run document.”\nThere is also a plain, non-interactive PDF version of the file below.\n EC655learnr.zip\n EC655learnrpdf.pdf"
  },
  {
    "objectID": "content/matrixrev.html",
    "href": "content/matrixrev.html",
    "title": "Matrix Algebra Review",
    "section": "",
    "text": "SW Chapter 19.1\nW2 Appendix D"
  },
  {
    "objectID": "content/matrixrev.html#readings",
    "href": "content/matrixrev.html#readings",
    "title": "Matrix Algebra Review",
    "section": "",
    "text": "SW Chapter 19.1\nW2 Appendix D"
  },
  {
    "objectID": "slides/index.html",
    "href": "slides/index.html",
    "title": "Matrix Review",
    "section": "",
    "text": "Undergrad metrics normally uses scalar notation\n\nMore accessible for students without advanced math background\n\nAt the graduate level, it is often taught using matrix algebra\nSome advantages to matrix notation\n\nMore compact\nEasier to express some estimators\n\nIn this section, we review matrix algebra essentials for econometrics\n\nNot a comprehensive review\n\nWe will switch between scalar and matrix notation in the course\n\nDepending on which is clearer in each context"
  },
  {
    "objectID": "syllabus.html#late-assignments",
    "href": "syllabus.html#late-assignments",
    "title": "EC313 Syllabus",
    "section": "Late Assignments",
    "text": "Late Assignments\nLate assignments and quizzes for religious conflicts, course conflicts, or medical/compassionate reasons as defined above will be given reasonable accommodation. In all other circumstances, students who submit late assignments or quizzes will receive a grade of zero."
  },
  {
    "objectID": "syllabus.html#deferred-final-examinations",
    "href": "syllabus.html#deferred-final-examinations",
    "title": "EC313 Syllabus",
    "section": "Deferred Final Examinations",
    "text": "Deferred Final Examinations\nStudents who miss a final examination should follow the university policy on deferred final exams. As noted in the policy, deferred exams may be granted for legitimate documentable reasons only, such as illness, religious reasons, extraordinary personal or family circumstances, a scheduling conflict with another exam or 3 exams within 24 hours. Deferred exams are not granted for travel or vacation during the final exam period, commuting, or for more study time. For religious accommodations, fill out the student request for accommodation for religious observances form within 7 calendar days before the final day of classes for the term. For other reasons, submit a petition to the Lazaridis School Petitions Coordinator within 3 business days after the scheduled date of the exam."
  },
  {
    "objectID": "syllabus.html#academic-integrity",
    "href": "syllabus.html#academic-integrity",
    "title": "EC313 Syllabus",
    "section": "Academic Integrity",
    "text": "Academic Integrity\nLaurier is committed to a culture of integrity within and beyond the classroom. This culture values trustworthiness (e.g., honesty, integrity, reliability), fairness, caring, respect, responsibility and citizenship. Together, we have a shared responsibility to uphold this culture in our academic and nonacademic behaviour. The University has a defined policy with respect to academic misconduct. As a Laurier student you are responsible for familiarizing yourself with this policy and the accompanying penalty guidelines, some of which may appear on your transcript if there is a finding of misconduct. The relevant policy can be found at Laurier’s academic integrity website along with resources to educate and support you in upholding a culture of integrity. Ignorance is not a defense.\nWilfrid Laurier University uses software that can check for plagiarism. Students may be required to submit their written work in electronic form and have it checked for plagiarism. Refer to the Handbook on Undergraduate Course Management for more information."
  },
  {
    "objectID": "syllabus.html#accessible-learning",
    "href": "syllabus.html#accessible-learning",
    "title": "EC313 Syllabus",
    "section": "Accessible Learning",
    "text": "Accessible Learning\nContact Accessible Learning if you require academic accommodations because of a disability. Review the Registration page for information about intake and documentation requirements. Deadlines: Students are responsible for meeting posted deadlines for registering with Accessible Learning and booking accommodated exams. Accessible Learning cannot guarantee accommodations for requests received after posted deadlines."
  },
  {
    "objectID": "syllabus.html#student-privacy",
    "href": "syllabus.html#student-privacy",
    "title": "EC313 Syllabus",
    "section": "Student Privacy",
    "text": "Student Privacy\nWilfrid Laurier University uses a range of technologies to facilitate in-person and remote instruction. Zoom is currently used for remote course delivery, including lectures, seminars, and group office hours, which may be recorded, stored and shared through MyLearningSpace for access by students in the course. For these course activities, students are permitted to turn off their cameras or use an alternative name to maintain their privacy after they have confirmed this with their instructor. Lectures will be recorded using a voice recorder in order to generate summaries. Student personal information is collected and used in the course in accordance with University policies and the Notice of Collection, Use or Disclosure of Personal Information."
  },
  {
    "objectID": "syllabus.html#foot-patrol-the-wellness-centre-and-the-student-food-bank",
    "href": "syllabus.html#foot-patrol-the-wellness-centre-and-the-student-food-bank",
    "title": "Syllabus",
    "section": "Foot Patrol, the Wellness Centre, and the Student Food Bank",
    "text": "Foot Patrol, the Wellness Centre, and the Student Food Bank\nThe University approved the inclusion of information about select wellness and safety services and supports on campus in the course information provided to students. (Approved by Senate November 28, 2011.) Specific language (by campus) is provided below.\n\nMulti-campus Resource:\n\nGood2Talk is a postsecondary school helpline that provides free, professional and confidential counselling support for students in Ontario. Call 1-866-925-5454 or through 2-1-1. Available 24-7.\n\nKitchener/Waterloo Resources:\n\nWaterloo Student Food Bank: All students are eligible to use this service to ensure they’re eating healthy when overwhelmed, stressed or financially strained. Anonymously request a package online 24-7. All dietary restrictions accommodated.\nWaterloo Foot Patrol: 519.886.FOOT (3668). A volunteer operated safe-walk program, available Fall and Winter daily from 6:30 pm to 3 am. Teams of two are assigned to escort students to and from campus by foot or by van.\nWaterloo Student Wellness Centre:519-884-0710, x3146. The Centre supports the physical, emotional, and mental health needs of students. Located on the 2nd floor of the Student Services Building, booked and same-day appointments are available Mondays and Wednesdays from 8:30 am to 7:30 pm, and Tuesdays, Thursdays and Fridays from 8:30 am to 4:15 pm. Contact the Centre at x3146, wellness@wlu.ca or @LaurierWellness. After hours crisis support available 24/7. Call 1-844-437-3247 (HERE247).\n\nBrantford Resources:\n\nBrantford Student Food Bank: All students are eligible to use this service to ensure they’re eating healthy when overwhelmed, stressed or financially strained. Anonymously request a package online 24-7. All dietary restrictions accommodated.\nBrantford Foot Patrol:519-751-PTRL (7875). A volunteer operated safe-walk program, available Fall and Winter, Monday through Thursday from 6:30 pm to 1 am; Friday through Sunday 6:30 pm to 11 pm. Teams of two are assigned to escort students to and from campus by foot or by van.\nBrantford Wellness Centre:519-756-8228, x5803. Students have access to support for all their physical, emotional, and mental health needs at the Wellness Centre. Location: Student Centre, 2nd floor. Hours: 8:30 am to 4:15 pm Monday through Friday. After hours crisis support available 24/7. Call 1-884-437-3247 (HERE247)."
  },
  {
    "objectID": "syllabus.html#intellectual-property",
    "href": "syllabus.html#intellectual-property",
    "title": "EC313 Syllabus",
    "section": "Intellectual Property",
    "text": "Intellectual Property\nThe educational materials developed for this course, including, but not limited to, lecture notes and slides, handout materials, examinations and assignments, and any materials posted to MyLearningSpace, are the intellectual property of the course instructors. These materials have been developed for student use only and they are not intended for wider dissemination and/or communication outside of a given course. Posting or providing unauthorized audio, video, or textual material of course content to third-party websites violates instructors’ intellectual property rights, and the Canadian Copyright Act. Recording lectures in any way is prohibited in this course unless specific permission has been granted by instructors. Failure to follow these instructions may be in contravention of the university’s Student Non-Academic Code of Conduct and/or Code of Academic Conduct, and will result in appropriate penalties. Participation in this course constitutes an agreement by all parties to abide by the relevant University Policies, and to respect the intellectual property of others during and after their association with Wilfrid Laurier University."
  },
  {
    "objectID": "content/matrixrev.html#videos",
    "href": "content/matrixrev.html#videos",
    "title": "Matrix Algebra Review",
    "section": "Videos",
    "text": "Videos\nThe series of videos below goes through the basics of linear algebra for economists. It convers most of the things we talk about, and more."
  },
  {
    "objectID": "content/matrixrev.html#other-resources",
    "href": "content/matrixrev.html#other-resources",
    "title": "Matrix Algebra Review",
    "section": "Other Resources",
    "text": "Other Resources"
  },
  {
    "objectID": "content/regression.html",
    "href": "content/regression.html",
    "title": "Regression",
    "section": "",
    "text": "AP1 Chapter 3\nAP2 Chapter 2\nC Chapter 2\nCT Chapter 4\nHA Chapters 2\nHK Chapter 13\nK Chapter 3\nSW Chapters 4,5,6,7,8\nW1 Chapter 4\nW2 Chapters 2,3"
  },
  {
    "objectID": "content/regression.html#readings",
    "href": "content/regression.html#readings",
    "title": "Regression",
    "section": "",
    "text": "AP1 Chapter 3\nAP2 Chapter 2\nC Chapter 2\nCT Chapter 4\nHA Chapters 2\nHK Chapter 13\nK Chapter 3\nSW Chapters 4,5,6,7,8\nW1 Chapter 4\nW2 Chapters 2,3"
  },
  {
    "objectID": "content/regression.html#slides",
    "href": "content/regression.html#slides",
    "title": "Regression",
    "section": "Slides",
    "text": "Slides\nThe slides are embedded in this page, and you can scroll through them with the arrow keys. If you prefer you can instead pop them out in a new window"
  },
  {
    "objectID": "content/regression.html#videos",
    "href": "content/regression.html#videos",
    "title": "Regression",
    "section": "Videos",
    "text": "Videos\nThis is a lecture from (recent Nobel Prize winner) Joshua Angrist explaining these same ideas as part of a lecture series from the American Economics Association (no preview available). View video"
  },
  {
    "objectID": "slides/regression/index.html",
    "href": "slides/regression/index.html",
    "title": "\nConditional Expectation Functions and Regression\n",
    "section": "",
    "text": "Conditional Expectation Functions and Regression"
  },
  {
    "objectID": "slides/regression/index.html#introduction-1",
    "href": "slides/regression/index.html#introduction-1",
    "title": "E655 - Econometrics",
    "section": "Introduction",
    "text": "Introduction\n\nQuestions in economics often involve explaining a variable in terms of others\n\nDoes age of school entry affect test scores?\nDoes childhood health insurance affect adult health?\nDoes foreign competition affect domestic innovation?\n\nInterest is usually in the causal relationship\n\nThe independent effect of one variable on another\n\nEconometrics provides a framework for examining these relationships\n\nStrong focus on causality"
  },
  {
    "objectID": "slides/regression/index.html#conditional-expectation-function",
    "href": "slides/regression/index.html#conditional-expectation-function",
    "title": "E655 - Econometrics",
    "section": "Conditional Expectation Function",
    "text": "Conditional Expectation Function\n\nWe want to relate dependent variable \\(y\\) to independent variables \\(\\mathbf{x}\\)\nWant to know systematically what happens to \\(y\\) when \\(\\mathbf{x}\\) changes\nDifficult because \\(y\\) and \\(\\mathbf{x}\\) are random variables\n\n\\(y\\) can take many different values for each \\(\\mathbf{x}\\)\n\nA way systematic patterns is to focus on average \\(y\\) at each \\(\\mathbf{x}\\)\n\nEx: Does average achievement fall as we increase class size?\n\nThis is the conditional expectation function (CEF) \\(\\mathbf{E}[y|\\mathbf{x}]\\)\n\n\n\n\n\n\n\nNote\n\n\nThe CEF is the population average value of \\(y\\) at each \\(\\mathbf{x}\\). The average can change at different \\(\\mathbf{x}\\), meaning it is a function of \\(\\mathbf{x}\\)."
  },
  {
    "objectID": "slides/regression/index.html#conditional-expectation-function-1",
    "href": "slides/regression/index.html#conditional-expectation-function-1",
    "title": "E655 - Econometrics",
    "section": "Conditional Expectation Function",
    "text": "Conditional Expectation Function\n\n\n\nLog earnings on vertical axis, years of schooling on horizontal\nGrey shaded areas are distribution of log earnings at each level of schooling\n\nBig spread incomes for each level of schooling\n\nBlack line is the CEF of earnings at each level of schooling\n\nIncreasing pattern between school and earnings is easier to see"
  },
  {
    "objectID": "slides/regression/index.html#conditional-expectation-function-2",
    "href": "slides/regression/index.html#conditional-expectation-function-2",
    "title": "E655 - Econometrics",
    "section": "Conditional Expectation Function",
    "text": "Conditional Expectation Function\n\nThe CEF highlights the pattern through randomness\nIt is the optimal predictor of \\(y\\) given \\(\\mathbf{x}\\)\n\nIt minimizes the mean squared error in predicting \\(y\\)\n\nProblem with using CEF: as a population value, it is not known\n\nIt is not observable because we do not see the population\n\nInstead, use linear regression to approximate it"
  },
  {
    "objectID": "slides/regression/index.html#conditional-expectation-function-3",
    "href": "slides/regression/index.html#conditional-expectation-function-3",
    "title": "E655 - Econometrics",
    "section": "Conditional Expectation Function",
    "text": "Conditional Expectation Function\n\nWe can use linear regression to approximate CEF\nThis approximation is justified in several ways\n\nIf the CEF is linear, it is equivalent to population regression function\nThe population regression function is the best linear predictor of \\(y\\) given \\(\\mathbf{x}\\)\nThe population regression function is the best linear approximation to the CEF\n\nThis is partly why linear regression is so popular in economics\nNext section examines the population regression function\n\nDerive the population slope before thinking about samples\nThis derivation will probably be new to you"
  },
  {
    "objectID": "slides/regression/index.html#model",
    "href": "slides/regression/index.html#model",
    "title": "E655 - Econometrics",
    "section": "Model",
    "text": "Model\n\nA linear model relating \\(y\\) to one or more explanatory variables \\(\\mathbf{x}\\) is\n\n\\[y = \\mathbf{x}\\boldsymbol{\\beta} + u\\]\n\nWhere\n\n\\(y\\) is a scalar observable random outcome variable\n\\(\\mathbf{x}\\) is a \\(1\\times (k + 1)\\) vector of random explanatory factors\n\\(\\boldsymbol{\\beta}\\) is a \\((k + 1) \\times 1\\) vector of slope parameters (non-random)\n\\(u\\) is a scalar population residual term\n\nThis is our model for the (unobserved) population\n\nSometimes called the Data Generating Process (DGP)\n\n\\(\\mathbf{x}\\boldsymbol{\\beta}\\) is called the Population Regression Function (PRF)\n\nThe part of \\(y\\) that is predictable by \\(\\mathbf{x}\\)"
  },
  {
    "objectID": "slides/regression/index.html#model-1",
    "href": "slides/regression/index.html#model-1",
    "title": "E655 - Econometrics",
    "section": "Model",
    "text": "Model\n\nRecall we are using it to approximate the CEF\n\nGoal is not necessarily to get approximation exactly right\nBut to capture essential features of relationship\n\nIn undergrad courses it is typical to just assume the CEF is linear\n\nThis is not necessarily true\nBut avoids complications of non-linear CEF\n\nIn some cases the CEF is inherently linear\n\nIn last section of the course, we saw the CEF for a binary treatment\nThis type of CEF is linear, so it equals the PRF"
  },
  {
    "objectID": "slides/regression/index.html#population-regression-slope-vector",
    "href": "slides/regression/index.html#population-regression-slope-vector",
    "title": "E655 - Econometrics",
    "section": "Population Regression Slope Vector",
    "text": "Population Regression Slope Vector\n\nThe population least squares vector minimizes the mean squared prediction error (MSPE)\n\n\\[\\min_\\beta \\textbf{E}[(y-\\mathbf{x}\\boldsymbol{\\beta})^2]\\]\n\nTake the derivative with respect to \\(\\boldsymbol{\\beta}\\) to get first order condition\n\n\\[\\textbf{E}[\\mathbf{x}'(y-\\mathbf{x}\\boldsymbol{\\beta})]= \\mathbf{0}\\]\n\nSolve for \\(\\boldsymbol{\\beta}\\)\n\n\\[\\textbf{E}[\\mathbf{x}'y]= \\textbf{E}[\\mathbf{x'x}\\boldsymbol{\\beta}]\\] \\[\\textbf{E}[\\mathbf{x}'y]= \\textbf{E}[\\mathbf{x'x}]\\boldsymbol{\\beta}\\] \\[(\\textbf{E}[\\mathbf{x'x}])^{-1} \\textbf{E}[\\mathbf{x}'y]= \\boldsymbol{\\beta}\\]"
  },
  {
    "objectID": "slides/regression/index.html#population-regression-slope-vector-1",
    "href": "slides/regression/index.html#population-regression-slope-vector-1",
    "title": "E655 - Econometrics",
    "section": "Population Regression Slope Vector",
    "text": "Population Regression Slope Vector\n\n\n\n\n\n\nImportant\n\n\nThe population least squares slope vector is\n\\[\\boldsymbol{\\beta} = (\\textbf{E}[\\mathbf{x'x}])^{-1} \\textbf{E}[\\mathbf{x}'y]\\]\n\n\n\n\nNow consider pulling the intercept out of the \\(\\boldsymbol{\\beta}\\) vector\n\n\\[y = \\alpha + \\mathbf{x}\\boldsymbol{\\beta} + u\\]\n\nTake the mean of this equation\n\n\\[E[y] = E[\\alpha + \\mathbf{x}\\boldsymbol{\\beta} + u] = \\alpha + E[\\mathbf{x}]\\boldsymbol{\\beta}\\]"
  },
  {
    "objectID": "slides/regression/index.html#population-regression-slope-vector-2",
    "href": "slides/regression/index.html#population-regression-slope-vector-2",
    "title": "E655 - Econometrics",
    "section": "Population Regression Slope Vector",
    "text": "Population Regression Slope Vector\n\nSubtract from first equation\n\n\\[y - E[y] = (\\mathbf{x}\\boldsymbol - E[\\mathbf{x}]){\\beta}  + u\\]\n\nUsing the population linear regression vector formula\n\n\\[\\boldsymbol{\\beta} = (\\textbf{E}[\\mathbf{(\\mathbf{x}\\boldsymbol - \\textbf{E}[\\mathbf{x}])'(\\mathbf{x}\\boldsymbol - \\textbf{E}[\\mathbf{x}])}])^{-1} \\textbf{E}[(\\mathbf{x}\\boldsymbol - \\textbf{E}[\\mathbf{x}])'(y - \\textbf{E}[y])]  = VAR[\\mathbf{x}]^{-1}COV[\\mathbf{x},y]\\]\n\n\n\n\n\n\nImportant\n\n\nAn alternative way to write the population least squares vector is\n\\[\\boldsymbol{\\beta} = VAR[\\mathbf{x}]^{-1}COV[\\mathbf{x},y]\\]\n\\[\\alpha = \\textbf{E}[y] - \\textbf{E}[\\mathbf{x}]\\boldsymbol{\\beta}\\]"
  },
  {
    "objectID": "slides/regression/index.html#population-regression-slope-vector-3",
    "href": "slides/regression/index.html#population-regression-slope-vector-3",
    "title": "E655 - Econometrics",
    "section": "Population Regression Slope Vector",
    "text": "Population Regression Slope Vector\n\nBringing the expectation through the brackets\n\n\\[\\text{cov}(x_{1},u) = \\mathbf{E}(x_{1}u) -  \\mathbf{E}(x_{1})\\mathbf{E}(u) = \\mathbf{E}(x_{1}u)\\]\n\nSays that \\(u\\) is mean zero and uncorrelated with \\(\\mathbf{x}\\)\n\n\n\n\n\n\n\nNote\n\n\n\\(u\\) is the population residual, and is defined as \\(u = y - \\mathbf{x}\\boldsymbol{\\beta}\\) where \\(\\boldsymbol{\\beta} = (\\textbf{E}[\\mathbf{x'x}])^{-1} \\textbf{E}[\\mathbf{x}'y]\\)\nBy definition it has mean zero and is uncorrelated with \\(\\mathbf{x}\\). We cannot use this to determine causality, which is determined by whether the slope in the CEF has a causal interpretation. We will discuss this in detail later."
  },
  {
    "objectID": "slides/regression/index.html#population-regression-slope-vector-4",
    "href": "slides/regression/index.html#population-regression-slope-vector-4",
    "title": "E655 - Econometrics",
    "section": "Population Regression Slope Vector",
    "text": "Population Regression Slope Vector\n\nIf we observed the population we could compute \\(\\boldsymbol{\\beta}\\)\nProblem again is we do not observe the population\nSo we cannot compute \\(\\textbf{E}[\\mathbf{x}'y]\\) or \\((\\textbf{E}[\\mathbf{x'x}])^{-1}\\)\nInstead, we collect a sample of data and estimate \\(\\boldsymbol{\\beta}\\)\nBefore we do that, we briefly discuss causality in regression models"
  },
  {
    "objectID": "slides/regression/index.html#why-is-causality-important",
    "href": "slides/regression/index.html#why-is-causality-important",
    "title": "E655 - Econometrics",
    "section": "Why is Causality Important?",
    "text": "Why is Causality Important?\n\nEmpirical economists are often interested in a causal effect\nFor policy, it is often key to have estimate causal effect\n\nE.g. a school district looking to implement pre-kindergarten program\nThis is generally funded with public money\nNeed to know if pre-k has independent effects on current and future outcomes\n\nDo not want this estimate confounded with parent background\n\n\nWhen can we interpret a regression slope as causal?\nAnswer: when the model is structural\n\nStructural model is one where the coefficients have a causal interpretation"
  },
  {
    "objectID": "slides/regression/index.html#model-with-one-binary-regressor",
    "href": "slides/regression/index.html#model-with-one-binary-regressor",
    "title": "E655 - Econometrics",
    "section": "Model with One Binary Regressor",
    "text": "Model with One Binary Regressor\n\nIn the last section we defined the underlying potential outcomes as\n\n\\[y_{0} = \\alpha + \\eta\\] \\[y_{1} = y_{0} + \\rho\\]\n\nWith the observed outcome\n\n\\[y = \\alpha + \\rho w + \\eta\\]\n\nThis regression model is structural because \\(\\rho\\) is the causal effect\nWe derived that the difference in conditional expectations is\n\n\\[E(y|w=1) - E(y|w=0) = \\rho  + E(\\eta |w=1) - E(\\eta |w=0)\\]"
  },
  {
    "objectID": "slides/regression/index.html#model-with-one-binary-regressor-1",
    "href": "slides/regression/index.html#model-with-one-binary-regressor-1",
    "title": "E655 - Econometrics",
    "section": "Model with One Binary Regressor",
    "text": "Model with One Binary Regressor\n\nThe population regression function with a binary regressor is\n\n\\[y = \\beta_{0} + \\beta_{1}w + u\\]\n\nThe population least squares slope \\(\\beta_{1}\\) from minimizing the MSPE is\n\n\\[\\beta_{1} =  E(y|w=1) - E(y|w=0)\\]\n\nCombining this equation with the structural model\n\n\\[\\beta_{1}  = \\rho  + E(\\eta |w=1) - E(\\eta |w=0)\\]"
  },
  {
    "objectID": "slides/regression/index.html#model-with-one-binary-regressor-2",
    "href": "slides/regression/index.html#model-with-one-binary-regressor-2",
    "title": "E655 - Econometrics",
    "section": "Model with One Binary Regressor",
    "text": "Model with One Binary Regressor\n\nThe regression slope \\(\\beta_{1}\\) equals the treatment effect \\(\\rho\\) when\n\\[E(\\eta |w=1) - E(\\eta |w=0)\\]\nWe saw cases when this is true\n\nRandomization\nMean independence of \\(\\eta\\)\n\nIf none of these are true, then \\(\\beta_{1} \\neq \\rho\\) and \\(\\beta_{1}\\) is not a causal effect"
  },
  {
    "objectID": "slides/regression/index.html#model-with-continuous-regressor",
    "href": "slides/regression/index.html#model-with-continuous-regressor",
    "title": "E655 - Econometrics",
    "section": "Model with Continuous Regressor",
    "text": "Model with Continuous Regressor\n\nWith a continuous independent variable \\(s\\), suppose the structural model is\n\n\\[y = \\alpha + \\rho s + \\eta\\]\n\nWhere the definition of \\(\\rho\\) is\n\\[\\rho = E(y_{s_{0}}|s=s_{0}) - E(y_{s_{0}-1}|s = s_{0} - 1)\\]\nWhere \\(y_{s_{0}}\\) and \\(y_{s_{0}-1}\\) are potential outcomes with two different levels of \\(s\\)\n\n\\(\\rho\\) is the causal effect of a one-unit increase in \\(s\\)\n\nIf we set the population regression function as\n\n\\[y = \\beta_{0} + \\beta_{1}s + u\\]"
  },
  {
    "objectID": "slides/regression/index.html#model-with-continuous-regressor-1",
    "href": "slides/regression/index.html#model-with-continuous-regressor-1",
    "title": "E655 - Econometrics",
    "section": "Model with Continuous Regressor",
    "text": "Model with Continuous Regressor\n\nThe regression slope is\n\n\\[\\beta_{1} = \\frac{cov(y,s)}{var(s)}\\]\n\nTo relate \\(\\beta_{1}\\) to \\(\\rho\\), sub in the structural model for \\(y\\)\n\n\\[\\beta_{1} = \\frac{cov(\\alpha + \\rho s + \\eta ,s)}{var(s)}\\]\n\nSimplifying we get\n\n\\[\\beta_{1} = \\rho + \\frac{cov(\\eta ,s)}{var(s)}\\]"
  },
  {
    "objectID": "slides/regression/index.html#model-with-continuous-regressor-2",
    "href": "slides/regression/index.html#model-with-continuous-regressor-2",
    "title": "E655 - Econometrics",
    "section": "Model with Continuous Regressor",
    "text": "Model with Continuous Regressor\n\n\\(\\beta_{1}\\) equals \\(\\rho\\) when \\(\\eta\\) and \\(s\\) are uncorrelated\n\nRandomization, mean independence both mean this is true\n\nSo if we assume\n\n\\[E(\\eta | s) = 0\\]\n\nThen the second term in equation above is zero and the population slope is the causal effect"
  },
  {
    "objectID": "slides/regression/index.html#model-with-continuous-regressor-3",
    "href": "slides/regression/index.html#model-with-continuous-regressor-3",
    "title": "E655 - Econometrics",
    "section": "Model with Continuous Regressor",
    "text": "Model with Continuous Regressor\n\nNow imagine that the structural model is\n\n\\[y = \\alpha + \\rho s + \\gamma x + \\eta\\]\n\nThe definition of \\(\\rho\\) is\n\n\\[\\rho = E(y_{s_{0}}|x, s=s_{0}) - E(y_{s_{0}-1}|x, s = s_{0} - 1)\\]\n\nIf we set the population regression function as\n\n\\[y = \\beta_{0} + \\beta_{1}s +  \\beta_{2} x+ u\\]"
  },
  {
    "objectID": "slides/regression/index.html#model-with-continuous-regressor-4",
    "href": "slides/regression/index.html#model-with-continuous-regressor-4",
    "title": "E655 - Econometrics",
    "section": "Model with Continuous Regressor",
    "text": "Model with Continuous Regressor\n\nThen \\(\\beta_{1}\\) equals \\(\\rho\\) if we assume\n\nConditional independence of \\(\\eta\\)\nConditional mean independence of \\(\\eta\\)\n\nConditional mean independence means\n\n\\[E(\\eta | s, x) = E(\\eta | x)\\]\n\nIn words, this means \\(s\\) is related to potential outcomes only through \\(x\\)\n\nSo holding \\(x\\) constant breaks this relationship\n\nEven though \\(\\beta_{1}\\) equals \\(\\rho\\), it is important to note that \\(\\beta_{0} \\neq \\alpha\\) and \\(\\beta_{2} \\neq \\gamma\\)\n\nWith regression we do not measure the structural intercept or effect of \\(x\\)"
  },
  {
    "objectID": "slides/regression/index.html#model-with-continuous-regressor-5",
    "href": "slides/regression/index.html#model-with-continuous-regressor-5",
    "title": "E655 - Econometrics",
    "section": "Model with Continuous Regressor",
    "text": "Model with Continuous Regressor\n\nTo see this, take expectation of \\(y\\) in structural model\n\n\\[E[y|s,x] = \\alpha + \\rho s + \\gamma x + E[\\eta|s,x]\\]\n\nIf we impose conditional mean independence, then \\(E(\\eta | s, x) = E(\\eta | x)\\)\n\n\\[E[y|s,x] = \\alpha + \\rho s + \\gamma x + E[\\eta|x]\\]\n\nThe error is not a function of \\(s\\) anymore, but it is a function of \\(x\\)\nFor example, suppose\n\n\\[\\eta = \\theta_{0} + \\theta_{1} x + \\epsilon\\]"
  },
  {
    "objectID": "slides/regression/index.html#model-with-continuous-regressor-6",
    "href": "slides/regression/index.html#model-with-continuous-regressor-6",
    "title": "E655 - Econometrics",
    "section": "Model with Continuous Regressor",
    "text": "Model with Continuous Regressor\n\nAssume that \\(\\epsilon\\) is just a random error unrelated to \\(x\\) and \\(s\\)\nSub into structural model\n\n\\[y = \\alpha + \\rho s + \\gamma x +  \\theta_{0} + \\theta_{1} x + \\epsilon\\] \\[y = (\\alpha +\\theta_{0})+ \\rho s + (\\gamma + \\theta_{1})x \\epsilon\\] \\[y = \\lambda + \\rho s + \\pi x + \\epsilon\\]\n\nThe intercept and slope on \\(x\\) are now redefined\n\nThe are no longer causal effects\n\nSlope on \\(s\\) is still the causal effect \\(\\rho\\)"
  },
  {
    "objectID": "slides/regression/index.html#model-with-continuous-regressor-7",
    "href": "slides/regression/index.html#model-with-continuous-regressor-7",
    "title": "E655 - Econometrics",
    "section": "Model with Continuous Regressor",
    "text": "Model with Continuous Regressor\n\nIf the regression function is\n\n\\[y = \\beta_{0} + \\beta_{1}s +  \\beta_{2} x+ u\\]\n\nThen if \\(E[\\epsilon|s,x] = 0\\)\n\n\\[\\beta_{0} = \\lambda\\] \\[\\beta_{1} = \\rho\\] \\[\\beta_{2} = \\pi\\]"
  },
  {
    "objectID": "slides/regression/index.html#omitted-variables-bias",
    "href": "slides/regression/index.html#omitted-variables-bias",
    "title": "E655 - Econometrics",
    "section": "Omitted Variables Bias",
    "text": "Omitted Variables Bias\n\nIn the regression model above, what happens if we leave out \\(x\\)?\nContinue to assume conditional mean independence\n\n\\[y = \\beta_{0} + \\beta_{1}s  + u\\]\n\nRemember the regression slope is\n\n\\[\\beta_{1} =  \\frac{cov(y ,s)}{var(s)}\\]\n\nSub in the structural model\n\n\\[\\beta_{1} =  \\frac{cov(\\lambda + \\rho s + \\pi x + \\epsilon ,s)}{var(s)}\\]"
  },
  {
    "objectID": "slides/regression/index.html#omitted-variables-bias-1",
    "href": "slides/regression/index.html#omitted-variables-bias-1",
    "title": "E655 - Econometrics",
    "section": "Omitted Variables Bias",
    "text": "Omitted Variables Bias\n\\[\\beta_{1} =  \\rho + \\pi* \\frac{cov( x ,s)}{var(s)} +  \\frac{cov( \\epsilon ,s)}{var(s)}\\]\n\nThe last term is zero because we assume \\(\\epsilon\\) is unrelated to \\(x\\) and \\(s\\)\n\\[\\beta_{1} =  \\rho + \\pi* \\frac{cov( x ,s)}{var(s)}\\]\nThe regression slope does not measure the causal effect in this case\nThe bias is\n\n\\[\\pi* \\frac{cov( x ,s)}{var(s)}\\]"
  },
  {
    "objectID": "slides/regression/index.html#omitted-variables-bias-2",
    "href": "slides/regression/index.html#omitted-variables-bias-2",
    "title": "E655 - Econometrics",
    "section": "Omitted Variables Bias",
    "text": "Omitted Variables Bias\n\nBias has two parts\n\n\\(\\pi \\rightarrow\\) the effect of \\(x\\) on \\(y\\)\n\\(\\frac{cov( x ,s)}{var(s)} \\rightarrow\\) the effect of \\(s\\) on \\(x\\)\n\nIf \\(x\\) is related to \\(y\\) and \\(x\\) is related to \\(s\\), we have bias\nDirection of bias depends on signs of each term\n\nIf both positive or both negative \\(\\rightarrow\\) positive bias\nIf one positive and one negative \\(\\rightarrow\\) negative bias\n\nIf either \\(y\\) or \\(s\\) is unrelated to \\(x\\), there is no bias\nIn vector notation, restate the structural model as\n\n\\[y = \\mathbf{x_{1}}\\boldsymbol{\\alpha_{1}} + \\mathbf{x_{2}}\\boldsymbol{\\alpha_{2}} + \\eta\\]"
  },
  {
    "objectID": "slides/regression/index.html#omitted-variables-bias-3",
    "href": "slides/regression/index.html#omitted-variables-bias-3",
    "title": "E655 - Econometrics",
    "section": "Omitted Variables Bias",
    "text": "Omitted Variables Bias\n\nIf we try to approximate it with the population regression function\n\n\\[y = \\mathbf{x_{1}}\\boldsymbol{\\beta_{1}} + u\\]\n\nWe get the population regression slope as\n\n\\[\\boldsymbol{\\beta_{1}}=\\left (  E[\\mathbf{x_{1}'x_{1}}\\right] )^{-1}  E[\\mathbf{x_{1}'}y]\\]\n\nSub the structural model into the population slope function\n\n\\[\\boldsymbol{\\beta_{1}}=\\left (  E[\\mathbf{x_{1}'x_{1}}\\right] )^{-1}  E[\\mathbf{x_{1}'}( \\mathbf{x_{1}}\\boldsymbol{\\alpha_{1}} + \\mathbf{x_{2}}\\boldsymbol{\\alpha_{2}} + \\eta )]\\] \\[=\\left (  E[\\mathbf{x_{1}'x_{1}}\\right] )^{-1}  E[\\mathbf{x_{1}'} \\mathbf{x_{1}}\\boldsymbol{\\alpha_{1}} + \\mathbf{x_{1}'x_{2}}\\boldsymbol{\\alpha_{2}} + \\mathbf{x_{1}'}\\eta ]\\] \\[=\\left (  E[\\mathbf{x_{1}'x_{1}}\\right] )^{-1}  E[\\mathbf{x_{1}'} \\mathbf{x_{1}}]\\boldsymbol{\\alpha_{1}} + \\left (  E[\\mathbf{x_{1}'x_{1}}\\right] )^{-1}E[\\mathbf{x_{1}'x_{2}}]\\boldsymbol{\\alpha_{2}} + \\left (  E[\\mathbf{x_{1}'x_{1}}\\right] )^{-1}E[\\mathbf{x_{1}'}\\eta ]\\]"
  },
  {
    "objectID": "slides/regression/index.html#omitted-variables-bias-4",
    "href": "slides/regression/index.html#omitted-variables-bias-4",
    "title": "E655 - Econometrics",
    "section": "Omitted Variables Bias",
    "text": "Omitted Variables Bias\n\\[=\\boldsymbol{\\alpha_{1}} + \\left (  E[\\mathbf{x_{1}'x_{1}}\\right] )^{-1}E[\\mathbf{x_{1}'x_{2}}]\\boldsymbol{\\alpha_{2}}\\]\n\nThe population slope vector on \\(\\mathbf{x_{1}}\\) equals the sum of\n\nThe causal slope vector \\(\\boldsymbol{\\alpha_{1}}\\)\nA bias term containing\n\nthe regression of \\(\\mathbf{x_{2}}\\) on \\(\\mathbf{x_{1}}\\)\nthe slope on \\(\\mathbf{x_{2}}\\) in the structural for \\(y\\)\n\n\nA key lesson here is that a single omitted variable will bias all population slopes \\(\\boldsymbol{\\beta_{1}}\\)\n\nUnless it is unrelated to y\nOr it is uncorrelated with all but one included regressor, and that regressor is uncorrelated with the others"
  },
  {
    "objectID": "slides/matrixrev/index.html",
    "href": "slides/matrixrev/index.html",
    "title": "\nMatrix Review\n",
    "section": "",
    "text": "Matrix Review"
  },
  {
    "objectID": "slides/matrixrev/index.html#introduction-1",
    "href": "slides/matrixrev/index.html#introduction-1",
    "title": "E655 - Econometrics",
    "section": "Introduction",
    "text": "Introduction\n\nUndergrad metrics normally uses scalar notation\n\nMore accessible for students without advanced math background\n\nAt the graduate level, it is often taught using matrix algebra\nSome advantages to matrix notation\n\nMore compact\nEasier to express some estimators\n\nIn this section, we review matrix algebra essentials for econometrics\n\nNot a comprehensive review\n\nWe will switch between scalar and matrix notation in the course\n\nDepending on which is clearer in each context"
  },
  {
    "objectID": "slides/matrixrev/index.html#matrix",
    "href": "slides/matrixrev/index.html#matrix",
    "title": "E655 - Econometrics",
    "section": "Matrix",
    "text": "Matrix\n\nA matrix is a rectangular array of numbers organized in rows and columns\nFor example, matrix \\(\\mathbf{A}\\) with 2 rows and 3 columns could be\n\n\\[\\mathbf{A} =\n\\begin{bmatrix}\n1 & 2  & 3 \\\\\n4 &5 & 6\n\\end{bmatrix}\\]\n\nMore generally, matrix \\(\\mathbf{A}\\) with m rows and n columns is\n\n\\[\\mathbf{A}=\n\\begin{bmatrix}\na_{11}& a_{12} &\\cdots & a_{1n} \\\\\na_{21}& a_{22} &\\cdots & a_{2n} \\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\na_{m1}& a_{m2} &\\cdots & a_{mn}\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/matrixrev/index.html#vectors",
    "href": "slides/matrixrev/index.html#vectors",
    "title": "E655 - Econometrics",
    "section": "Vectors",
    "text": "Vectors\n\nA vector is a matrix with one column or one row\nA row vector \\(\\mathbf{a}\\) with n elements is\n\n\\[\\mathbf{a}=\n\\begin{bmatrix}\na_{1}& a_{2} &\\cdots & a_{n}\n\\end{bmatrix}\\]\n\nA [column vector{.red} \\(\\mathbf{a}\\) with m elements is\n\n\\[\\mathbf{a}=\n\\begin{bmatrix}\na_{1}\\\\\na_{2}\\\\\n\\vdots \\\\\na_{m}\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/matrixrev/index.html#special-matrices",
    "href": "slides/matrixrev/index.html#special-matrices",
    "title": "E655 - Econometrics",
    "section": "Special Matrices",
    "text": "Special Matrices\n\nA Square Matrix has the same number of rows and columns\n\n\\[\\mathbf{A}=\n\\begin{bmatrix}\na_{11}& a_{12} &\\cdots & a_{1m} \\\\\na_{21}& a_{22} &\\cdots & a_{2m} \\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\na_{m1}& a_{m2} &\\cdots & a_{mm}\n\\end{bmatrix}\\]\n\nA Diagonal Matrix is a square matrix with zeroes for all off-diagonal elements\n\n\\[\\mathbf{A}=\n\\begin{bmatrix}\na_{11}& 0&\\cdots & 0 \\\\\n0& a_{22} &\\cdots & 0 \\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\n0& 0&\\cdots & a_{mm}\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/matrixrev/index.html#special-matrices-1",
    "href": "slides/matrixrev/index.html#special-matrices-1",
    "title": "E655 - Econometrics",
    "section": "Special Matrices",
    "text": "Special Matrices\n\nThe Identity Matrix is a square matrix with ones on the diagonal and zeroes on the off-diagonals\n\n\\[\\mathbf{I}=\n\\begin{bmatrix}\n1& 0&\\cdots & 0 \\\\\n0& 1 &\\cdots & 0 \\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\n0& 0&\\cdots & 1\n\\end{bmatrix}\\]\n\nThe Zero Matrix is a matrix with zeroes for all elements\n\n\\[\\mathbf{0}=\n\\begin{bmatrix}\n0& 0&\\cdots & 0 \\\\\n0& 0 &\\cdots & 0 \\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\n0& 0&\\cdots & 0\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/matrixrev/index.html#matrix-addition",
    "href": "slides/matrixrev/index.html#matrix-addition",
    "title": "E655 - Econometrics",
    "section": "Matrix Addition",
    "text": "Matrix Addition\n\nYou can add and subtract matrices with the same dimensions\n\nMatrices with different dimensions are not conformable for addition or subtraction\n\nThe sum of matrices \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\) with dimension \\(m \\times n\\) is\n\n\\[\\mathbf{A} + \\mathbf{B}=\n\\begin{bmatrix}\na_{11}& a_{12} &\\cdots & a_{1n} \\\\\na_{21}& a_{22} &\\cdots & a_{2n} \\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\na_{m1}& a_{m2} &\\cdots & a_{mn}\n\\end{bmatrix}\n+\n\\begin{bmatrix}\nb_{11}& b_{12} &\\cdots & b_{1n} \\\\\nb_{21}& b_{22} &\\cdots & b_{2n} \\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\nb_{m1}& b_{m2} &\\cdots & b_{mn}\n\\end{bmatrix}\\]\n\\[=\n\\begin{bmatrix}\na_{11} + b_{11}& a_{12} + b_{12} &\\cdots & a_{1n}+ b_{1n} \\\\\na_{21} + b_{21}& a_{22} + b_{22} &\\cdots & a_{2n}+ b_{2n} \\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\na_{m1} + b_{m1}& a_{m2} +b_{m2} &\\cdots & a_{mn}+ b_{mn} \\\\\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/matrixrev/index.html#matrix-subtraction",
    "href": "slides/matrixrev/index.html#matrix-subtraction",
    "title": "E655 - Econometrics",
    "section": "Matrix Subtraction",
    "text": "Matrix Subtraction\n\nSimilarly, the difference between matrices \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\) is\n\n\\[\\mathbf{A} - \\mathbf{B}=\n\\begin{bmatrix}\na_{11}& a_{12} &\\cdots & a_{1n} \\\\\na_{21}& a_{22} &\\cdots & a_{2n} \\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\na_{m1}& a_{m2} &\\cdots & a_{mn}\n\\end{bmatrix}\n-\n\\begin{bmatrix}\nb_{11}& b_{12} &\\cdots & b_{1n} \\\\\nb_{21}& b_{22} &\\cdots & b_{2n} \\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\nb_{m1}& b_{m2} &\\cdots & b_{mn}\n\\end{bmatrix}\\]\n\\[=\n\\begin{bmatrix}\na_{11} - b_{11}& a_{12} - b_{12} &\\cdots & a_{1n}- b_{1n} \\\\\na_{21} - b_{21}& a_{22} - b_{22} &\\cdots & a_{2n}- b_{2n} \\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\na_{m1} - b_{m1}& a_{m2} -b_{m2} &\\cdots & a_{mn}- b_{mn} \\\\\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/matrixrev/index.html#rules-for-addition-and-subtraction",
    "href": "slides/matrixrev/index.html#rules-for-addition-and-subtraction",
    "title": "E655 - Econometrics",
    "section": "Rules for Addition and Subtraction",
    "text": "Rules for Addition and Subtraction\n\nThe following rules apply to matrix addition and subtraction\n\nCommutativity \\[\\mathbf{A + B = B + A}\\]\nAssociativity \\[\\mathbf{A + (B + C) = (A+B) + C}\\]\n\nEffectively, both rules mean order does not matter\n\nSimilar to scalar math\n\nFor subtraction, replace plus sign with minus sign and same rules apply"
  },
  {
    "objectID": "slides/matrixrev/index.html#matrix-multiplication",
    "href": "slides/matrixrev/index.html#matrix-multiplication",
    "title": "E655 - Econometrics",
    "section": "Matrix Multiplication",
    "text": "Matrix Multiplication\n\nTo multiply matrix \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\), the number of columns in \\(\\mathbf{A}\\) must equal the number of rows in \\(\\mathbf{B}\\)\nSuppose matrix \\(\\mathbf{A}\\) is \\(m \\times n\\) and matrix \\(\\mathbf{B}\\) is \\(n \\times p\\)\nDefine product as \\(\\mathbf{C}\\)= \\(\\mathbf{AB}\\)\n\nThe \\(ij\\) element of \\(\\mathbf{C}\\) is the sum of the product of the corresponding elements along the \\(i\\)th row of \\(\\mathbf{A}\\) and \\(j\\)th column of \\(\\mathbf{B}\\)\n\\[c_{ij} = \\sum_{k} a_{ik}b_{kj}\\]\nThe product matrix \\(\\mathbf{C}\\) will have dimension \\(m \\times p\\)\n\nThe number of rows of \\(\\textbf{A}\\) and number of columns of \\(\\textbf{B}\\)"
  },
  {
    "objectID": "slides/matrixrev/index.html#matrix-multiplication-1",
    "href": "slides/matrixrev/index.html#matrix-multiplication-1",
    "title": "E655 - Econometrics",
    "section": "Matrix Multiplication",
    "text": "Matrix Multiplication\n\nThe product \\(\\mathbf{AB}\\) is\n\n\\[\\mathbf{AB}=\n    \\begin{bmatrix}\n    a_{11}& a_{12} &\\cdots & a_{1n} \\\\\n    a_{21}& a_{22} &\\cdots & a_{2n} \\\\\n    \\vdots & \\vdots &\\ddots & \\vdots \\\\\n    a_{m1}& a_{m2} &\\cdots & a_{mn}\n    \\end{bmatrix}\n    \\times\n    \\begin{bmatrix}\n    b_{11}& b_{12} &\\cdots & b_{1p} \\\\\n    b_{21}& b_{22} &\\cdots & b_{2p} \\\\\n    \\vdots & \\vdots &\\ddots & \\vdots \\\\\n    b_{n1}& b_{n2} &\\cdots & b_{np}\n    \\end{bmatrix}\\]\n\n\\[=\n\\begin{bmatrix}\na_{11} b_{11} + a_{12} b_{21}  + \\cdots + a_{1n} b_{n1}  &a_{11} b_{12} + a_{12} b_{22}  + \\cdots + a_{1n} b_{n2} &\\cdots&a_{11} b_{1p} + a_{12} b_{2p}  + \\cdots + a_{1n} b_{np}\\\\\na_{21} b_{11} + a_{22} b_{21}  + \\cdots + a_{2n} b_{n1}  &a_{21} b_{12} + a_{22} b_{22}  + \\cdots + a_{2n} b_{n2} &\\cdots&a_{21} b_{1p} + a_{22} b_{2p}  + \\cdots + a_{2n} b_{np}\\\\\n\\vdots &\\ddots & \\vdots \\\\\na_{m1} b_{11} + a_{m2} b_{21}  + \\cdots + a_{mn} b_{n1}  &a_{m1} b_{12} + a_{m2} b_{22}  + \\cdots + a_{mn} b_{n2} &\\cdots&a_{m1} b_{1p} + a_{m2} b_{2p}  + \\cdots + a_{mn} b_{np}\\\\\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/matrixrev/index.html#matrix-multiplication-2",
    "href": "slides/matrixrev/index.html#matrix-multiplication-2",
    "title": "E655 - Econometrics",
    "section": "Matrix Multiplication",
    "text": "Matrix Multiplication\n\nAs an illustration suppose we have the following matrices \\[\\mathbf{A}=\n\\begin{bmatrix}\n1& 2\\\\\n3& 4 \\\\\n\\end{bmatrix}\n\\mathbf{B}=\n\\begin{bmatrix}\n5&6&7  \\\\\n8&9 &10\n\\end{bmatrix}\\]\nWe can multiply \\(\\mathbf{AB}\\) because \\(\\mathbf{A}\\) has 2 columns, and \\(\\mathbf{B}\\) has 2 rows\nThe product \\(\\mathbf{C}\\) = \\(\\mathbf{AB}\\) is\n\n\\[\\mathbf{C}=\n\\begin{bmatrix}\n1& 2\\\\\n3& 4 \\\\\n\\end{bmatrix}\n\\times\n\\begin{bmatrix}\n5&6&7  \\\\\n8&9 &10\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n1 \\times 5 + 2\\times 8&1 \\times 6 + 2 \\times 9 & 1 \\times 7 + 2 \\times 10  \\\\\n3 \\times 5 + 4\\times 8&3 \\times 6 + 4 \\times 9 & 3 \\times 7 + 4 \\times 10  \n\\end{bmatrix}\\]\n\\[=\n\\begin{bmatrix}\n21& 24& 27 \\\\\n47&54&  61\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/matrixrev/index.html#scalar-multiplication",
    "href": "slides/matrixrev/index.html#scalar-multiplication",
    "title": "E655 - Econometrics",
    "section": "Scalar Multiplication",
    "text": "Scalar Multiplication\n\nA scalar is a single real number\nYou can also multiply a scalar by a matrix\nIf \\(\\gamma\\) is a scalar, and \\(\\mathbf{A}\\) is a matrix, then\n\n\\[\\mathbf{\\gamma A}= \\gamma\n\\begin{bmatrix}\na_{11}& a_{12} &\\cdots & a_{1n} \\\\\na_{21}& a_{22} &\\cdots & a_{2n} \\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\na_{m1}& a_{m2} &\\cdots & a_{mn}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\gamma a_{11}&\\gamma  a_{12} &\\cdots & \\gamma a_{1n} \\\\\n\\gamma a_{21}& \\gamma a_{22} &\\cdots & \\gamma a_{2n} \\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\n\\gamma a_{m1}& \\gamma a_{m2} &\\cdots & \\gamma a_{mn}\n\\end{bmatrix}\\]\n\nYou multiply the scalar by each element of the matrix"
  },
  {
    "objectID": "slides/matrixrev/index.html#transpose",
    "href": "slides/matrixrev/index.html#transpose",
    "title": "E655 - Econometrics",
    "section": "Transpose",
    "text": "Transpose\n\nThe transpose of a matrix is one where the rows and columns are switched\nSuppose matrix \\(\\mathbf{A}\\) is\n\n\\[\\mathbf{A}=\n    \\begin{bmatrix}\n    a_{11}& a_{12} &\\cdots & a_{1n} \\\\\n    a_{21}& a_{22} &\\cdots & a_{2n} \\\\\n    \\vdots & \\vdots &\\ddots & \\vdots \\\\\n    a_{m1}& a_{m2} &\\cdots & a_{mn}\n    \\end{bmatrix}\\]\n\nThen its transpose \\(\\mathbf{A'}\\) is\n\n\\[\\mathbf{A'}=\n\\begin{bmatrix}\na_{11}& a_{21} &\\cdots & a_{m1} \\\\\na_{12}& a_{22} &\\cdots & a_{m2} \\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\na_{1n}& a_{2n} &\\cdots & a_{mn}\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/matrixrev/index.html#transpose-1",
    "href": "slides/matrixrev/index.html#transpose-1",
    "title": "E655 - Econometrics",
    "section": "Transpose",
    "text": "Transpose\n\nThe transpose has the following properties\n\n\\[\\mathbf{(A')' = A }\\] \\[\\mathbf{(\\alpha A)' = \\alpha A' }\\] \\[\\mathbf{(A + B)' = A' + B' }\\] \\[\\mathbf{(AB)' = B'A' }\\]\n\nThere are additional rules for different types of matrices that we will cover below"
  },
  {
    "objectID": "slides/matrixrev/index.html#partitioned-matrix-multiplication",
    "href": "slides/matrixrev/index.html#partitioned-matrix-multiplication",
    "title": "E655 - Econometrics",
    "section": "Partitioned Matrix Multiplication",
    "text": "Partitioned Matrix Multiplication\n\nYou may sometimes want to break matrices into vectors before you multiply\nMultiplication works the same way, but notation can be cleaner and more intuitive\nSuppose we have the following matrices \\[\\mathbf{A}=\n\\begin{bmatrix}\na_{11}& a_{12} &\\cdots & a_{1n} \\\\\na_{21}& a_{22} &\\cdots & a_{2n} \\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\na_{m1}& a_{m2} &\\cdots & a_{mn}\n\\end{bmatrix}\n\\mathbf{B}=\n\\begin{bmatrix}\nb_{11}& b_{12} &\\cdots & b_{1p} \\\\\nb_{21}& b_{22} &\\cdots & b_{2p} \\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\nb_{n1}& b_{n2} &\\cdots & b_{np}\n\\end{bmatrix}\\]\nWe are interested in the product \\(\\mathbf{AB}\\)"
  },
  {
    "objectID": "slides/matrixrev/index.html#partitioned-matrix-multiplication-1",
    "href": "slides/matrixrev/index.html#partitioned-matrix-multiplication-1",
    "title": "E655 - Econometrics",
    "section": "Partitioned Matrix Multiplication",
    "text": "Partitioned Matrix Multiplication\n\nBreak these matrices into vectors conformable for multiplication\n\n\\[\\mathbf{A}=\n\\begin{bmatrix}\n\\mathbf{a_{1}}&\\mathbf{a_{2}} & \\cdots & \\mathbf{a_{n}}\n\\end{bmatrix}\n\\mathbf{B}=\n\\begin{bmatrix}\n\\mathbf{b_{1}}\\\\\n\\mathbf{b_{2} }\\\\\n\\vdots  \\\\\n\\mathbf{b_{n}}\n\\end{bmatrix}\\]\n\nWhere\n\n\\[\\mathbf{a_{1}}=\n\\begin{bmatrix}\na_{11}\\\\\na_{21}\\\\\n\\cdots\\\\\na_{m1}\n\\end{bmatrix}\n\\mathbf{b_{1}}=\n\\begin{bmatrix}\nb_{11}&b_{12} & \\cdots & b_{1p}\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/matrixrev/index.html#partitioned-matrix-multiplication-2",
    "href": "slides/matrixrev/index.html#partitioned-matrix-multiplication-2",
    "title": "E655 - Econometrics",
    "section": "Partitioned Matrix Multiplication",
    "text": "Partitioned Matrix Multiplication\n\nMultiply the vectors to get\n\n\\[\\mathbf{AB} = \\sum_{i=1}^{n} \\mathbf{a_{i}b_{i}}\\]\n\nThis breaks the product \\(\\mathbf{AB}\\) into the sum of \\(n\\) sub-matrices\n\nEach sub-matrix is product of corresponding vectors\nAlso each sub-matrix will have dimension \\(m \\times p\\)\n\nThis will be useful for some econometric estimators we derive\n\nMakes notation simpler and more intuitive\n\nAgain, note that you get the same answer as doing straight matrix multiplication"
  },
  {
    "objectID": "slides/matrixrev/index.html#rules-for-matrix-multiplication",
    "href": "slides/matrixrev/index.html#rules-for-matrix-multiplication",
    "title": "E655 - Econometrics",
    "section": "Rules for Matrix Multiplication",
    "text": "Rules for Matrix Multiplication\n\nThere are several useful properties for matrix (and scalar) multiplication\n\n\\[(\\alpha + \\beta)\\mathbf{A} = \\alpha \\mathbf{A} + \\beta\\mathbf{A}\\] \\[\\alpha (\\mathbf{A} +\\mathbf{B}) =\\alpha \\mathbf{A} +\\alpha\\mathbf{B}\\] \\[(\\alpha\\beta) \\mathbf{A}  =\\alpha(\\beta \\mathbf{A})\\] \\[\\alpha (\\mathbf{A}\\mathbf{B}) =(\\alpha \\mathbf{A}) \\mathbf{B}\\] \\[(\\mathbf{A}\\mathbf{B} )\\mathbf{C} =\\mathbf{A}(\\mathbf{B} \\mathbf{C})\\] \\[\\mathbf{A}(\\mathbf{B} +\\mathbf{C}) =\\mathbf{A}\\mathbf{B} +\\mathbf{A} \\mathbf{C}\\] \\[(\\mathbf{A}+\\mathbf{B} )\\mathbf{C} =\\mathbf{A}\\mathbf{C} +\\mathbf{B} \\mathbf{C}\\] \\[\\mathbf{A}\\mathbf{I}  =\\mathbf{I}\\mathbf{A} = \\mathbf{A}\\] \\[\\mathbf{A}\\mathbf{0}  =\\mathbf{0}\\mathbf{A} = \\mathbf{0}\\] \\[\\mathbf{A}\\mathbf{B}  \\neq\\mathbf{B}\\mathbf{A}\\] —"
  },
  {
    "objectID": "slides/matrixrev/index.html#trace",
    "href": "slides/matrixrev/index.html#trace",
    "title": "E655 - Econometrics",
    "section": "Trace",
    "text": "Trace\n\nThe trace of a square matrix is the sum of the diagonal elements\nIf square matrix \\(\\mathbf{A}\\) is\n\n\\[\\mathbf{A}=\n    \\begin{bmatrix}\n    a_{11}& a_{12} &\\cdots & a_{1n} \\\\\n    a_{21}& a_{22} &\\cdots & a_{2n} \\\\\n    \\vdots & \\vdots &\\ddots & \\vdots \\\\\n    a_{n1}& a_{n2} &\\cdots & a_{nn}\n    \\end{bmatrix}\\]\n\nThen its trace is\n\n\\[tr(\\mathbf{A})= \\sum_{i=1}^{n} a_{ii}\\]"
  },
  {
    "objectID": "slides/matrixrev/index.html#trace-1",
    "href": "slides/matrixrev/index.html#trace-1",
    "title": "E655 - Econometrics",
    "section": "Trace",
    "text": "Trace\n\nImportant properties of the trace are\n\n\\[tr(\\mathbf{I_{n}})= n\\] \\[tr(\\mathbf{A}')=tr(\\mathbf{A})\\] \\[tr(\\mathbf{A +B})=tr(\\mathbf{A}) + tr(\\mathbf{B})\\] \\[tr(\\alpha \\mathbf{A})=\\alpha tr(\\mathbf{A})\\] \\[tr(\\mathbf{AB})=tr(\\mathbf{BA})\\]"
  },
  {
    "objectID": "slides/matrixrev/index.html#marix-determinant",
    "href": "slides/matrixrev/index.html#marix-determinant",
    "title": "E655 - Econometrics",
    "section": "Marix Determinant",
    "text": "Marix Determinant\n\nThe determinant is a scalar value associated with a square matrix\n\nHelpful concept for several things in matrix algebra\nFor econometrics, most useful for solving systems of equations and finding inverse of a matrix\n\nFor \\(2 \\times 2\\) matrix \\(\\mathbf{A}\\) \\[\\mathbf{A}=\n\\begin{bmatrix}\na_{11}& a_{12} \\\\\na_{21}& a_{22}  \\\\\n\\end{bmatrix}\\]\nThe determinant is\n\n\\[|\\mathbf{A}|=a_{11}a_{22} - a_{12}a_{21}\\]"
  },
  {
    "objectID": "slides/matrixrev/index.html#marix-determinant-1",
    "href": "slides/matrixrev/index.html#marix-determinant-1",
    "title": "E655 - Econometrics",
    "section": "Marix Determinant",
    "text": "Marix Determinant\n\nFor \\(3 \\times 3\\) matrix \\(\\mathbf{A}\\)\n\n\\[\\mathbf{A}=\n\\begin{bmatrix}\na_{11}& a_{12} & a_{13} \\\\\na_{21}& a_{22} & a_{23} \\\\\na_{31}& a_{32} & a_{33} \\\\\n\\end{bmatrix}\\]\n\nThe determinant is\n\n\\[|\\mathbf{A}|=a_{11}a_{22}a_{33} + a_{12}a_{23}a_{31} +a_{13}a_{21}a_{32}\\] \\[-(a_{12}a_{21}a_{33} + a_{11}a_{23}a_{32} +a_{13}a_{22}a_{31})\\]\n\\[=a_{11}(a_{22}a_{33} - a_{23}a_{32}) + a_{12}(a_{23}a_{31} -a_{21}a_{33} )  +a_{13}(a_{21}a_{32} - a_{22}a_{31} )\\]"
  },
  {
    "objectID": "slides/matrixrev/index.html#marix-determinant-2",
    "href": "slides/matrixrev/index.html#marix-determinant-2",
    "title": "E655 - Econometrics",
    "section": "Marix Determinant",
    "text": "Marix Determinant\n\nFor \\(n \\times n\\) matrix \\(\\mathbf{A}\\) the determinant is\n\n\\[|\\mathbf{A}|=a_{i1}c_{i1} + a_{i2}c_{i2} + \\cdots + a_{in}c_{in} \\text{   for choice of any row i}\\]\n\nWhere\n\n\\(a_{ij}\\) is the \\(ij\\) element of matrix \\(\\mathbf{A}\\)\n\\(c_{ij}\\) is the \\(ij\\) cofactor of matrix \\(\\mathbf{A}\\) defined as \\[c_{ij} = (-1)^{i+j}|\\mathbf{A}_{ij}|\\]\n\\(|\\mathbf{A}_{ij}|\\) is the minor of matrix \\(\\mathbf{A}\\)\n\nDeterminant of the sub-matrix formed by deleting the \\(i\\)th row and \\(j\\)th column of \\(\\mathbf{A}\\)\n\n\nProcess is long and tedious for large matrices"
  },
  {
    "objectID": "slides/matrixrev/index.html#marix-determinant-3",
    "href": "slides/matrixrev/index.html#marix-determinant-3",
    "title": "E655 - Econometrics",
    "section": "Marix Determinant",
    "text": "Marix Determinant\n\nExample of \\(3 \\times 3\\) matrix\n\n\\[\\mathbf{A}=\n\\begin{bmatrix}\n1& 2 & 3 \\\\\n4& 5&6   \\\\\n7& 8 &9  \n\\end{bmatrix}\\]\n\nChoose any row to find cofactors and compute determinant\n\nDoes not matter which\n\nLet us expand along row 1\n\n\\[|\\mathbf{A}|=1(-1)^{1+1}\n\\begin{vmatrix}\n  5&6   \\\\\n8 &9  \n\\end{vmatrix}\n+2(-1)^{1+2}\n\\begin{vmatrix}\n  4&6   \\\\\n7 &9  \n\\end{vmatrix}\n+3(-1)^{1+3}\n\\begin{vmatrix}\n  4&5   \\\\\n7 &8  \n\\end{vmatrix}\\]\n\\[|\\mathbf{A}|= -3 +12 -9 = 0\\]"
  },
  {
    "objectID": "slides/matrixrev/index.html#matrix-inverse",
    "href": "slides/matrixrev/index.html#matrix-inverse",
    "title": "E655 - Econometrics",
    "section": "Matrix Inverse",
    "text": "Matrix Inverse\n\nThe inverse of a square matrix \\(\\mathbf{A}\\) is defined such that\n\n\\[\\mathbf{A}\\mathbf{A}^{-1} = \\mathbf{A}^{-1}\\mathbf{A} = \\mathbf{I}\\]\n\nIt is roughly the equivalent of taking the reciprocal in scalar math\n\nBut it is not generally the reciprocal of the elements of a matrix\n\nThe formula for the inverse is\n\n\\[\\mathbf{A}^{-1}= \\frac{1}{|\\mathbf{A}|}\n\\begin{bmatrix}\nc_{11}& c_{12} &\\cdots & c_{1n} \\\\\nc_{21}& c_{22} &\\cdots & c_{2n} \\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\nc_{n1}& c_{n2} &\\cdots & c_{nn}\n\\end{bmatrix}\\]\n\nwhere \\(c_{ij}\\) are the cofactors defined above"
  },
  {
    "objectID": "slides/matrixrev/index.html#matrix-inverse-1",
    "href": "slides/matrixrev/index.html#matrix-inverse-1",
    "title": "E655 - Econometrics",
    "section": "Matrix Inverse",
    "text": "Matrix Inverse\n\nThe inverse exists only when \\(|\\mathbf{A}| \\neq 0\\)\n\nThis is why it is important to know the determinant\nIn example above, inverse does not exist\n\nWe will see later that it is because the columns are linearly dependent\n\n\nA matrix that cannot be inverted is singular\nA matrix that has an inverse is nonsingular\nInverse matrices have the following properties\n\n\\[\\mathbf{(\\alpha A)^{-1} = \\frac{1}{\\alpha} A^{-1} }\\] \\[\\mathbf{(A')^{-1}} = \\mathbf{(A^{-1})' }\\] \\[\\mathbf{(A^{-1})^{-1}} = \\mathbf{A}\\] \\[\\mathbf{(AB)^{-1}= B^{-1}A^{-1} }\\]"
  },
  {
    "objectID": "slides/matrixrev/index.html#summary",
    "href": "slides/matrixrev/index.html#summary",
    "title": "E655 - Econometrics",
    "section": "Summary",
    "text": "Summary\n\nNow that we can manipulate matrices, we can move to more advanced topics\nMatrix algebra is useful for expressing and solving systems of equations\n\nThis is how we will use it in econometrics\n\nWe will learn you can solve for the OLS estimator when regressors are linearly independent\n\nThey are not linear functions of one another\n\nTo check linear independence, we use the concept of rank\nThe rank of a matrix is the maximum number of independent rows or columns\n\nFor non-square matrices, the maximum rank is the lesser of the number or rows or columns"
  },
  {
    "objectID": "slides/matrixrev/index.html#linear-independence",
    "href": "slides/matrixrev/index.html#linear-independence",
    "title": "E655 - Econometrics",
    "section": "Linear Independence",
    "text": "Linear Independence\n\nA set of vectors are linearly independent if you cannot express any of them as linear functions the others\nMathematically, suppose that \\(\\mathbf{A}=\\begin{bmatrix} \\mathbf{a}_{1}& \\mathbf{a}_{2} &\\cdots & \\mathbf{a}_{m} \\end{bmatrix}\\)\n\nwhere \\(\\mathbf{a}_{1}, \\mathbf{a}_{2}, \\cdots,\\mathbf{a}_{m}\\) are \\(n \\times 1\\) vectors\n\nThe vectors are independent if the only solution to\n\n\\[\\alpha_{1}\\mathbf{a}_{1}+ \\alpha_{2}\\mathbf{a}_{2}+ \\cdots+\\alpha_{n}\\mathbf{a}_{n}= 0\\]\n\nis\n\n\\[\\alpha_{1} = \\alpha_{2}= \\cdots=\\alpha_{n}= 0\\]\n\nIf at least one \\(\\alpha_{i} \\neq 0\\), then the vectors are linearly dependent"
  },
  {
    "objectID": "slides/matrixrev/index.html#rank-of-a-matrix",
    "href": "slides/matrixrev/index.html#rank-of-a-matrix",
    "title": "E655 - Econometrics",
    "section": "Rank of a Matrix",
    "text": "Rank of a Matrix\n\nThe rank of a matrix is the maximum number of linearly independent rows or columns\n\nThe rank of the rows will always equal the rank of the columns\nIf the number of rows is less than columns, the highest rank is the number of rows\nVice versa if the number of columns is less than the number of rows\n\nA matrix has full rank if rank equals the minimum of the number of rows/columns\nIn econometrics, we mostly deal with matrices with more rows than columns\n\nSo the matrix will be full rank if the rank equals the number of columns\n\nWe will see later we need our matrix of regressors to have full rank\n\nNone of the regressors can be linear functions of each other (no multicollinearity)"
  },
  {
    "objectID": "slides/matrixrev/index.html#rank-of-a-matrix-1",
    "href": "slides/matrixrev/index.html#rank-of-a-matrix-1",
    "title": "E655 - Econometrics",
    "section": "Rank of a Matrix",
    "text": "Rank of a Matrix\n\nSome useful properties of the rank of a matrix\n\nThe rank of a matrix and transpose are the same \\[rank(\\mathbf{A'}) = rank(\\mathbf{A})\\]\nIf \\(\\mathbf{A}\\) is \\(m \\times n\\) then \\[rank(\\mathbf{A}) \\le min(m,n)\\]\nIf \\(\\mathbf{A}\\) is \\(n \\times n\\) and \\(rank(\\mathbf{A}) =n\\) then \\(\\mathbf{A}\\) is nonsingular (invertible)"
  },
  {
    "objectID": "slides/matrixrev/index.html#quadratic-form",
    "href": "slides/matrixrev/index.html#quadratic-form",
    "title": "E655 - Econometrics",
    "section": "Quadratic Form",
    "text": "Quadratic Form\n\nIf \\(\\mathbf{A}\\) is \\(n \\times n\\) and symmetric, and \\(\\mathbf{x}\\) is \\(n \\times 1\\), the quadratic form for \\(\\mathbf{A}\\) is\n\n\\[\\mathbf{x'Ax}=\n\\begin{bmatrix}\nx_{1}& x_{2} &\\cdots & x_{n}\n\\end{bmatrix}\n\\begin{bmatrix}\na_{11}& a_{12} &\\cdots & a_{1n} \\\\\na_{21}& a_{22} &\\cdots & a_{2n} \\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\na_{n1}& a_{n2} &\\cdots & a_{nn}\n\\end{bmatrix}\n\\begin{bmatrix}\nx_{1}\\\\\nx_{2} \\\\\n\\vdots \\\\\n  x_{n}\n\\end{bmatrix}\\]\n\\[=\\sum_{i=1}^n a_{ii}x_{i}^2 + 2\\sum_{i=1}^n \\sum_{j&gt;i}a_{ij}x_{i}x_{j}\\]\n\nA matrix is positive definite if for all \\(\\mathbf{x} \\neq 0\\)\n\n\\[\\mathbf{x'Ax} &gt; 0\\]"
  },
  {
    "objectID": "slides/matrixrev/index.html#positive-definite-matrices",
    "href": "slides/matrixrev/index.html#positive-definite-matrices",
    "title": "E655 - Econometrics",
    "section": "Positive Definite Matrices",
    "text": "Positive Definite Matrices\n\nA matrix is positive semidefinite if for all \\(\\mathbf{x} \\neq 0\\)\n\n\\[\\mathbf{x'Ax} \\ge 0\\]\n\nPositive definite matrices have diagonal elements that are strictly positive\nPositive semidefinite matrices have diagonal elements that are nonnegative\nSome other useful properties of positive definite/semidefinite matrices\n\nIf \\(\\mathbf{A}\\) is positive definite, then \\(\\mathbf{A}^{-1}\\) exists and is also positive definite\nIf \\(\\mathbf{A}\\) is \\(n \\times m\\), then \\(\\mathbf{A'A}\\) and \\(\\mathbf{AA'}\\) are positive definite\nIf \\(\\mathbf{A}\\) is \\(n \\times m\\) and \\(rank(\\mathbf{A}) = m\\) then \\(\\mathbf{A'A}\\) is positive definite\n\nThese concepts are used mostly for variance-covariance matrices in econometrics"
  },
  {
    "objectID": "slides/matrixrev/index.html#idempotent-matrices",
    "href": "slides/matrixrev/index.html#idempotent-matrices",
    "title": "E655 - Econometrics",
    "section": "Idempotent Matrices",
    "text": "Idempotent Matrices\n\nAn idempotent matrix is one that does not change when multiplied by itself\nMathematically, \\(\\mathbf{A}\\) is idempotent when\n\n\\[\\mathbf{AA} = \\mathbf{A}\\]\n\nWhen we discuss OLS, we will work with the following idempotent matrices\n\nSuppose \\(\\mathbf{X}\\) is \\(n \\times k\\) with full rank. Define\n\n\n\\[\\mathbf{P} = \\mathbf{X(X'X)^{-1}X'}\\] \\[\\mathbf{M} =\\mathbf{I_{n}} - \\mathbf{X(X'X)^{-1}X'}\\]\n\nYou can verify they are idempotent my multiplying each by itself\nSome important properties of idempotent matrices are\n\n\\(rank(\\mathbf{A}) = tr(\\mathbf{A})\\)\n\\(\\mathbf{A}\\) is positive semidefinite"
  },
  {
    "objectID": "slides/matrixrev/index.html#expected-value",
    "href": "slides/matrixrev/index.html#expected-value",
    "title": "E655 - Econometrics",
    "section": "Expected Value",
    "text": "Expected Value\n\nThe expected value of a random matrix is the matrix of expected values\nIf \\(\\mathbf{X}\\) is an \\(n \\times m\\) matrix, then\n\n\\[\\mathbf{E}(\\mathbf{X})=\n\\begin{bmatrix}\n\\mathbf{E}(x_{11}) & \\mathbf{E}(x_{12}) & \\cdots & \\mathbf{E}(x_{1m})\\\\\n\\mathbf{E}(x_{21}) & \\mathbf{E}(x_{22}) & \\cdots &\\mathbf{E}(x_{2m})\\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\n\\mathbf{E}(x_{n1}) & \\mathbf{E}(x_{n2}) & \\cdots &\\mathbf{E}(x_{nm})\\\\\n\\end{bmatrix}\\]\n\nProperties of expected values are similar to those in scalar math\n\nIf \\(\\mathbf{x}\\) is a random vector, \\(\\mathbf{b}\\) is a nonrandom vector, and \\(\\mathbf{A}\\) is a nonrandom matrix, then \\(\\mathbf{E}(\\mathbf{Ax+b}) = \\mathbf{A}\\mathbf{E}(\\mathbf{x})+\\mathbf{b}\\)\nIf \\(\\mathbf{X}\\) is a random matrix, and \\(\\mathbf{B}\\) and \\(\\mathbf{A}\\) are nonrandom matrices, then \\(\\mathbf{E}(\\mathbf{AXB}) = \\mathbf{A}\\mathbf{E}(\\mathbf{X})\\mathbf{B}\\)"
  },
  {
    "objectID": "slides/matrixrev/index.html#variance-covariance-matrix",
    "href": "slides/matrixrev/index.html#variance-covariance-matrix",
    "title": "E655 - Econometrics",
    "section": "Variance-Covariance Matrix",
    "text": "Variance-Covariance Matrix\n\nThe variance-covariance matrix of random vector \\(\\mathbf{y}\\) has variances on the diagonal, covariances in the off-diagonal\nIf \\(\\mathbf{y}\\) is an \\(n \\times 1\\) random vector, then\n\n\\[var(\\mathbf{y})= \\mathbf{\\sigma_{y}} = \\mathbf{E[(y-E[y])(y-E[y])']}\\] \\[=\n\\begin{bmatrix}\n\\text{var}(y_{1}) & \\text{cov}(y_{1},y_{2}) & \\cdots &\\text{cov}(y_{1},y_{n}) \\\\\n\\text{cov}(y_{2},y_{1}) & \\text{var}(y_{2}) & \\cdots &\\text{cov}(y_{2},y_{n}) \\\\\n\\vdots & \\vdots &\\ddots & \\vdots \\\\\n\\text{cov}(y_{n},y_{1})  & \\text{cov}(y_{n},y_{2}) & \\cdots &\\text{var}(y_{n})\\\\\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/matrixrev/index.html#variance-covariance-matrix-1",
    "href": "slides/matrixrev/index.html#variance-covariance-matrix-1",
    "title": "E655 - Econometrics",
    "section": "Variance-Covariance Matrix",
    "text": "Variance-Covariance Matrix\n\nUseful properties of variance-covariance matrices are\n\nIf \\(\\mathbf{a}\\) is a nonrandom vector, then \\(\\text{var}(\\mathbf{a'y}) =\\mathbf{a'}\\text{var}\\mathbf{(y)a}\\)\nIf \\(\\text{var}(\\mathbf{a'y})&gt;0\\) for all \\(\\mathbf{a&gt;0}\\), \\(\\text{var}(\\mathbf{y})\\) is positive definite\nIf \\(\\mathbf{A}\\) is a nonrandom matrix, \\(\\mathbf{b}\\) is a nonrandom vector, then \\(\\text{var}(\\mathbf{Ay + b}) =\\mathbf{A'}\\text{var}\\mathbf{(y)A}\\)\nIf \\(\\text{var}(y_{j})=\\sigma^{2}\\) for all \\(j=1,2,...,n\\), and the elements of \\(\\textbf{y}\\) are uncorrelated, then \\(\\text{var}(\\mathbf{y})=\\sigma^{2}\\mathbf{I_{n}}\\)"
  },
  {
    "objectID": "slides/matrixrev/index.html#scalar-functions",
    "href": "slides/matrixrev/index.html#scalar-functions",
    "title": "E655 - Econometrics",
    "section": "Scalar Functions",
    "text": "Scalar Functions\n\nA scalar function of a vector is a single function with respect to several variables\n\nA vector function is a set of one or more scalar functions, each with respect to several variables -&gt; we will not discuss these\n\nConsider the scalar function \\(y = f(\\mathbf{x}) =f(x_{1}, x_{2},...,x_{n})\\)\n\nThe function takes the vector \\(\\mathbf{x}\\) and returns a scalar\nThis is just another way to write a multivariate function\n\nThe derivative of this function is\n\n\\[\\frac{\\partial f(\\mathbf{x})}{\\mathbf{x}}=\n\\begin{bmatrix}\n\\frac{\\partial f(\\mathbf{x})}{x_{1}} & \\frac{\\partial f(\\mathbf{x})}{x_{2}} & \\cdots & \\frac{\\partial f(\\mathbf{x})}{x_{n}}  \n\\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/matrixrev/index.html#derivative-of-scalar-function",
    "href": "slides/matrixrev/index.html#derivative-of-scalar-function",
    "title": "E655 - Econometrics",
    "section": "Derivative of Scalar Function",
    "text": "Derivative of Scalar Function\n\nWe simply collect the derivative with respect to each element of \\(\\mathbf{x}\\) in a vector\nEx: linear function of \\(\\mathbf{x}\\)\n\nSuppose \\(\\mathbf{a}\\) is an \\(n \\times 1\\) vector and \\[y = f(\\mathbf{x}) = \\mathbf{a'x} = \\sum_{i=1}^{n} a_{i}x_{i}\\]\nThe derivative is\n\n\\[\\frac{\\partial f(\\mathbf{x})}{\\partial \\mathbf{x}}=\\frac{\\partial \\mathbf{a'x} }{\\partial \\mathbf{x}}= \\mathbf{a'} =\n    \\begin{bmatrix}\n    a_{1}& a_{2}& \\cdots & a_{n}\n    \\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/matrixrev/index.html#derivative-of-scalar-function-1",
    "href": "slides/matrixrev/index.html#derivative-of-scalar-function-1",
    "title": "E655 - Econometrics",
    "section": "Derivative of Scalar Function",
    "text": "Derivative of Scalar Function\n\nEx: Quadratic form of \\(\\mathbf{x}\\)\n\nSuppose \\(\\mathbf{A}\\) is an \\(n \\times n\\) symmetric matrix. The quadratic form is \\[y = f(\\mathbf{x}) = \\mathbf{x'Ax} =\\sum_{i=1}^n a_{ii}x_{i}^2 + 2\\sum_{i=1}^n \\sum_{j&gt;i}a_{ij}x_{i}x_{j}\\]\nThe derivative is \\[\\frac{\\partial f(\\mathbf{x})}{\\partial \\mathbf{x}}=\\frac{\\partial \\mathbf{x'Ax} }{\\partial \\mathbf{x}}= \\mathbf{2x'A}\\]"
  },
  {
    "objectID": "slides/matrixrev/index.html#population-regression-model",
    "href": "slides/matrixrev/index.html#population-regression-model",
    "title": "E655 - Econometrics",
    "section": "Population Regression Model",
    "text": "Population Regression Model\n\nIn undergraduate textbooks, the population linear regression model is written as\n\n\\[y= \\beta_{0} + \\beta_{1}x_{1} + \\beta_{2}x_{2} + \\cdots + \\beta_{k}x_{k} + u\\]\n\n\\(y\\) and \\(x_{1},...,x_{k}\\) are observable random variables\n\\(u\\) is an unobservable random variable\nWe can write more compactly in vector form as\n\n\\[y=  \\mathbf{x}\\boldsymbol{\\beta}  + u\\]\n\n\\(\\mathbf{x}\\) is a \\(1 \\times (k+1)\\) vector of independent variables\n\nThere are \\(k\\) independent variables, plus an intercept\n\n\\(\\boldsymbol{\\beta}\\) is a \\((k+1) \\times 1\\) vector of slope parameters"
  },
  {
    "objectID": "slides/matrixrev/index.html#population-regression-model-1",
    "href": "slides/matrixrev/index.html#population-regression-model-1",
    "title": "E655 - Econometrics",
    "section": "Population Regression Model",
    "text": "Population Regression Model\n\nNow suppose we take a random sample of \\(n\\) people from the population\nThe population model holds for each member of the sample\n\n\\[y_{i}=  \\mathbf{x_{i}}\\boldsymbol{\\beta}  + u_{i}, \\forall i=1,...,n\\]\n\nWe can express this more compactly with full matrix notation\n\n\\[\\mathbf{y}=  \\mathbf{X}\\boldsymbol{\\beta}  + \\mathbf{u}\\]\n\n\\(\\mathbf{X}\\) is an \\(n \\times (k+1)\\) matrix of observations on each regressor\n\\(\\boldsymbol{\\beta}\\) is still a \\((k+1) \\times 1\\) vector of slope parameters\n\\(\\mathbf{y}\\) is an \\(n \\times 1\\) vector of observations on the dependent variable\n\\(\\mathbf{u}\\) is an \\(n \\times 1\\) vector of error terms"
  },
  {
    "objectID": "content/regression.html#other-resources",
    "href": "content/regression.html#other-resources",
    "title": "Regression",
    "section": "Other Resources",
    "text": "Other Resources"
  },
  {
    "objectID": "slides/regression/index.html#motivation",
    "href": "slides/regression/index.html#motivation",
    "title": "E655 - Econometrics",
    "section": "Motivation",
    "text": "Motivation\n\nWe can use linear regression to approximate CEF. Why?\n\nIf the CEF is linear, it is equivalent to population regression function\nThe population regression function is the best linear predictor of \\(y\\) given \\(\\mathbf{x}\\)\nThe population regression function is the best linear approximation to the CEF\n\nThis is partly why linear regression is popular in economics\nNext section examines population regression\n\nWe will cover estimation of the population regression with a sample later\n\n\n\n\n\n\n\n\nNote\n\n\nMost undergrad classes do not derive the population regression slope and instead skip directly to estimation with a sample, so this may be new. It is important to understand that at this point there is no data; we are only talking about features of the population. As you will see later, the population and sample regression functions are closely related."
  },
  {
    "objectID": "slides/regression/index.html#population-regression-function",
    "href": "slides/regression/index.html#population-regression-function",
    "title": "E655 - Econometrics",
    "section": "Population Regression Function",
    "text": "Population Regression Function\n\nA linear model relating \\(y\\) to explanatory variables \\(\\mathbf{x}\\) is\n\n\\[y = \\mathbf{x}\\boldsymbol{\\beta} + u\\]\n\nWhere\n\n\\(y\\) is a scalar observable random outcome variable\n\\(\\mathbf{x}\\) is a \\(1\\times (k + 1)\\) vector of random explanatory factors\n\\(\\boldsymbol{\\beta}\\) is a \\((k + 1) \\times 1\\) vector of slope parameters (non-random)\n\\(u\\) is a scalar population residual term\n\n\\(\\mathbf{x}\\boldsymbol{\\beta}\\) is called the Population Regression Function (PRF)\n\nThe part of \\(y\\) that is predictable by \\(\\mathbf{x}\\)"
  },
  {
    "objectID": "slides/regression/index.html#population-regression-function-1",
    "href": "slides/regression/index.html#population-regression-function-1",
    "title": "E655 - Econometrics",
    "section": "Population Regression Function",
    "text": "Population Regression Function\n\nUse the PRF to approximate the CEF\nIf CEF is linear, PRF equals CEF\n\nTrue when model is “saturated” or when variables are joint Normal\n\nStill useful to use PRF if CEF is not linear\n\nGoal is capture essential features of relationship\n\n\n\n\n\n\n\n\nSaturated Models\n\n\nA saturated model is one where the independent variables are discrete, and there is a dummy variable for each possible value it can take. For example if you regress wages on gender, a (saturated) CEF is\n\\[E[wage|female] = \\alpha + \\beta female\\]\nwhere \\(\\alpha = E[wage|female = 0]\\) and \\(\\beta =E[wage|female = 1] - E[wage|female = 0]\\)"
  },
  {
    "objectID": "slides/regression/index.html#population-regression-slope-vector-5",
    "href": "slides/regression/index.html#population-regression-slope-vector-5",
    "title": "E655 - Econometrics",
    "section": "Population Regression Slope Vector",
    "text": "Population Regression Slope Vector\n\nIf we observed the population we could compute \\(\\boldsymbol{\\beta}\\)\nProblem again is we do not observe the population\nSo we cannot compute \\(\\textbf{E}[\\mathbf{x}'y]\\) or \\((\\textbf{E}[\\mathbf{x'x}])^{-1}\\)\nInstead, we collect a sample of data and estimate \\(\\boldsymbol{\\beta}\\)\nBefore we do that, we briefly discuss causality in regression models"
  },
  {
    "objectID": "slides/regression/index.html#properties-of-population-regression",
    "href": "slides/regression/index.html#properties-of-population-regression",
    "title": "E655 - Econometrics",
    "section": "Properties of Population Regression",
    "text": "Properties of Population Regression\n\nThe first order condition from minimizing the MSPE by choosing \\(\\boldsymbol{\\beta}\\) is\n\n\\[\\textbf{E}[\\mathbf{x}'(y-\\mathbf{x}\\boldsymbol{\\beta})]= \\mathbf{0}\\]\n\nThis is the same as saying\n\n\\[\\textbf{E}[\\mathbf{x}'u]=\\mathbf{0}\\]\n\nExpanding that equation, we get\n\n\\[\\begin{bmatrix}\n    \\textbf{E}(u)\\\\\n    \\textbf{E}(x_{1}u)\\\\\n    \\vdots\\\\\n    \\textbf{E}(x_{k}u)\n    \\end{bmatrix}\n    =\\mathbf{0}\\]"
  },
  {
    "objectID": "slides/regression/index.html#properties-of-population-regression-1",
    "href": "slides/regression/index.html#properties-of-population-regression-1",
    "title": "E655 - Econometrics",
    "section": "Properties of Population Regression",
    "text": "Properties of Population Regression\n\n\\(\\textbf{E}[\\mathbf{x}'u]=\\mathbf{0}\\) says two important things\n\nThe average value of the population residual \\(u\\) is zero\nThe covariance between each \\(x\\) and \\(u\\) is zero\n\nTo see the covariance part\n\n\\[\\text{cov}(x_{1},u) = \\mathbf{E}[(x_{1} -  \\mathbf{E}(x_{1}))(u -  \\mathbf{E}(u))]\\]\n\nFrom above, we know that \\(\\mathbf{E}(u) =0\\), so\n\n\\[\\text{cov}(x_{1},u) = \\mathbf{E}[x_{1}u -  \\mathbf{E}(x_{1})u]\\]"
  },
  {
    "objectID": "slides/regression/index.html#linear-cef-and-regression",
    "href": "slides/regression/index.html#linear-cef-and-regression",
    "title": "E655 - Econometrics",
    "section": "Linear CEF and Regression",
    "text": "Linear CEF and Regression\n\nThere are two special cases when the CEF is definitely linear\n\nJoint Normal variables\nSaturated models\n\nWe show below that in these cases the PRF and the CEF are identical\nNote again that we have no data yet\n\nWe are just comparing features of the population"
  },
  {
    "objectID": "slides/regression/index.html#joint-normal-variables",
    "href": "slides/regression/index.html#joint-normal-variables",
    "title": "E655 - Econometrics",
    "section": "Joint Normal Variables",
    "text": "Joint Normal Variables\n\nSuppose the random variables \\(y\\) and \\(x\\) have a bivariate Normal distribution\nThe CEF of \\(y\\) given \\(x\\) is\n\n\\[ E[y|x] = \\mu_{y} + \\rho \\frac{\\sigma_{y}}{\\sigma_{x}}(x - \\mu_{x}) \\]\n\nThe terms in this equation are\n\n\\(\\mu_{x}, \\mu_{y}\\) are the population means of \\(x,y\\)\n\\(\\sigma_{x}, \\sigma_{y}\\) are the population standard deviations of \\(x,y\\)\n\\(\\rho\\) is the correlation coefficient between \\(x,y\\)\n\nThis is linear in \\(x\\) with slope \\(\\rho \\frac{\\sigma_{y}}{\\sigma_{x}}\\)"
  },
  {
    "objectID": "slides/regression/index.html#joint-normal-variables-1",
    "href": "slides/regression/index.html#joint-normal-variables-1",
    "title": "E655 - Econometrics",
    "section": "Joint Normal Variables",
    "text": "Joint Normal Variables\n\nKeep things simple and assume\n\n\\(\\mu_{x} = 0\\) and \\(\\mu_{y} = 1\\)\n\\(\\sigma_{x} = 1\\) and \\(\\sigma_{y} = 1\\)\n\\(\\rho = 0.5\\)\n\nIn this example the CEF is\n\n\\[ E[y|x] = 1 + 0.5x \\]"
  },
  {
    "objectID": "slides/regression/index.html#joint-normal-variables-2",
    "href": "slides/regression/index.html#joint-normal-variables-2",
    "title": "E655 - Econometrics",
    "section": "Joint Normal Variables",
    "text": "Joint Normal Variables\n\nGraphically this looks like"
  },
  {
    "objectID": "slides/regression/index.html#d-density-plot",
    "href": "slides/regression/index.html#d-density-plot",
    "title": "E655 - Econometrics",
    "section": "3D Density Plot",
    "text": "3D Density Plot"
  },
  {
    "objectID": "slides/regression/index.html#contour-plot",
    "href": "slides/regression/index.html#contour-plot",
    "title": "E655 - Econometrics",
    "section": "Contour Plot",
    "text": "Contour Plot"
  },
  {
    "objectID": "slides/regression/index.html#distribution-plot",
    "href": "slides/regression/index.html#distribution-plot",
    "title": "E655 - Econometrics",
    "section": "Distribution Plot",
    "text": "Distribution Plot"
  },
  {
    "objectID": "slides/regression/index.html#estimating-the-cef-with-prf",
    "href": "slides/regression/index.html#estimating-the-cef-with-prf",
    "title": "E655 - Econometrics",
    "section": "Estimating The CEF with PRF",
    "text": "Estimating The CEF with PRF\n\nThe population regression equation to estimate this CEF would be\n\n\\[y = \\alpha +  x\\beta + u\\]\n\nWe derived that the slope in this regression is\n\n\\[\\beta = \\frac{cov(x,y)}{var(x)}\\]\n\nFrom previous slide we know\n\n\\(var(x) = 1\\)\n\\(cov(x,y) = \\rho \\sigma_{x} \\sigma_{y} = 0.5\\)\n\nThe population slope value is therefore \\(\\beta = 0.5\\), exactly the slope of the CEF\nThe intercept is \\(\\alpha = \\mu_{y} - \\mu_{x}\\beta = 1\\)"
  },
  {
    "objectID": "slides/regression/index.html#cef-with-binary-regressor",
    "href": "slides/regression/index.html#cef-with-binary-regressor",
    "title": "E655 - Econometrics",
    "section": "CEF with Binary Regressor",
    "text": "CEF with Binary Regressor\n\nImagine that \\(y\\) is a continuous variable, and \\(x\\) takes on two values \\((0,1)\\)\nThe CEF for these variables is\n\n\\[E[y|x] = E[y|x = 0] + (E[y|x=1] -E[y|x=0])x\\] \\[ = \\alpha + \\beta x\\]\n\nThe slope is the difference in means between the two groups"
  },
  {
    "objectID": "slides/regression/index.html#population-regression-function-2",
    "href": "slides/regression/index.html#population-regression-function-2",
    "title": "E655 - Econometrics",
    "section": "Population Regression Function",
    "text": "Population Regression Function\n\nAgain, the population regression is\n\n\\[y = \\alpha +  x\\beta + u\\]\n\nTaking expectations we get\n\n\\[E[y|x=0] = \\alpha + E[u|x = 0]\\] \\[E[y|x=1] = \\alpha + \\beta + E[u|x = 1]\\]\n\nThe difference is\n\n\\[E[y|x=1] - E[y|x=0] = \\beta + E[u|x = 1] - E[u|x = 0]\\]"
  },
  {
    "objectID": "slides/regression/index.html#population-regression-function-3",
    "href": "slides/regression/index.html#population-regression-function-3",
    "title": "E655 - Econometrics",
    "section": "Population Regression Function",
    "text": "Population Regression Function\n\nThe last two terms are zero because of the properties of regression\nTo see this recall that \\(E[u] = 0\\) in regression, and the Law of Iterated Expectations means\n\n\\[E[xu] = E[xE[u|x]] = 0\\]\n\nSince \\(x\\) takes two values, the only way for this to be true is\n\n\\[ E[u|x = 1] =E[u|x = 0] = 0\\]\n\nThis means\n\n\\[\\beta = E[y|x=1] - E[y|x=0]\\]\n\nThis is exactly the same value as the CEF"
  },
  {
    "objectID": "slides/regression/index.html#cef",
    "href": "slides/regression/index.html#cef",
    "title": "E655 - Econometrics",
    "section": "CEF",
    "text": "CEF\n\nThe CEF and PRF are not equal when the CEF is non-linear\nSuppose that the random variable y is determined by\n\n\\[y = x^2 + \\epsilon\\]\n\nAssume the variable \\(x \\sim \\mathcal{N}(0, 1)\\) and \\(\\epsilon \\sim \\mathcal{N}(0, 1)\\) and independent of \\(x\\)\nThe non-linear CEF in this setup is\n\n\\[E[y|x] = x^2\\]\n\n\n\n\n\n\nCaution\n\n\nThe random variable \\(\\epsilon\\) is not the same as the regression residual \\(u\\). The residual \\(u\\) is defined as \\(u = y- x\\beta\\), whre \\(\\beta\\) is the population regression slope vector. In this example, you can think of \\(\\epsilon\\) as just another random variable, like \\(x\\)."
  },
  {
    "objectID": "slides/regression/index.html#population-regression",
    "href": "slides/regression/index.html#population-regression",
    "title": "E655 - Econometrics",
    "section": "Population Regression",
    "text": "Population Regression\n\nA linear regression function would specify the relationship as\n\n\\[y = \\alpha + x\\beta + e\\]\n\nWe know the population slope is\n\n\\[\\beta = \\frac{cov(x,y)}{var(x)}\\]\n\nBecause \\(x \\sim \\mathcal{N}(0, 1)\\) we know \\(var(x) = 1\\)\nThe covariance term is calculated as\n\n\\[cov(x,y) = cov(x, x^2 + \\epsilon)\\] \\[=cov(x,x^2) + cov(x,\\epsilon)\\]"
  },
  {
    "objectID": "slides/regression/index.html#population-regression-1",
    "href": "slides/regression/index.html#population-regression-1",
    "title": "E655 - Econometrics",
    "section": "Population Regression",
    "text": "Population Regression\n\nThe second term is zero because \\(x\\) and \\(\\epsilon\\) are independent\nFor Standard Normal random variables, \\(x\\) and \\(x^2\\) are also uncorrelated\nBased on this, the PRF slope is\n\n\\[\\beta = 0\\]\n\nThe population intercept is\n\n\\[\\alpha = E[y] - E[x]\\beta\\] \\[=E[x^2 + \\epsilon] - E[x]\\beta\\] \\[=1\\]"
  },
  {
    "objectID": "slides/regression/index.html#graphical-comparison",
    "href": "slides/regression/index.html#graphical-comparison",
    "title": "E655 - Econometrics",
    "section": "Graphical Comparison",
    "text": "Graphical Comparison"
  },
  {
    "objectID": "slides/regression/index.html#what-did-we-learn",
    "href": "slides/regression/index.html#what-did-we-learn",
    "title": "E655 - Econometrics",
    "section": "What did we learn?",
    "text": "What did we learn?\n\nIn econometrics we are often interested in how variables are related\nTo do this, we study how the mean of one variable changes with another\nWe mostly do not know the mean function, so approximate it with regression\nIn population regression the slope vector minimizes the MSPE\nRegression residuals are by definition mean zero and unrelated to \\(\\mathbf{x}\\)\nSo far we have only discussed this in the population\n\nUse of data is coming later"
  },
  {
    "objectID": "content/causality.html",
    "href": "content/causality.html",
    "title": "Causality",
    "section": "",
    "text": "AP1 Chapter 3\nAP2 Chapter 2\nC Chapters 3,4\nCT Chapter 2\nHA Chapter 2\nHK Chapters 5,6,7,8,9,10,11\nK Chapter 3\nSW Chapter 4\nW1 Chapters 2,4\nW2 Chapter 3"
  },
  {
    "objectID": "content/causality.html#readings",
    "href": "content/causality.html#readings",
    "title": "Causality",
    "section": "",
    "text": "AP1 Chapter 3\nAP2 Chapter 2\nC Chapters 3,4\nCT Chapter 2\nHA Chapter 2\nHK Chapters 5,6,7,8,9,10,11\nK Chapter 3\nSW Chapter 4\nW1 Chapters 2,4\nW2 Chapter 3"
  },
  {
    "objectID": "content/causality.html#slides",
    "href": "content/causality.html#slides",
    "title": "Causality",
    "section": "Slides",
    "text": "Slides\nThe slides are embedded in this page, and you can scroll through them with the arrow keys. If you prefer you can instead pop them out in a new window"
  },
  {
    "objectID": "content/causality.html#videos",
    "href": "content/causality.html#videos",
    "title": "Causality",
    "section": "Videos",
    "text": "Videos\nThis is a lecture from (recent Nobel Prize winner) Joshua Angrist explaining these same ideas as part of a lecture series from the American Economics Association (no preview available). View video"
  },
  {
    "objectID": "content/causality.html#other-resources",
    "href": "content/causality.html#other-resources",
    "title": "Causality",
    "section": "Other Resources",
    "text": "Other Resources\ndaggity.net - Website where you can create and analyze DAGs. Will help you determine whether you can identify direct effects by controlling for variables in a model. Also tells you testable model implications and gives code to plot DAG in R."
  },
  {
    "objectID": "slides/causality/index.html",
    "href": "slides/causality/index.html",
    "title": "\nCausality and Regression\n",
    "section": "",
    "text": "Causality and Regression\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\nLoading required package: kableExtra\n\n\nAttaching package: 'kableExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\n\n\nAttaching package: 'ggdag'\n\n\nThe following object is masked from 'package:stats':\n\n    filter"
  },
  {
    "objectID": "slides/causality/index.html#why-is-causality-important",
    "href": "slides/causality/index.html#why-is-causality-important",
    "title": "E655 - Econometrics",
    "section": "Why is Causality Important?",
    "text": "Why is Causality Important?\n\nEmpirical economists are often interested in a causal effect\nFor policy, it is often key to have estimate causal effect\n\nE.g. a school district looking to implement pre-kindergarten program\nThis is generally funded with public money\nNeed to know if pre-k has independent effects on current and future outcomes\n\nDo not want this estimate confounded with parent background\n\n\nWhen can we interpret a regression slope as causal?\nAnswer: when the model is structural\n\nStructural model is one where the coefficients have a causal interpretation"
  },
  {
    "objectID": "slides/causality/index.html#model-with-one-binary-regressor",
    "href": "slides/causality/index.html#model-with-one-binary-regressor",
    "title": "E655 - Econometrics",
    "section": "Model with One Binary Regressor",
    "text": "Model with One Binary Regressor\n\nIn the last section we defined the underlying potential outcomes as\n\n\\[y_{0} = \\alpha + \\eta\\] \\[y_{1} = y_{0} + \\rho\\]\n\nWith the observed outcome\n\n\\[y = \\alpha + \\rho w + \\eta\\]\n\nThis regression model is structural because \\(\\rho\\) is the causal effect\nWe derived that the difference in conditional expectations is\n\n\\[E(y|w=1) - E(y|w=0) = \\rho  + E(\\eta |w=1) - E(\\eta |w=0)\\]"
  },
  {
    "objectID": "slides/causality/index.html#model-with-one-binary-regressor-1",
    "href": "slides/causality/index.html#model-with-one-binary-regressor-1",
    "title": "E655 - Econometrics",
    "section": "Model with One Binary Regressor",
    "text": "Model with One Binary Regressor\n\nThe population regression function with a binary regressor is\n\n\\[y = \\beta_{0} + \\beta_{1}w + u\\]\n\nThe population least squares slope \\(\\beta_{1}\\) from minimizing the MSPE is\n\n\\[\\beta_{1} =  E(y|w=1) - E(y|w=0)\\]\n\nCombining this equation with the structural model\n\n\\[\\beta_{1}  = \\rho  + E(\\eta |w=1) - E(\\eta |w=0)\\]"
  },
  {
    "objectID": "slides/causality/index.html#model-with-one-binary-regressor-2",
    "href": "slides/causality/index.html#model-with-one-binary-regressor-2",
    "title": "E655 - Econometrics",
    "section": "Model with One Binary Regressor",
    "text": "Model with One Binary Regressor\n\nThe regression slope \\(\\beta_{1}\\) equals the treatment effect \\(\\rho\\) when\n\\[E(\\eta |w=1) - E(\\eta |w=0)\\]\nWe saw cases when this is true\n\nRandomization\nMean independence of \\(\\eta\\)\n\nIf none of these are true, then \\(\\beta_{1} \\neq \\rho\\) and \\(\\beta_{1}\\) is not a causal effect"
  },
  {
    "objectID": "slides/causality/index.html#model-with-continuous-regressor",
    "href": "slides/causality/index.html#model-with-continuous-regressor",
    "title": "E655 - Econometrics",
    "section": "Model with Continuous Regressor",
    "text": "Model with Continuous Regressor\n\nWith a continuous independent variable \\(s\\), suppose the structural model is\n\n\\[y = \\alpha + \\rho s + \\eta\\]\n\nWhere the definition of \\(\\rho\\) is\n\\[\\rho = E(y_{s_{0}}|s=s_{0}) - E(y_{s_{0}-1}|s = s_{0} - 1)\\]\nWhere \\(y_{s_{0}}\\) and \\(y_{s_{0}-1}\\) are potential outcomes with two different levels of \\(s\\)\n\n\\(\\rho\\) is the causal effect of a one-unit increase in \\(s\\)\n\nIf we set the population regression function as\n\n\\[y = \\beta_{0} + \\beta_{1}s + u\\]"
  },
  {
    "objectID": "slides/causality/index.html#model-with-continuous-regressor-1",
    "href": "slides/causality/index.html#model-with-continuous-regressor-1",
    "title": "E655 - Econometrics",
    "section": "Model with Continuous Regressor",
    "text": "Model with Continuous Regressor\n\nThe regression slope is\n\n\\[\\beta_{1} = \\frac{cov(y,s)}{var(s)}\\]\n\nTo relate \\(\\beta_{1}\\) to \\(\\rho\\), sub in the structural model for \\(y\\)\n\n\\[\\beta_{1} = \\frac{cov(\\alpha + \\rho s + \\eta ,s)}{var(s)}\\]\n\nSimplifying we get\n\n\\[\\beta_{1} = \\rho + \\frac{cov(\\eta ,s)}{var(s)}\\]"
  },
  {
    "objectID": "slides/causality/index.html#model-with-continuous-regressor-2",
    "href": "slides/causality/index.html#model-with-continuous-regressor-2",
    "title": "E655 - Econometrics",
    "section": "Model with Continuous Regressor",
    "text": "Model with Continuous Regressor\n\n\\(\\beta_{1}\\) equals \\(\\rho\\) when \\(\\eta\\) and \\(s\\) are uncorrelated\n\nRandomization, mean independence both mean this is true\n\nSo if we assume\n\n\\[E(\\eta | s) = 0\\]\n\nThen the second term in equation above is zero and the population slope is the causal effect"
  },
  {
    "objectID": "slides/causality/index.html#model-with-continuous-regressor-3",
    "href": "slides/causality/index.html#model-with-continuous-regressor-3",
    "title": "E655 - Econometrics",
    "section": "Model with Continuous Regressor",
    "text": "Model with Continuous Regressor\n\nNow imagine that the structural model is\n\n\\[y = \\alpha + \\rho s + \\gamma x + \\eta\\]\n\nThe definition of \\(\\rho\\) is\n\n\\[\\rho = E(y_{s_{0}}|x, s=s_{0}) - E(y_{s_{0}-1}|x, s = s_{0} - 1)\\]\n\nIf we set the population regression function as\n\n\\[y = \\beta_{0} + \\beta_{1}s +  \\beta_{2} x+ u\\]"
  },
  {
    "objectID": "slides/causality/index.html#model-with-continuous-regressor-4",
    "href": "slides/causality/index.html#model-with-continuous-regressor-4",
    "title": "E655 - Econometrics",
    "section": "Model with Continuous Regressor",
    "text": "Model with Continuous Regressor\n\nThen \\(\\beta_{1}\\) equals \\(\\rho\\) if we assume\n\nConditional independence of \\(\\eta\\)\nConditional mean independence of \\(\\eta\\)\n\nConditional mean independence means\n\n\\[E(\\eta | s, x) = E(\\eta | x)\\]\n\nIn words, this means \\(s\\) is related to potential outcomes only through \\(x\\)\n\nSo holding \\(x\\) constant breaks this relationship\n\nEven though \\(\\beta_{1}\\) equals \\(\\rho\\), it is important to note that \\(\\beta_{0} \\neq \\alpha\\) and \\(\\beta_{2} \\neq \\gamma\\)\n\nWith regression we do not measure the structural intercept or effect of \\(x\\)"
  },
  {
    "objectID": "slides/causality/index.html#model-with-continuous-regressor-5",
    "href": "slides/causality/index.html#model-with-continuous-regressor-5",
    "title": "E655 - Econometrics",
    "section": "Model with Continuous Regressor",
    "text": "Model with Continuous Regressor\n\nTo see this, take expectation of \\(y\\) in structural model\n\n\\[E[y|s,x] = \\alpha + \\rho s + \\gamma x + E[\\eta|s,x]\\]\n\nIf we impose conditional mean independence, then \\(E(\\eta | s, x) = E(\\eta | x)\\)\n\n\\[E[y|s,x] = \\alpha + \\rho s + \\gamma x + E[\\eta|x]\\]\n\nThe error is not a function of \\(s\\) anymore, but it is a function of \\(x\\)\nFor example, suppose\n\n\\[\\eta = \\theta_{0} + \\theta_{1} x + \\epsilon\\]"
  },
  {
    "objectID": "slides/causality/index.html#model-with-continuous-regressor-6",
    "href": "slides/causality/index.html#model-with-continuous-regressor-6",
    "title": "E655 - Econometrics",
    "section": "Model with Continuous Regressor",
    "text": "Model with Continuous Regressor\n\nAssume that \\(\\epsilon\\) is just a random error unrelated to \\(x\\) and \\(s\\)\nSub into structural model\n\n\\[y = \\alpha + \\rho s + \\gamma x +  \\theta_{0} + \\theta_{1} x + \\epsilon\\] \\[y = (\\alpha +\\theta_{0})+ \\rho s + (\\gamma + \\theta_{1})x \\epsilon\\] \\[y = \\lambda + \\rho s + \\pi x + \\epsilon\\]\n\nThe intercept and slope on \\(x\\) are now redefined\n\nThe are no longer causal effects\n\nSlope on \\(s\\) is still the causal effect \\(\\rho\\)"
  },
  {
    "objectID": "slides/causality/index.html#model-with-continuous-regressor-7",
    "href": "slides/causality/index.html#model-with-continuous-regressor-7",
    "title": "E655 - Econometrics",
    "section": "Model with Continuous Regressor",
    "text": "Model with Continuous Regressor\n\nIf the regression function is\n\n\\[y = \\beta_{0} + \\beta_{1}s +  \\beta_{2} x+ u\\]\n\nThen if \\(E[\\epsilon|s,x] = 0\\)\n\n\\[\\beta_{0} = \\lambda\\] \\[\\beta_{1} = \\rho\\] \\[\\beta_{2} = \\pi\\]"
  },
  {
    "objectID": "slides/causality/index.html#omitted-variables-bias",
    "href": "slides/causality/index.html#omitted-variables-bias",
    "title": "E655 - Econometrics",
    "section": "Omitted Variables Bias",
    "text": "Omitted Variables Bias\n\nIn the regression model above, what happens if we leave out \\(x\\)?\nContinue to assume conditional mean independence\n\n\\[y = \\beta_{0} + \\beta_{1}s  + u\\]\n\nRemember the regression slope is\n\n\\[\\beta_{1} =  \\frac{cov(y ,s)}{var(s)}\\]\n\nSub in the structural model\n\n\\[\\beta_{1} =  \\frac{cov(\\lambda + \\rho s + \\pi x + \\epsilon ,s)}{var(s)}\\]"
  },
  {
    "objectID": "slides/causality/index.html#omitted-variables-bias-1",
    "href": "slides/causality/index.html#omitted-variables-bias-1",
    "title": "E655 - Econometrics",
    "section": "Omitted Variables Bias",
    "text": "Omitted Variables Bias\n\\[\\beta_{1} =  \\rho + \\pi* \\frac{cov( x ,s)}{var(s)} +  \\frac{cov( \\epsilon ,s)}{var(s)}\\]\n\nThe last term is zero because we assume \\(\\epsilon\\) is unrelated to \\(x\\) and \\(s\\)\n\\[\\beta_{1} =  \\rho + \\pi* \\frac{cov( x ,s)}{var(s)}\\]\nThe regression slope does not measure the causal effect in this case\nThe bias is\n\n\\[\\pi* \\frac{cov( x ,s)}{var(s)}\\]"
  },
  {
    "objectID": "slides/causality/index.html#omitted-variables-bias-2",
    "href": "slides/causality/index.html#omitted-variables-bias-2",
    "title": "E655 - Econometrics",
    "section": "Omitted Variables Bias",
    "text": "Omitted Variables Bias\n\nBias has two parts\n\n\\(\\pi \\rightarrow\\) the effect of \\(x\\) on \\(y\\)\n\\(\\frac{cov( x ,s)}{var(s)} \\rightarrow\\) the effect of \\(s\\) on \\(x\\)\n\nIf \\(x\\) is related to \\(y\\) and \\(x\\) is related to \\(s\\), we have bias\nDirection of bias depends on signs of each term\n\nIf both positive or both negative \\(\\rightarrow\\) positive bias\nIf one positive and one negative \\(\\rightarrow\\) negative bias\n\nIf either \\(y\\) or \\(s\\) is unrelated to \\(x\\), there is no bias\nIn vector notation, restate the structural model as\n\n\\[y = \\mathbf{x_{1}}\\boldsymbol{\\alpha_{1}} + \\mathbf{x_{2}}\\boldsymbol{\\alpha_{2}} + \\eta\\]"
  },
  {
    "objectID": "slides/causality/index.html#omitted-variables-bias-3",
    "href": "slides/causality/index.html#omitted-variables-bias-3",
    "title": "E655 - Econometrics",
    "section": "Omitted Variables Bias",
    "text": "Omitted Variables Bias\n\nIf we try to approximate it with the population regression function\n\n\\[y = \\mathbf{x_{1}}\\boldsymbol{\\beta_{1}} + u\\]\n\nWe get the population regression slope as\n\n\\[\\boldsymbol{\\beta_{1}}=\\left (  E[\\mathbf{x_{1}'x_{1}}\\right] )^{-1}  E[\\mathbf{x_{1}'}y]\\]\n\nSub the structural model into the population slope function\n\n\\[\\boldsymbol{\\beta_{1}}=\\left (  E[\\mathbf{x_{1}'x_{1}}\\right] )^{-1}  E[\\mathbf{x_{1}'}( \\mathbf{x_{1}}\\boldsymbol{\\alpha_{1}} + \\mathbf{x_{2}}\\boldsymbol{\\alpha_{2}} + \\eta )]\\] \\[=\\left (  E[\\mathbf{x_{1}'x_{1}}\\right] )^{-1}  E[\\mathbf{x_{1}'} \\mathbf{x_{1}}\\boldsymbol{\\alpha_{1}} + \\mathbf{x_{1}'x_{2}}\\boldsymbol{\\alpha_{2}} + \\mathbf{x_{1}'}\\eta ]\\] \\[=\\left (  E[\\mathbf{x_{1}'x_{1}}\\right] )^{-1}  E[\\mathbf{x_{1}'} \\mathbf{x_{1}}]\\boldsymbol{\\alpha_{1}} + \\left (  E[\\mathbf{x_{1}'x_{1}}\\right] )^{-1}E[\\mathbf{x_{1}'x_{2}}]\\boldsymbol{\\alpha_{2}} + \\left (  E[\\mathbf{x_{1}'x_{1}}\\right] )^{-1}E[\\mathbf{x_{1}'}\\eta ]\\]"
  },
  {
    "objectID": "slides/causality/index.html#omitted-variables-bias-4",
    "href": "slides/causality/index.html#omitted-variables-bias-4",
    "title": "E655 - Econometrics",
    "section": "Omitted Variables Bias",
    "text": "Omitted Variables Bias\n\\[=\\boldsymbol{\\alpha_{1}} + \\left (  E[\\mathbf{x_{1}'x_{1}}\\right] )^{-1}E[\\mathbf{x_{1}'x_{2}}]\\boldsymbol{\\alpha_{2}}\\]\n\nThe population slope vector on \\(\\mathbf{x_{1}}\\) equals the sum of\n\nThe causal slope vector \\(\\boldsymbol{\\alpha_{1}}\\)\nA bias term containing\n\nthe regression of \\(\\mathbf{x_{2}}\\) on \\(\\mathbf{x_{1}}\\)\nthe slope on \\(\\mathbf{x_{2}}\\) in the structural for \\(y\\)\n\n\nA key lesson here is that a single omitted variable will bias all population slopes \\(\\boldsymbol{\\beta_{1}}\\)\n\nUnless it is unrelated to y\nOr it is uncorrelated with all but one included regressor, and that regressor is uncorrelated with the others"
  },
  {
    "objectID": "slides/causality/index.html#introduction-1",
    "href": "slides/causality/index.html#introduction-1",
    "title": "E655 - Econometrics",
    "section": "Introduction",
    "text": "Introduction\n\nEmpirical economists are often interested in a causal effect\n\nThe independent effect of a particular variable on the outcome\n\nIt is important for policy\n\nE.g. a school district looking to implement pre-kindergarten program\nNeed to know if pre-k has independent effects on current and future outcomes\n\nDo not want estimate confounded with parent background\n\n\nCan we interpret regression slopes as causal?\nFirst, we attempt to understand the underlying concept of causality"
  },
  {
    "objectID": "slides/causality/index.html#model-setup",
    "href": "slides/causality/index.html#model-setup",
    "title": "E655 - Econometrics",
    "section": "Model Setup",
    "text": "Model Setup\n\nEconomists often study causality within the Rubin Causal Model\nImagine an individual either gets a “treatment” or “no treatment”\n\nGetting a drug, or placebo\nGoing to university, or stopping at high school\nBeing in a small class, or large class\n\nDefine the following potential outcomes\n\n\\(y_{1}\\) is the outcome with treatment\n\\(y_{0}\\) is the outcome without treatment\n\\(w\\) is a binary variable with 1 denoting treatment, and 0 no treatment\n\n\n\n\n\n\n\n\nImportant\n\n\nWe only observe one potential outcome, and the other is hypothetical. For a treated person we see \\(y_{1}\\), and for an untreated person we see \\(y_{0}\\)"
  },
  {
    "objectID": "slides/causality/index.html#treatment-effects",
    "href": "slides/causality/index.html#treatment-effects",
    "title": "E655 - Econometrics",
    "section": "Treatment Effects",
    "text": "Treatment Effects\n\nWe would like to know the treatment effect \\(y_{1} - y_{0}\\) for an individual\n\nThis is the causal effect of the treatment\nEffect differs from person to person in the population\n\nFundamental problem of causal inference: we never observe both \\(y_{1}\\) and \\(y_{0}\\)\nWe only observe \\((y, w)\\), where\n\\[y = y_{0} + (y_{1} -y_{0})w\\]\n\nWe observe treatment status, potential outcome given that treatment status\n\nThe counterfactual outcome with opposite treatment is never observed"
  },
  {
    "objectID": "slides/causality/index.html#simple-differences-in-average-outcomes",
    "href": "slides/causality/index.html#simple-differences-in-average-outcomes",
    "title": "E655 - Econometrics",
    "section": "Simple Differences in Average Outcomes",
    "text": "Simple Differences in Average Outcomes\n\nSuppose we regress \\(y\\) on \\(w\\)\nThe slope in this regression is $= \\(E(y|w=1) - E(y|w=0)\\)\nSubstitute for \\(y\\) using equation with potential outcomes\n\\[E(y|w=1) - E(y|w=0)\\] \\[=  E(y_{1}|w=1) - E(y_{0}|w=0)\\] \\[= \\left [ E(y_{1}|w=1) - E(y_{0}|w=1) \\right ] + E(y_{0}|w=1) - E(y_{0}|w=0)\\]\nThe first term is called the Average Treatment Effect on the Treated (ATT)\n\nAverage effect of the treatment for those in the treatment group"
  },
  {
    "objectID": "slides/causality/index.html#simple-differences-in-average-outcomes-1",
    "href": "slides/causality/index.html#simple-differences-in-average-outcomes-1",
    "title": "E655 - Econometrics",
    "section": "Simple Differences in Average Outcomes",
    "text": "Simple Differences in Average Outcomes\n\nThe second term is Selection Bias\n\nBaseline difference between treatment and control groups\n\nSimple average differences will not identify a treatment effect\n\nIt is partly a treatment effect, partly differences in who gets treated\n\nEx: Comparing average incomes of university grads to high school grads\n\nWill be partly average causal effect of university\nAlso difference in baseline earning ability without the degree\n\nLesson is that simple differences in averages do not reveal causal effects\nUnder what conditions can we measure the causal effect of \\(w\\) on \\(y\\)?"
  },
  {
    "objectID": "slides/causality/index.html#randomization-and-independence-of-treatment",
    "href": "slides/causality/index.html#randomization-and-independence-of-treatment",
    "title": "E655 - Econometrics",
    "section": "Randomization and Independence of Treatment",
    "text": "Randomization and Independence of Treatment\n\nA common way to isolate treatment effects is to randomize \\(w\\)\n\nBlindly put people into treatment or control group\nEnsures that on average the two groups are similar at baseline\n\nWhen treatment is randomized, potential outcomes are independent from treatment \\[(y_{0}, y_{1}) \\perp w\\]\nIndependence implies conditioning on \\(w\\) has no effect on expectation\n\\[E(y_{0}|w=1) =E(y_{0}|w=0)\\] \\[E(y_{0}|w) = E(y_{0})\\] \\[E(y_{1}|w) = E(y_{1})\\]"
  },
  {
    "objectID": "slides/causality/index.html#randomization-and-treatment-effects",
    "href": "slides/causality/index.html#randomization-and-treatment-effects",
    "title": "E655 - Econometrics",
    "section": "Randomization and Treatment Effects",
    "text": "Randomization and Treatment Effects\n\nWith randomization, selection bias is zero\n\\[E(y_{0}|w=1) - E(y_{0}|w=0) = E(y_{0}|w=1) - E(y_{0}|w=1) = 0\\]\nAs a result the population regression slope is \\[\\beta = E(y|w=1) - E(y|w=0)\\] \\[= E(y_{1}|w=1) - E(y_{0}|w=0)\\] \\[= E(y_{1}) - E(y_{0})\\]\nThis is the Average Treatment Effect (ATE)\n\n\n\n\n\n\n\nNote\n\n\nThe ATE is the treatment effect averaged across everyone in the population, whereas the ATT is the treatment effect among only people in the treatment group (i.e. excludes people in the control group)."
  },
  {
    "objectID": "slides/causality/index.html#recent-example-in-economics-literature",
    "href": "slides/causality/index.html#recent-example-in-economics-literature",
    "title": "E655 - Econometrics",
    "section": "Recent Example in Economics Literature",
    "text": "Recent Example in Economics Literature\n\nRandomization is the standard way to measure the effects of medical treatments\nIt is becoming more popular in economics\nEx: Bangladesh mask study (Abaluck et. al., 2021)\n\nRandomized promoting mask use in rural Bangladesh\nCompare COVID rates between treatment and control\nFind some positive effect of masks, especially for age 50+"
  },
  {
    "objectID": "slides/causality/index.html#link-to-regression-models",
    "href": "slides/causality/index.html#link-to-regression-models",
    "title": "E655 - Econometrics",
    "section": "Link to Regression Models",
    "text": "Link to Regression Models\n\nIn randomized experiments, you can get causal effects with difference in means\nEconomists typically work with regression models\nRemember the outcome we observe \\(y\\) is\n\\[y = (y_{1} - y_{0})w + y_{0}\\]\nIf we define the potential outcomes as \\[y_{0} = \\alpha + \\eta\\] \\[y_{1} = y_{0} + \\rho\\]"
  },
  {
    "objectID": "slides/causality/index.html#link-to-regression-models-1",
    "href": "slides/causality/index.html#link-to-regression-models-1",
    "title": "E655 - Econometrics",
    "section": "Link to Regression Models",
    "text": "Link to Regression Models\n\nIf we combine the three equations we get\n\\[y = \\alpha + \\rho w + \\eta\\]\nThe difference in means for \\(y\\) by treatment status is now\n\\[E(y|w=1) - E(y|w=0)\\] \\[\\rho  + E(\\eta |w=1) - E(\\eta |w=0)\\]\nTreatment effect is the regression slope\nSelection bias is correlation between error term and treatment\n\\[E[y_{0}|w=1] -  E[y_{0}|w=0] = E[\\eta|w=1] -  E[\\eta|w=0]\\]"
  },
  {
    "objectID": "slides/causality/index.html#link-to-regression-models-2",
    "href": "slides/causality/index.html#link-to-regression-models-2",
    "title": "E655 - Econometrics",
    "section": "Link to Regression Models",
    "text": "Link to Regression Models\n\nRandomization means no selection bias\nIn a regression framework, this means the error is unrelated to treatment\n\\[E[\\eta|w=1] -  E[\\eta|w=0] =0\\]\nSo a regression of \\(y\\) on \\(w\\) would measure the causal effect\nIn reality, we cannot always randomize \\(w\\)\n\nEconomists deal mostly with observational data\n\nNext we look at causal effects when we cannot randomize"
  },
  {
    "objectID": "slides/causality/index.html#mean-independence-of-treatment",
    "href": "slides/causality/index.html#mean-independence-of-treatment",
    "title": "E655 - Econometrics",
    "section": "Mean Independence of Treatment",
    "text": "Mean Independence of Treatment\n\nMost economic data do not come from randomized experiments\nWe can still uncover causal effects without experiments\nOne way is through Mean Independence\n\\[E(y_{0}|w) = E(y_{0})\\] \\[E(y_{1}|w) = E(y_{1})\\]\nSays average potential outcomes do not depend on treatment status\n\nWeaker assumption than full statistical independence\nFull independence means one event has no effect on probability of another"
  },
  {
    "objectID": "slides/causality/index.html#mean-independence-of-treatment-1",
    "href": "slides/causality/index.html#mean-independence-of-treatment-1",
    "title": "E655 - Econometrics",
    "section": "Mean Independence of Treatment",
    "text": "Mean Independence of Treatment\n\nWith mean independence, we get\n\\[\\beta = E(y|w=1) - E(y|w=0)\\] \\[= \\left [ E(y_{1}|w=1) - E(y_{0}|w=1) \\right ] + E(y_{0}|w=1) - E(y_{0}|w=0)\\] \\[= \\left [ E(y_{1}|w=1) - E(y_{0}|w=1) \\right ]\\] \\[=  E(y_{1}) - E(y_{0})\\]\nRegression slope equals ATE (and ATT in this case)\nIs this assumption realistic?\n\nMeans both potential outcomes unrelated to treatment\nWhether this is realistic depends on context"
  },
  {
    "objectID": "slides/causality/index.html#mean-independence-of-y_0",
    "href": "slides/causality/index.html#mean-independence-of-y_0",
    "title": "E655 - Econometrics",
    "section": "Mean Independence of \\(y_{0}\\)",
    "text": "Mean Independence of \\(y_{0}\\)\n\nA variation if this assumption is mean independence of \\(\\mathbf{y_{0}}\\)\n\\[E(y_{0}|w) = E(y_{0})\\]\nThe regression slope in this case is\n\\[\\beta = E(y|w=1) - E(y|w=0)\\] \\[= \\left [ E(y_{1}|w=1) - E(y_{0}|w=1) \\right ] + E(y_{0}|w=1) - E(y_{0}|w=0)\\] \\[= \\left [ E(y_{1}|w=1) - E(y_{0}|w=1) \\right ]\\]\nWith this assumption, we only measure the ATT (Not ATE)\nIs this realistic?\n\nMeans there are no baseline differences between groups on average\nPuts no restriction on differences in treated outcome"
  },
  {
    "objectID": "slides/causality/index.html#conditional-mean-independence",
    "href": "slides/causality/index.html#conditional-mean-independence",
    "title": "E655 - Econometrics",
    "section": "Conditional Mean Independence",
    "text": "Conditional Mean Independence\n\nMore commonly, we can use other variables to control for selection bias\nSuppose we observe a set of pre-treatment characteristics \\(\\mathbf{x}\\)\n\nEx: gender, parental education, school test scores, etc.\nKey is they are determined before treatment\n\nConditional Mean Independence is when the mean of the potential outcomes is independent of treatment conditional on \\(\\mathbf{x}\\)\n\\[E(y_{0}|w=1, \\mathbf{x}) =E(y_{0}|w=0, \\mathbf{x})\\] \\[E(y_{0}|w, \\mathbf{x}) = E(y_{0}| \\mathbf{x})\\] \\[E(y_{1}|w, \\mathbf{x}) = E(y_{1}|\\mathbf{x})\\]\n\n\n\n\n\n\n\nNote\n\n\nA stronger assumption is conditional independence \\((y_{0}, y_{1}) \\perp w |\\mathbf{x}\\), where each potential outcome is fully independent of treatment conditional on \\(\\mathbf{x}\\)"
  },
  {
    "objectID": "slides/causality/index.html#conditional-mean-independence-1",
    "href": "slides/causality/index.html#conditional-mean-independence-1",
    "title": "E655 - Econometrics",
    "section": "Conditional Mean Independence",
    "text": "Conditional Mean Independence\n\nImagine running a regression of \\(y\\) on \\(w\\) and \\(\\mathbf{x}\\)\nThe population regression slope is\n\\[\\beta = E(y|w=1,  \\mathbf{x}) - E(y|w=0,  \\mathbf{x})\\]\nWhen this assumption is true we can get treatment effects at each \\(\\mathbf{x}\\) \\[E(y|w=1,  \\mathbf{x}) - E(y|w=0,  \\mathbf{x})\\] \\[= E(y_{1}|w=1,  \\mathbf{x}) - E(y_{0}|w=1,  \\mathbf{x})= E(y_{1} | \\mathbf{x}) - E(y_{0}| \\mathbf{x})\\] \\[= ATT( \\mathbf{x}) =ATE( \\mathbf{x})\\]\nThese treatment effects hold \\(\\mathbf{x}\\) constant\n\nThey are an average of the treatment effects across different values of \\(\\mathbf{x}\\)"
  },
  {
    "objectID": "slides/causality/index.html#link-with-regression",
    "href": "slides/causality/index.html#link-with-regression",
    "title": "E655 - Econometrics",
    "section": "Link with Regression",
    "text": "Link with Regression\n\nSubstitute this into the equation for \\(y_{0}\\)\n\\[y_{0} = \\alpha + \\mathbf{x}\\boldsymbol{\\gamma} + \\epsilon\\]\nNow if we combine the equations for \\(y\\), \\(y_{0}\\), and \\(y_{1}\\)\n\\[y = \\alpha + \\rho w + \\mathbf{x}\\boldsymbol{\\gamma} + \\epsilon\\]\nThe difference in means for \\(y\\) at each \\(\\mathbf{x}\\) between groups is now \\[E(y| \\mathbf{x}, w=1) - E(y| \\mathbf{x}, w=0)\\] \\[\\rho  + E(\\epsilon | \\mathbf{x}, w=1)  - E(\\epsilon | \\mathbf{x}, w=0)\\]"
  },
  {
    "objectID": "slides/causality/index.html#link-with-regression-1",
    "href": "slides/causality/index.html#link-with-regression-1",
    "title": "E655 - Econometrics",
    "section": "Link with Regression",
    "text": "Link with Regression\n\nAgain, the difference in the mean conditional error term is selection bias\n\\[E[y_{0}|\\mathbf{x}, w=1] -  E[y_{0}|\\mathbf{x}, w=0] = E[\\epsilon|\\mathbf{x},w=1] -  E[\\epsilon|\\mathbf{x},w=0]\\]\nIf we assume Conditional Independence (or Conditional Mean Independence) then \\[E(y_{0}  | \\mathbf{x}, w)  = E(y_{0}  | \\mathbf{x})\\]\nand as a result\n\\[E(y_{0}  | \\mathbf{x}, w=1)  = E(y_{0}  | \\mathbf{x}, w=0)\\]\nand\n\\[E[\\epsilon|\\mathbf{x},w=1] -  E[\\epsilon|\\mathbf{x},w=0] =0\\]"
  },
  {
    "objectID": "slides/causality/index.html#link-with-regression-2",
    "href": "slides/causality/index.html#link-with-regression-2",
    "title": "E655 - Econometrics",
    "section": "Link with Regression",
    "text": "Link with Regression\n\nIntuition is as follows\n\nParticipation in treatment and control might be related to baseline factors\nBut, for those with the same baseline factors, treatment is as good as random\nComputing treatment effects for each \\(\\mathbf{x}\\) eliminates selection bias\n\nIn this model, adding “control variables” identifies the causal effect of \\(w\\)\nWhether this is actually true depends on assumptions\n\nOften we cannot prove those assumptions"
  },
  {
    "objectID": "slides/causality/index.html#link-with-regression-3",
    "href": "slides/causality/index.html#link-with-regression-3",
    "title": "E655 - Econometrics",
    "section": "Link with Regression",
    "text": "Link with Regression\n\nIntuition is as follows\n\nParticipation in treatment and control might be related to baseline factors\nBut, for those with the same baseline factors, treatment is as good as random\nComputing treatment effects for each \\(\\mathbf{x}\\) eliminates selection bias\n\nIn this model, adding “control variables” identifies the causal effect of \\(w\\)\nWhether this is actually true depends on assumptions\n\nOften we cannot prove those assumptions"
  },
  {
    "objectID": "slides/causality/index.html#summary-of-rubin-model-1",
    "href": "slides/causality/index.html#summary-of-rubin-model-1",
    "title": "E655 - Econometrics",
    "section": "Summary of Rubin Model",
    "text": "Summary of Rubin Model\n\nThe Rubin model defines what is a causal effect\nRoughly speaking, it an Average Treatment Effect\n\nThey will differ across values of \\(\\mathbf{x}\\)\nDifference in potential outcomes, on average in population\nDepending on context, it might be an Average Treatment Effect for the Treated\n\nWe can express the Rubin model in a regression framework\nThe slope in a linear regression is the causal effect if we can assume one of\n\nRandomization of treatment\n“As good as” randomization\n\nMean Independence, Conditional Independence, Conditional Mean Indpendence"
  },
  {
    "objectID": "slides/causality/index.html#summary-of-rubin-model-2",
    "href": "slides/causality/index.html#summary-of-rubin-model-2",
    "title": "E655 - Econometrics",
    "section": "Summary of Rubin Model",
    "text": "Summary of Rubin Model\n\nThe Rubin model defines what is a causal effect\nRoughly speaking, it an Average Treatment Effect\n\nThey will differ across values of \\(\\mathbf{x}\\)\nDifference in potential outcomes, on average in population\nDepending on context, it might be an Average Treatment Effect for the Treated\n\nWe can express the Rubin model in a regression framework\nThe slope in a linear regression is the causal effect if we can assume one of\n\nRandomization of treatment\n“As good as” randomization\n\nMean Independence, Conditional Independence, Conditional Mean Indpendence"
  },
  {
    "objectID": "slides/causality/index.html#data-setup",
    "href": "slides/causality/index.html#data-setup",
    "title": "E655 - Econometrics",
    "section": "Data Setup",
    "text": "Data Setup\n\n\n\nCode to the right creates potential outcomes\nFor simplicity the treatment effect is set to 5 for everyone\nOutcomes \\(y_{0}\\) and \\(y_{1}\\) created to have a Normal distribution\n\nNormality is not important for the model\n\n\n\n\ndata &lt;- data.frame(eta=rnorm(100000,0,1)) %&gt;%\n  mutate(y0 = 2 + eta, y1 = y0 + 5, \n         treat_eff = y1 - y0)\n\nsumtable(data, summ=c('notNA(x)','mean(x)','sd(x)'), \n         summ.names = c('N', 'Mean', 'SD')) \n\n\nSummary Statistics\n\n\nVariable\nN\nMean\nSD\n\n\n\n\neta\n100000\n-0.0012\n1\n\n\ny0\n100000\n2\n1\n\n\ny1\n100000\n7\n1\n\n\ntreat_eff\n100000\n5\n0.00000000000000021"
  },
  {
    "objectID": "slides/causality/index.html#random-assignment-to-treatment",
    "href": "slides/causality/index.html#random-assignment-to-treatment",
    "title": "E655 - Econometrics",
    "section": "Random Assignment to Treatment",
    "text": "Random Assignment to Treatment\n\n\n\nNext assign treatment \\(w\\) using randomization\nIn the code, \\(w=1\\) randomly with probability 0.5\nCompute observed \\(y\\) based on treatment status\n\n\n\ndata %&lt;&gt;% mutate(w = if_else(runif(100000) &gt; .5,1,0), \n                 y = y0 + (y1-y0)*w) %&gt;% \n  group_by(w)\n\nhead(data)\n## # A tibble: 6 × 6\n## # Groups:   w [2]\n##      eta    y0    y1 treat_eff     w     y\n##    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n## 1  2.16  4.16   9.16         5     1 9.16 \n## 2 -1.63  0.365  5.37         5     0 0.365\n## 3 -0.794 1.21   6.21         5     1 6.21 \n## 4  1.07  3.07   8.07         5     0 3.07 \n## 5  0.133 2.13   7.13         5     1 7.13 \n## 6  1.90  3.90   8.90         5     0 3.90"
  },
  {
    "objectID": "slides/causality/index.html#random-assignment-to-treatment-1",
    "href": "slides/causality/index.html#random-assignment-to-treatment-1",
    "title": "E655 - Econometrics",
    "section": "Random Assignment to Treatment",
    "text": "Random Assignment to Treatment\n\n\n\nWith random assignment we know\n\n\\(y_{0}\\) is independent of \\(w\\)\n\\(y_{1}\\) is independent of \\(w\\)\n\nSo the distributions of \\(y_{0}\\) and \\(y_{1}\\) are the same when \\(w=0\\) and when \\(w=1\\)\nTo the right we show the distribution of \\(y_{0}\\)\n\n\n\nggplot(data, aes(x=y0, color=as.factor(w))) +\n  geom_density(alpha = .4, size=2) +\n  theme_pander(nomargin=FALSE, boxes=TRUE) +\n  labs(title = \"Distribution of Y0\", color = \"w\")"
  },
  {
    "objectID": "slides/causality/index.html#random-assignment-to-treatment-2",
    "href": "slides/causality/index.html#random-assignment-to-treatment-2",
    "title": "E655 - Econometrics",
    "section": "Random Assignment to Treatment",
    "text": "Random Assignment to Treatment\n\n\n\nRandomization ensures difference in average \\(y\\) between groups equals the ATE and ATT\nOn the right we show the difference in mean of \\(y\\) equals 5\n\n\n\nsummarize(data, my = mean(y)) %&gt;%\n  mutate(diff_y = my - lag(my))\n## # A tibble: 2 × 3\n##       w    my diff_y\n##   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n## 1     0  2.00  NA   \n## 2     1  7.00   5.00"
  },
  {
    "objectID": "slides/causality/index.html#random-assignment-to-treatment-3",
    "href": "slides/causality/index.html#random-assignment-to-treatment-3",
    "title": "E655 - Econometrics",
    "section": "Random Assignment to Treatment",
    "text": "Random Assignment to Treatment\n\n\n\nCan implement difference in means as a regression\nRecall slope in OLS regression of \\(y\\) on dummy variable is difference in means of \\(y\\)\n\n\n\nlm(y ~ w, data)\n## \n## Call:\n## lm(formula = y ~ w, data = data)\n## \n## Coefficients:\n## (Intercept)            w  \n##       1.997        5.005"
  },
  {
    "objectID": "slides/causality/index.html#selection-into-treatment",
    "href": "slides/causality/index.html#selection-into-treatment",
    "title": "E655 - Econometrics",
    "section": "Selection into Treatment",
    "text": "Selection into Treatment\n\n\n\nNow simulate selection into treatment based on \\(y_{0}\\)\n\nTreatment now related to value of \\(y_{0}\\)\n\nWe know \\(\\eta\\) determines value of \\(y_{0}\\)\n\nIf we make \\(w=1\\) with higher values of \\(\\eta\\) then \\(w\\) is related to \\(y_{0}\\)\n\n\n\n\ndata2 &lt;- data %&gt;% \n  ungroup() %&gt;% \n  select(eta, y0,y1) %&gt;%\n  mutate(w = if_else(eta + runif(100000,-1,1) &gt; 0,1,0), \n         y = y0 + (y1-y0)*w) %&gt;%\n  group_by(w)\n\nsumtable(data2, \n         summ=c('notNA(x)','mean(x)','sd(x)'),\n         summ.names = c('N', 'Mean', 'SD' ),\n         group=\"w\",\n         group.long = TRUE)"
  },
  {
    "objectID": "slides/causality/index.html#selection-into-treatment-1",
    "href": "slides/causality/index.html#selection-into-treatment-1",
    "title": "E655 - Econometrics",
    "section": "Selection into Treatment",
    "text": "Selection into Treatment\n\n\n\nThe means of \\(y_{0}\\) and \\(y_{1}\\) are now different by group\nBecause of selection bias\n\nTreated group has better non-treated outcomes\n\n\n\n\n\n\nSummary Statistics\n\n\nVariable\nN\nMean\nSD\n\n\n\n\nw: 0\n\n\n\n\n\neta\n49920\n-0.68\n0.73\n\n\ny0\n49920\n1.3\n0.73\n\n\ny1\n49920\n6.3\n0.73\n\n\ny\n49920\n1.3\n0.73\n\n\nw: 1\n\n\n\n\n\neta\n50080\n0.68\n0.73\n\n\ny0\n50080\n2.7\n0.73\n\n\ny1\n50080\n7.7\n0.73\n\n\ny\n50080\n7.7\n0.73"
  },
  {
    "objectID": "slides/causality/index.html#selection-into-treatment-2",
    "href": "slides/causality/index.html#selection-into-treatment-2",
    "title": "E655 - Econometrics",
    "section": "Selection into Treatment",
    "text": "Selection into Treatment\n\n\n\nThe distribution of \\(y_{0}\\) differs by \\(w\\)\n\nTreated group has better baseline outcomes\n\nThis creates selection bias\n\n\n\nggplot(data2, aes(x=y0, color=as.factor(w))) +\n  geom_density(alpha = .4, size=2) +\n  theme_pander(nomargin=FALSE, boxes=TRUE) +\n  labs(title = \"Distribution of Y0\", color = \"w\")"
  },
  {
    "objectID": "slides/causality/index.html#selection-into-treatment-3",
    "href": "slides/causality/index.html#selection-into-treatment-3",
    "title": "E655 - Econometrics",
    "section": "Selection into Treatment",
    "text": "Selection into Treatment\n\n\n\nSelction bias shows up when you take difference in mean \\(y\\)\n\nWe know the true treatment effect is 5\nBut difference in \\(y\\) is larger\nThere is positive selection bias\nBias is about 1.4\n\n\n\n\nsummarize(data2, my = mean(y)) %&gt;%\n  mutate(diff_y = my - lag(my))\n## # A tibble: 2 × 3\n##       w    my diff_y\n##   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n## 1     0  1.32  NA   \n## 2     1  7.68   6.36"
  },
  {
    "objectID": "slides/causality/index.html#selection-into-treatment-4",
    "href": "slides/causality/index.html#selection-into-treatment-4",
    "title": "E655 - Econometrics",
    "section": "Selection into Treatment",
    "text": "Selection into Treatment\n\n\n\nYou can implement this as a regression\nOLS estimates biased treatment effect\nRemember the intercept is mean of \\(y\\) when \\(w=0\\)\n\n\n\nlm(y ~ w, data2)\n## \n## Call:\n## lm(formula = y ~ w, data = data2)\n## \n## Coefficients:\n## (Intercept)            w  \n##       1.319        6.358"
  },
  {
    "objectID": "slides/causality/index.html#mean-independence-of-y_0-1",
    "href": "slides/causality/index.html#mean-independence-of-y_0-1",
    "title": "E655 - Econometrics",
    "section": "Mean Independence of \\(y_{0}\\)",
    "text": "Mean Independence of \\(y_{0}\\)\n\n\n\nRandomization ensures entire distribution of \\(y_{0}\\) is the same for treatment and control\nWe do not need this to estimate average treatment effects\nIf the mean of \\(y_{0}\\) is the same between treatment and control we can estimate treatment effect with difference in means\nCode makes mean of \\(y_{0}\\) the same, but variance bigger for \\(w=1\\)\n\n\n\ndata3 &lt;- data %&gt;% \n  ungroup() %&gt;% \n  select(eta, y0,y1) %&gt;%\n  mutate(w =  if_else(between(percent_rank(y0),.25,.75),0,1), \n         y = y0 + (y1-y0)*w) %&gt;%\n  group_by(w)\n\nsumtable(data3, \n         summ=c('notNA(x)','mean(x)','sd(x)'), \n         group=\"w\",\n         group.long = TRUE)"
  },
  {
    "objectID": "slides/causality/index.html#mean-independence-of-y_0-2",
    "href": "slides/causality/index.html#mean-independence-of-y_0-2",
    "title": "E655 - Econometrics",
    "section": "Mean Independence of \\(y_{0}\\)",
    "text": "Mean Independence of \\(y_{0}\\)\n\n\n\nRandomization ensures entire distribution of \\(y_{0}\\) is the same for treatment and control\nWe do not need this to estimate average treatment effects\nIf the mean of \\(y_{0}\\) is the same between treatment and control we can estimate treatment effect with difference in means\nCode makes mean of \\(y_{0}\\) the same, but variance bigger for \\(w=1\\)\n\n\n\n\n\nSummary Statistics\n\n\nVariable\nN\nMean\nSD\n\n\n\n\nw: 0\n\n\n\n\n\neta\n50000\n0.0032\n0.38\n\n\ny0\n50000\n2\n0.38\n\n\ny1\n50000\n7\n0.38\n\n\ny\n50000\n2\n0.38\n\n\nw: 1\n\n\n\n\n\neta\n50000\n0.002\n1.4\n\n\ny0\n50000\n2\n1.4\n\n\ny1\n50000\n7\n1.4\n\n\ny\n50000\n7\n1.4"
  },
  {
    "objectID": "slides/causality/index.html#mean-independence-of-y_0-3",
    "href": "slides/causality/index.html#mean-independence-of-y_0-3",
    "title": "E655 - Econometrics",
    "section": "Mean Independence of \\(y_{0}\\)",
    "text": "Mean Independence of \\(y_{0}\\)\n\n\n\nThe distribution of \\(y_{0}\\) is plotted on the right\nThe spread is larger for \\(w=1\\)\nThis does not affect estimate of the average treatment effect\n\n\n\nggplot(data3, aes(x=y0, color=as.factor(w))) +\n  geom_density(alpha = .4, size=2) +\n  theme_pander(nomargin=FALSE, boxes=TRUE) +\n  labs(title = \"Distribution of Y0\")"
  },
  {
    "objectID": "slides/causality/index.html#mean-independence-of-y_0-4",
    "href": "slides/causality/index.html#mean-independence-of-y_0-4",
    "title": "E655 - Econometrics",
    "section": "Mean Independence of \\(y_{0}\\)",
    "text": "Mean Independence of \\(y_{0}\\)\n\n\n\nTake difference in mean \\(y\\)\n\nThis equals the treatment effect\nDifference in variance did not create bias\n\n\n\n\nsummarize(data3, my = mean(y)) %&gt;%\n  mutate(diff_y = my - lag(my))\n## # A tibble: 2 × 3\n##       w    my diff_y\n##   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n## 1     0  2.00  NA   \n## 2     1  7.00   5.00"
  },
  {
    "objectID": "slides/causality/index.html#mean-independence-of-y_0-5",
    "href": "slides/causality/index.html#mean-independence-of-y_0-5",
    "title": "E655 - Econometrics",
    "section": "Mean Independence of \\(y_{0}\\)",
    "text": "Mean Independence of \\(y_{0}\\)\n\n\n\nRunning regression produces same result\nThe variance in \\(y_{1}\\) affects the standard error\n\nBut we are not concerned with that right now\n\n\n\n\nlm(y ~ w, data3)\n## \n## Call:\n## lm(formula = y ~ w, data = data3)\n## \n## Coefficients:\n## (Intercept)            w  \n##       2.003        4.999"
  },
  {
    "objectID": "slides/causality/index.html#conditional-mean-independence-2",
    "href": "slides/causality/index.html#conditional-mean-independence-2",
    "title": "E655 - Econometrics",
    "section": "Conditional Mean Independence",
    "text": "Conditional Mean Independence\n\n\n\nFinally consider conditional mean independence\nTreatment is related to \\(y_{0}\\), but only through \\(x\\)\n\nFor people with the same \\(x\\), \\(y_{0}\\) is unrelated to \\(w\\)\n\nEx: Education and wages\n\nSmart people \\((x = 1)\\) earn higher wages regardless of schooling \\((y_0)\\)\nSmart people are more likely to go to university \\((w = 1)\\)\nPeople at university will have higher \\(y_0\\)\n\n\n\n\ndata3 &lt;- data %&gt;% \n  ungroup() %&gt;% \n  select(eta) %&gt;%\n  mutate(x = if_else(runif(100000) &gt; .5,1,0),\n         w = if_else(x + runif(100000, -1,1) &gt; .5,1,0),\n         y0 = 2 + 3*x + eta,\n         y1 = y0 + 5,\n         y = y0 + (y1-y0)*w) %&gt;%\n  group_by(w)\n\nsumtable(data3, \n         summ=c('notNA(x)','mean(x)','sd(x)'),\n         summ.names = c('N', 'Mean', 'SD' ),\n         group=\"w\",\n         group.long = TRUE)"
  },
  {
    "objectID": "slides/causality/index.html#conditional-mean-independence-3",
    "href": "slides/causality/index.html#conditional-mean-independence-3",
    "title": "E655 - Econometrics",
    "section": "Conditional Mean Independence",
    "text": "Conditional Mean Independence\n\n\n\nComparing treatment and control, \\(y_{0}\\) is bigger when \\(w=1\\)\nThis is because\n\n\\(y_{0}\\) is bigger when \\(x=1\\)\n\\(w\\) more likely to be \\(1\\) when \\(x=1\\)\n\n\n\n\n\n\nSummary Statistics\n\n\nVariable\nN\nMean\nSD\n\n\n\n\nw: 0\n\n\n\n\n\neta\n49913\n-0.0015\n1\n\n\nx\n49913\n0.25\n0.43\n\n\ny0\n49913\n2.8\n1.6\n\n\ny1\n49913\n7.8\n1.6\n\n\ny\n49913\n2.8\n1.6\n\n\nw: 1\n\n\n\n\n\neta\n50087\n-0.00096\n1\n\n\nx\n50087\n0.75\n0.43\n\n\ny0\n50087\n4.2\n1.6\n\n\ny1\n50087\n9.2\n1.6\n\n\ny\n50087\n9.2\n1.6"
  },
  {
    "objectID": "slides/causality/index.html#conditional-mean-independence-4",
    "href": "slides/causality/index.html#conditional-mean-independence-4",
    "title": "E655 - Econometrics",
    "section": "Conditional Mean Independence",
    "text": "Conditional Mean Independence\n\n\n\nWhat if we focus only on people with \\(x=1\\)?\nNo difference in \\(y_{0}\\) between treated and control\n\nBecause \\(x\\) is only reason why they differed\nThis is holding \\(x\\) fixed\n\n\n\n\nsumtable(filter(data3, x==1), \n         summ=c('notNA(x)','mean(x)','sd(x)'),\n         summ.names = c('N', 'Mean', 'SD' ),\n         group=\"w\")\n\n\nSummary Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nw\n\n\n0\n\n\n1\n\n\n\nVariable\nN\nMean\nSD\nN\nMean\nSD\n\n\n\n\neta\n12528\n-0.0032\n1\n37517\n0.0032\n1\n\n\nx\n12528\n1\n0\n37517\n1\n0\n\n\ny0\n12528\n5\n1\n37517\n5\n1\n\n\ny1\n12528\n10\n1\n37517\n10\n1\n\n\ny\n12528\n5\n1\n37517\n10\n1"
  },
  {
    "objectID": "slides/causality/index.html#conditional-mean-independence-5",
    "href": "slides/causality/index.html#conditional-mean-independence-5",
    "title": "E655 - Econometrics",
    "section": "Conditional Mean Independence",
    "text": "Conditional Mean Independence\n\n\n\nSame result if we hold \\(x=0\\)?\n\nAgain because \\(x\\) is only reason why they differed\n\n\n\n\nsumtable(filter(data3, x==0), \n         summ=c('notNA(x)','mean(x)','sd(x)'),\n         summ.names = c('N', 'Mean', 'SD' ),\n         group=\"w\")\n\n\nSummary Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nw\n\n\n0\n\n\n1\n\n\n\nVariable\nN\nMean\nSD\nN\nMean\nSD\n\n\n\n\neta\n37385\n-0.0009\n0.99\n12570\n-0.013\n1\n\n\nx\n37385\n0\n0\n12570\n0\n0\n\n\ny0\n37385\n2\n0.99\n12570\n2\n1\n\n\ny1\n37385\n7\n0.99\n12570\n7\n1\n\n\ny\n37385\n2\n0.99\n12570\n7\n1"
  },
  {
    "objectID": "slides/causality/index.html#conditional-mean-independence-6",
    "href": "slides/causality/index.html#conditional-mean-independence-6",
    "title": "E655 - Econometrics",
    "section": "Conditional Mean Independence",
    "text": "Conditional Mean Independence\n\n\n\nRegression of \\(y\\) on \\(w\\) is biased\n\nBecause \\(w\\) is correlated with error\n\nBut regression of \\(y\\) on \\(w\\) and \\(x\\) generates actual treatment effect\nThis is conditional mean independence\n\nHolding \\(x\\) fixed, potential outcomes no longer related to treatment\n\n\n\n\nlm(y ~ w, data3)\n## \n## Call:\n## lm(formula = y ~ w, data = data3)\n## \n## Coefficients:\n## (Intercept)            w  \n##       2.752        6.495\nlm(y ~ w + x, data3)\n## \n## Call:\n## lm(formula = y ~ w + x, data = data3)\n## \n## Coefficients:\n## (Intercept)            w            x  \n##       1.997        4.997        3.007"
  },
  {
    "objectID": "slides/causality/index.html#regression-slopes-and-potential-outcomes",
    "href": "slides/causality/index.html#regression-slopes-and-potential-outcomes",
    "title": "E655 - Econometrics",
    "section": "Regression Slopes and Potential Outcomes",
    "text": "Regression Slopes and Potential Outcomes\n\nSuppose we regress \\(y\\) on \\(w\\)\nThe slope in this regression is \\(\\beta = E(y|w=1) - E(y|w=0)\\)\nExpress in terms of potential outcomes\n\\[E(y|w=1) - E(y|w=0)\\] \\[=  E(y_{1}|w=1) - E(y_{0}|w=0)\\] \\[= \\left [ E(y_{1}|w=1) - E(y_{0}|w=1) \\right ] + E(y_{0}|w=1) - E(y_{0}|w=0)\\]\nThe first term is called the Average Treatment Effect on the Treated (ATT)\n\nAverage effect of the treatment for those in the treatment group\n\n\n\n\n\n\n\n\nNote\n\n\nGroups in the population can have different treatment effects, so there isn’t necessarily a single treatment or causal effect."
  },
  {
    "objectID": "slides/causality/index.html#selection-bias",
    "href": "slides/causality/index.html#selection-bias",
    "title": "E655 - Econometrics",
    "section": "Selection bias",
    "text": "Selection bias\n\nThe second term is Selection Bias\n\nPreexisting difference between treatment and control groups\n\nExample: \\(y\\) is income, and \\(w\\) is going to university\n\nSelection bias is potential income difference in absence of university\nWould happen if people who end up in university are already smarter\n\nIf selection bias exists, regression slope is a combination of treatment effect and bias\nThere are some cases where there is no selection bias, and regression slope is only causal effect\nWe outline those below"
  },
  {
    "objectID": "slides/causality/index.html#continuous-treatment",
    "href": "slides/causality/index.html#continuous-treatment",
    "title": "E655 - Econometrics",
    "section": "Continuous Treatment",
    "text": "Continuous Treatment\n\nWe can also apply this model to a continuous treatment variable\nAll of the intuition we have discussed at the same\n\nJust slightly more complex because treatment is continuous"
  },
  {
    "objectID": "slides/causality/index.html#summary-of-rubin-model",
    "href": "slides/causality/index.html#summary-of-rubin-model",
    "title": "E655 - Econometrics",
    "section": "Summary of Rubin Model",
    "text": "Summary of Rubin Model\n\nRegression will identify a causal effect if\n\nTreatment comes from a randomized experiment\nPotential outcomes are mean independent of treatment\nPotential outcomes are mean independent of treatment conditional on \\(\\mathbf{x}\\)\n\nWithout one of these, we could have selection bias\n\nRegression does not provide a causal effect\n\nUnfortunately, these assumptions are generally not met\n\nWe will cover other methods to uncover the causal effect in this case"
  },
  {
    "objectID": "slides/causality/index.html#introduction-2",
    "href": "slides/causality/index.html#introduction-2",
    "title": "E655 - Econometrics",
    "section": "Introduction",
    "text": "Introduction\n\nThis section will demonstrate the Rubin model with simulated data\nWe will show what happens in regression under different assumptions\nUse large samples to simulate the population\n\nReplace population values with consistent estimators\n\nWe will simulate both potential outcomes\n\nEven though they would not both be observed in practice"
  },
  {
    "objectID": "slides/causality/index.html#summary-of-rubin-model-3",
    "href": "slides/causality/index.html#summary-of-rubin-model-3",
    "title": "E655 - Econometrics",
    "section": "Summary of Rubin Model",
    "text": "Summary of Rubin Model\n\nWhen our regression model identifies an underlying causal effect, we call it a structural model\nIn many econometric applications, this is what we want\nNext, we discuss in more detail linear regression\nFirst we discuss the population model\n\nWe will define the parameters we are measuring\nSome of this might be new\n\nThen we discuss estimation by OLS\n\nFocus is on when OLS consistently estimates the parameters"
  },
  {
    "objectID": "slides/causality/index.html#basic-dag",
    "href": "slides/causality/index.html#basic-dag",
    "title": "E655 - Econometrics",
    "section": "Basic DAG",
    "text": "Basic DAG\n\n\n\nSuppose we are interested in the direct effect of \\(w\\) on \\(y\\)\n\n\\(w\\) is the treatment\n\\(y\\) is the outcome\n\nThe DAG to the right shows how \\(w\\) and \\(y\\) could be related\n\\(x\\) is another factor that is related to both \\(w\\) and \\(y\\)\nThe dots (with variable names) are nodes\nThe lines connecting nodes are edges\nDirection of the arrows is the direction of the relationship"
  },
  {
    "objectID": "slides/causality/index.html#basic-dag-1",
    "href": "slides/causality/index.html#basic-dag-1",
    "title": "E655 - Econometrics",
    "section": "Basic DAG",
    "text": "Basic DAG\n\n\n\nWe want to find all the paths that can lead from \\(w\\) to \\(y\\)\nIn this DAG there are two\n\nA direct path \\(w \\rightarrow y\\)\nAn indirect path \\(w \\leftarrow x \\rightarrow y\\)\n\nA correlation between \\(y\\) on \\(w\\) would reflect both paths\n\n\\(w\\) can directly cause \\(y\\)\n\\(x\\) could change \\(w\\) and \\(y\\) simultaneously creating a spurious correlation between them"
  },
  {
    "objectID": "slides/causality/index.html#backdoor-path",
    "href": "slides/causality/index.html#backdoor-path",
    "title": "E655 - Econometrics",
    "section": "Backdoor Path",
    "text": "Backdoor Path\n\n\n\nA backdoor path is a non-causal (indirect) relationship between variables of interest\nIn this DAG, the confounder \\(z\\) sits on the backdoor path between \\(x\\) and \\(y\\)\nA regression of \\(y\\) on \\(x\\) would not identify a causal effect\n\nIt is a mixture of causal effect and the indirect relationship\n\nIn this regression the backdoor path is open, allowing the indirect effect\nWe can close the backdoor path by holding \\(z\\) constant\n\nA regression of \\(y\\) on \\(x\\) and \\(z\\) allows only the direct effect"
  },
  {
    "objectID": "slides/causality/index.html#types-of-paths",
    "href": "slides/causality/index.html#types-of-paths",
    "title": "E655 - Econometrics",
    "section": "Types of Paths",
    "text": "Types of Paths\n\n\n\nIn a DAG you may find two types of paths\n\nFront Door: arrows point away from treatment and toward to outcome\nBack Door: arrows point toward treatment\n\nWe are usually interested in front door paths\n\nShow how \\(w\\) causes changes in \\(y\\)\n\nBack door paths are usually bad\n\nShow ways that a correlation between treatment and outcome are biased\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaution\n\n\nThere can be multiple front door paths in a DAG, and we might not be interested in all of them."
  },
  {
    "objectID": "slides/causality/index.html#basic-dag-2",
    "href": "slides/causality/index.html#basic-dag-2",
    "title": "E655 - Econometrics",
    "section": "Basic DAG",
    "text": "Basic DAG\n\n\n\nThere are two ways that \\(x\\) and \\(y\\) are connected\n\nA direct path \\(x \\rightarrow y\\)\nAn indirect path \\(x \\leftarrow z \\rightarrow y\\)\n\nThis depicts a confounding variable\n\n\\(x\\) causes changes in \\(y\\)\n\\(z\\) jointly changes \\(x\\) and \\(y\\) leading to spurious link between \\(x\\) and \\(y\\)\n\nIn DAG terminology \\(z\\) is a confounder"
  },
  {
    "objectID": "slides/causality/index.html#open-and-closed-paths",
    "href": "slides/causality/index.html#open-and-closed-paths",
    "title": "E655 - Econometrics",
    "section": "Open and Closed Paths",
    "text": "Open and Closed Paths\n\n\n\nPaths between treatment and outcome can be open or closed\n\nOpen: all variables along the path are allowed to vary\nClosed: at least one variable along the path cannot vary, or there is a collider on the path\n\nIf you regress \\(y\\) on \\(w\\) both paths are open\n\n\\(w\\) and \\(y\\) can vary, so direct path is open\nWe are not holding \\(x\\) fixed, so indirect path is also open\n\nYou can close the backdoor path by controlling for \\(x\\)\n\nRegress \\(y\\) on \\(w\\) and \\(x\\)"
  },
  {
    "objectID": "slides/causality/index.html#open-and-closed-paths-1",
    "href": "slides/causality/index.html#open-and-closed-paths-1",
    "title": "E655 - Econometrics",
    "section": "Open and Closed Paths",
    "text": "Open and Closed Paths\n\n\n\nSuppose we are interested in the causal effect of \\(w\\) on \\(y\\)\nIn a DAG, this means we only want the path \\(w \\rightarrow y\\)\nWe need to leave this path open, but close all others\nThe regression of \\(y\\) on \\(w\\) and \\(x\\) does this\nIt works in this case because \\(x\\) is a confounder\nControlling for other variables does not always identify a causal effect"
  },
  {
    "objectID": "slides/causality/index.html#three-dags",
    "href": "slides/causality/index.html#three-dags",
    "title": "E655 - Econometrics",
    "section": "Three DAGs",
    "text": "Three DAGs"
  },
  {
    "objectID": "slides/causality/index.html#different-associations-in-dag",
    "href": "slides/causality/index.html#different-associations-in-dag",
    "title": "E655 - Econometrics",
    "section": "Different Associations in DAG",
    "text": "Different Associations in DAG\n\n\n\n\n\n\n\n\n\n\n\n\nConfounder\n\n\n\n\n\n\n\n\n\n\n\n\nMediator\n\n\n\n\n\n\n\n\n\n\n\n\nCollider"
  },
  {
    "objectID": "slides/causality/index.html#different-associations-in-dag-1",
    "href": "slides/causality/index.html#different-associations-in-dag-1",
    "title": "E655 - Econometrics",
    "section": "Different Associations in DAG",
    "text": "Different Associations in DAG"
  },
  {
    "objectID": "slides/causality/index.html#confounder",
    "href": "slides/causality/index.html#confounder",
    "title": "E655 - Econometrics",
    "section": "Confounder",
    "text": "Confounder\n\n\n\nThe DAG we have been working with has \\(x\\) as a confounder\nConfounder: The treatment and outcome have a common cause\nIn this example\n\n\\(x\\) changes \\(w\\) and \\(y\\) simultaneously\nMakes it look like \\(w\\) and \\(y\\) are related, but it is spurious\n\nExample: Returns to Schooling\n\n\\(y\\) is wages, \\(w\\) is years of schooling\nA confounder \\(x\\) would be intelligence\n\nCan close the backdoor path by controlling for \\(x\\)"
  },
  {
    "objectID": "slides/causality/index.html#mediator",
    "href": "slides/causality/index.html#mediator",
    "title": "E655 - Econometrics",
    "section": "Mediator",
    "text": "Mediator\n\n\n\nIn this DAG we have two paths\n\n\\[w \\rightarrow y\\] \\[w \\rightarrow x \\rightarrow y\\]\n\nBoth are front door paths\nIn this example \\(x\\) acts as a mediator\nMediator: A variable within a causal pathway between treatment and outcome\nIn this example\n\n\\(w\\) causes \\(y\\) directly\nBut also indirectly through \\(x\\)"
  },
  {
    "objectID": "slides/causality/index.html#mediator-1",
    "href": "slides/causality/index.html#mediator-1",
    "title": "E655 - Econometrics",
    "section": "Mediator",
    "text": "Mediator\n\n\n\nThis is not the same as omitted variables bias\nA regression of \\(y\\) on \\(w\\) measures the causal effect\n\nTwo causal paths between \\(w\\) and \\(y\\)\n\nWe can still close the indirect path by controlling for \\(x\\)\nThis would leave only the direct path\nWhether we want to do this depends on the research question\n\nIf you want only direct effect, control for \\(x\\)\nFor total effect, do not control"
  },
  {
    "objectID": "slides/causality/index.html#mediator-2",
    "href": "slides/causality/index.html#mediator-2",
    "title": "E655 - Econometrics",
    "section": "Mediator",
    "text": "Mediator\n\n\n\nExample: Effect of drinking on lifespan\n\\(w\\) is drinking, \\(y\\) is lifespan, \\(x\\) is drug use\nIf drug use is a mediator then\n\n\\[drinking \\rightarrow lifespan\\] \\[drinking \\rightarrow drugs \\rightarrow lifespan\\]\n\nDrinking has direct effect on lifespan, and also through drug use\nRegression of \\(lifespan\\) on \\(drinking\\) measures total effect\nRegression of \\(lifespan\\) on \\(drinking\\) and \\(drug\\) use measures only direct effect"
  },
  {
    "objectID": "slides/causality/index.html#collider",
    "href": "slides/causality/index.html#collider",
    "title": "E655 - Econometrics",
    "section": "Collider",
    "text": "Collider\n\n\n\nFinal association is trickier\nCollider: a variable that is influenced by two or more variables\nIn this DAG, \\(x\\) is a collider\n\nBoth \\(y\\) and \\(w\\) point to it\n\nPaths that contain a collider are closed\nIn this case, you could regress \\(y\\) on \\(w\\) and get causal effect"
  },
  {
    "objectID": "slides/causality/index.html#collider-1",
    "href": "slides/causality/index.html#collider-1",
    "title": "E655 - Econometrics",
    "section": "Collider",
    "text": "Collider\n\n\n\nControlling for a collider opens the path\nRegression of \\(y\\) on \\(w\\) and \\(x\\) does not measure causal effect\nCollider Bias: bias induced by controlling for collider\nCollider bias can\n\nCreate an association between \\(w\\) and \\(y\\) when there is no direct one\nHide a direct association\n\nEasiest way to understand is through example"
  },
  {
    "objectID": "slides/causality/index.html#collider-2",
    "href": "slides/causality/index.html#collider-2",
    "title": "E655 - Econometrics",
    "section": "Collider",
    "text": "Collider\n\n\n\nExample: talent and effort\n\\(w\\) is talent, \\(y\\) is effort, \\(x\\) is being in elite school\nAssume no direct link between talent and effort\nBoth talented and hard working students make it to elite schools\nControlling for school, talent and effort look negatively related\n\nYou need to be smart or work hard to get into Harvard\nLow-effort students must be smart, and un-smart students must be hard working"
  },
  {
    "objectID": "slides/causality/index.html#collider-3",
    "href": "slides/causality/index.html#collider-3",
    "title": "E655 - Econometrics",
    "section": "Collider",
    "text": "Collider\n\n\n\nExample: gender pay gap\n\\(w\\) is gender, \\(y\\) is ability, \\(x\\) is occupation\nAssume men and women have equal ability\nHigh ability people make it into certain occupations\nIf discrimination against women, they must be high ability to get in\nControlling for occupation, women appear to have higher ability\nThis could lead to gender pay gap being larger within jobs"
  },
  {
    "objectID": "slides/causality/index.html#a-more-complicated-dag",
    "href": "slides/causality/index.html#a-more-complicated-dag",
    "title": "E655 - Econometrics",
    "section": "A More Complicated DAG",
    "text": "A More Complicated DAG\n::: columns ::: {.column width=“50%”}\n\nDAGs are often much more complicated\nHere is a DAG with 4 variables\n\n\\(y\\) is outcome\n\\(w\\) is treatment\n\\(x\\) is confounder\n\\(u\\) is unobserved confounder\n\nThere are several paths connecting \\(w\\) and \\(y\\)\n\n\\(w \\rightarrow y\\)\n\\(w \\leftarrow x \\rightarrow y\\)\n\\(w \\leftarrow x \\rightarrow u \\rightarrow y\\)"
  },
  {
    "objectID": "slides/causality/index.html#a-more-complicated-dag-1",
    "href": "slides/causality/index.html#a-more-complicated-dag-1",
    "title": "E655 - Econometrics",
    "section": "A More Complicated DAG",
    "text": "A More Complicated DAG\n\n\n\nTo close a backdoor path you need to control for one variable along the path\nWe cannot control for \\(u\\) because it is unobserved\nControlling for \\(x\\) closes both backdoor paths"
  },
  {
    "objectID": "slides/causality/index.html#introduction-3",
    "href": "slides/causality/index.html#introduction-3",
    "title": "E655 - Econometrics",
    "section": "Introduction",
    "text": "Introduction\n\nThe Rubin framework is one way to understand causality\nAnother popular method is a Directed Acyclic Graph (DAG)\nA DAG is a graphical tool to show relationships between variables\nIt can make a complex model easier to understand\nFor econometrics, it can highlight bias in our estimates\n\nAnd how to overcome the bias\n\nIn this section we will introduce DAGs, and expand on it in further sections"
  },
  {
    "objectID": "slides/causality/index.html#introduction-4",
    "href": "slides/causality/index.html#introduction-4",
    "title": "E655 - Econometrics",
    "section": "Introduction",
    "text": "Introduction\n\nLike we did with Rubin model, we can simulate DAGs\nWe will illustrate\n\nConditional independence\nCollider bias\n\nAgain, this is meant to approximate the population"
  },
  {
    "objectID": "slides/causality/index.html#conditional-independence",
    "href": "slides/causality/index.html#conditional-independence",
    "title": "E655 - Econometrics",
    "section": "Conditional Independence",
    "text": "Conditional Independence\n\n\n\nConsider the following scenario\n\nHigher ability people get more schooling\nHigher ability people earn more\nHigher education increases earnings\nHigher ability is related to unobserved determinants of earnings\n\nWithout controlling for ability we will overestimate the effect of education\n\n\n\ndagdata &lt;- tibble(\n    ability = rnorm(10000),\n    educ = ifelse(ability + rnorm(10000, mean = 0, sd = 0.5) &gt; 1,1,0),\n    u = ability + rnorm(10000, mean = 0, sd = 2),\n    inc = educ + ability + u \n)\n\nlm(inc ~ educ, data = dagdata)\n## \n## Call:\n## lm(formula = inc ~ educ, data = dagdata)\n## \n## Coefficients:\n## (Intercept)         educ  \n##     -0.6213       4.2127"
  },
  {
    "objectID": "slides/causality/index.html#collider-bias",
    "href": "slides/causality/index.html#collider-bias",
    "title": "E655 - Econometrics",
    "section": "Collider Bias",
    "text": "Collider Bias\n\n\n\nConsider the following scenario\n\nTalent is unrelated to effort\nBoth talent and effort are positively related to being in an elite school\nElite school admission is based on having high talent or effort\n\nWe will see that\nWithout controlling for elite school, talent and effort are unrelated\nControlling for elite school, talent and effort are negatively related\n\n\n\ndagdata2 &lt;- tibble(\n    talent = rnorm(10000),\n    effort = rnorm(10000),\n    elite = ifelse(talent + effort &gt; 1,1,0)\n)\n\nggplot(dagdata2, aes(x = effort, y = talent)) +\n  geom_point(alpha = 0.2) +\n  geom_smooth(method = \"lm\", se = FALSE)"
  },
  {
    "objectID": "slides/causality/index.html#collider-bias-1",
    "href": "slides/causality/index.html#collider-bias-1",
    "title": "E655 - Econometrics",
    "section": "Collider Bias",
    "text": "Collider Bias\n\n\n\nNow color the dots according to elite school status\nThen run separate regressions by elite school\nWithin school, talent and effort are negatively related\n\n\n\nggplot(dagdata2,aes(x = effort, y = talent, color = as.factor(elite)) ) +\n  geom_point(alpha = 0.2) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  theme_pander() +\n  scale_color_grey()"
  },
  {
    "objectID": "slides/causality/index.html#collider-bias-2",
    "href": "slides/causality/index.html#collider-bias-2",
    "title": "E655 - Econometrics",
    "section": "Collider Bias",
    "text": "Collider Bias\n\n\n\nYou can see this in regression too\nFirst regress talent on effort\n\nNo relationship\n\nNegative relationship when controlling for elite school status\n\n\n\nlm(talent ~ effort, data = dagdata2)\n## \n## Call:\n## lm(formula = talent ~ effort, data = dagdata2)\n## \n## Coefficients:\n## (Intercept)       effort  \n##   -0.003301    -0.018345\nlm(talent ~ effort + elite, data = dagdata2) \n## \n## Call:\n## lm(formula = talent ~ effort + elite, data = dagdata2)\n## \n## Coefficients:\n## (Intercept)       effort        elite  \n##     -0.3948      -0.3740       1.6407"
  },
  {
    "objectID": "slides/causality/index.html#conditional-independence-1",
    "href": "slides/causality/index.html#conditional-independence-1",
    "title": "E655 - Econometrics",
    "section": "Conditional Independence",
    "text": "Conditional Independence\n\n\n\nIn the DAG, there are two backdoor paths from education to earnings\n\n\\(educ \\leftarrow ability \\rightarrow inc\\)\n\\(educ \\leftarrow ability \\rightarrow u \\rightarrow inc\\)\n\nControlling for ability closes both paths\n\nWe do not need to separately control for \\(u\\)\n\n\n\n\ndagdata &lt;- tibble(\n    ability = rnorm(10000),\n    educ = ifelse(ability + rnorm(10000, mean = 0, sd = 0.5) &gt; 1,1,0),\n    u = ability + rnorm(10000, mean = 0, sd = 2),\n    inc = educ + ability + u \n)\n\nlm(inc ~ educ + ability, data = dagdata)\n## \n## Call:\n## lm(formula = inc ~ educ + ability, data = dagdata)\n## \n## Coefficients:\n## (Intercept)         educ      ability  \n##    0.003091     1.030121     2.006510"
  },
  {
    "objectID": "slides/causality/index.html#omitted-variables-bias-in-regression",
    "href": "slides/causality/index.html#omitted-variables-bias-in-regression",
    "title": "E655 - Econometrics",
    "section": "Omitted Variables Bias in Regression",
    "text": "Omitted Variables Bias in Regression\n\nPartition the \\(\\mathbf{x}\\) vector into two pieces\n\n\\[\\mathbf{x}=\n\\begin{bmatrix}\n\\mathbf{x_{1}}& \\mathbf{x_{2}}  \n\\end{bmatrix}\\]\n\nNow imagine running a regression of \\(\\mathbf{y}\\) on only \\(\\mathbf{x_{1}}\\)\nThe slope of that regression is\n\\[\n\\boldsymbol{\\beta^{*}} = (\\textbf{E}[\\mathbf{x_{1}'x_{1}}])^{-1} \\textbf{E}[\\mathbf{x_{1}}'y]\n\\]\nSub in for \\(\\mathbf{y}\\) using the full \\(\\mathbf{x}\\) vector\n\\[\\boldsymbol{\\beta^{*}} = (\\textbf{E}[\\mathbf{x_{1}'x_{1}}])^{-1} \\textbf{E}[\\mathbf{x_{1}}'(\\mathbf{x_{1}}\\boldsymbol{\\beta_{1}} + \\mathbf{x_{2}}\\boldsymbol{\\beta_{2}} + u)]\\]\n\\[\\boldsymbol{\\beta^{*}} = \\boldsymbol{\\beta_{1}} + (\\textbf{E}[\\mathbf{x_{1}'x_{1}}])^{-1} \\textbf{E}[\\mathbf{x_{1}}'\\mathbf{x_{2}}]\\boldsymbol{\\beta_{2}} \\]"
  },
  {
    "objectID": "slides/causality/index.html#omitted-variables-bias-in-regression-1",
    "href": "slides/causality/index.html#omitted-variables-bias-in-regression-1",
    "title": "E655 - Econometrics",
    "section": "Omitted Variables Bias in Regression",
    "text": "Omitted Variables Bias in Regression\n\n\n\n\n\n\nImportant\n\n\nOmitted Variables Bias in Regression is\n\\[(\\textbf{E}[\\mathbf{x_{1}'x_{1}}])^{-1} \\textbf{E}[\\mathbf{x_{1}}'\\mathbf{x_{2}}]\\boldsymbol{\\beta_{2}} \\]\n\n\n\n\nOVB is a function of two things\n\nThe relationship between \\(\\mathbf{x_{2}}\\) and \\(\\mathbf{x_{1}}\\)\nThe relationship between \\(\\mathbf{x_{2}}\\) and \\(y\\)\n\nIf either of them is zero, there is no OVB\nThe sign of the bias depends on the sign of their product\n\nIf they have the same sign, bias is positive\nIf they have opposite signs, bias is negative"
  },
  {
    "objectID": "assignments/introtoquarto.html",
    "href": "assignments/introtoquarto.html",
    "title": "Introduction to Quarto",
    "section": "",
    "text": "The .zip file below contains the files to run a learnr interactive tutorial. To use it, first ensure that you have installed the learnr and shiny packages. Then, download the file, unpack it, open the .Rmd file in RStudio, and click “run document.”\nThere is also a plain, non-interactive PDF version of the file below.\n EC655quarto.zip\n EC655quartopdf.pdf"
  },
  {
    "objectID": "assignments/introtoquarto.html#readings",
    "href": "assignments/introtoquarto.html#readings",
    "title": "Introduction to Quarto",
    "section": "",
    "text": "Hanck, C., Arnold, M., Gerber, A., & Schmelzer, M. (2019). Introduction to Econometrics with R. University of Duisburg-Essen. Url: https://www.econometrics-with-r.org\nOswald, F., Viers, V., Robin, J.- M., Villedieu, P., Kenedi, G. (2020). Introduction to Econometrics with R. Department of Economics, Sciences Po. Url: https://scpoecon.github.io/ScPoEconometrics/"
  },
  {
    "objectID": "assignments/introtoquarto.html#tutorial",
    "href": "assignments/introtoquarto.html#tutorial",
    "title": "Introduction to Quarto",
    "section": "",
    "text": "The .zip file below contains the files to run a learnr interactive tutorial. To use it, first ensure that you have installed the learnr and shiny packages. Then, download the file, unpack it, open the .Rmd file in RStudio, and click “run document.”\nThere is also a plain, non-interactive PDF version of the file below.\n EC655quarto.zip\n EC655quartopdf.pdf"
  },
  {
    "objectID": "assignments/introtoquarto.html#videos",
    "href": "assignments/introtoquarto.html#videos",
    "title": "Introduction to Quarto",
    "section": "Videos",
    "text": "Videos\n\nIntroduction to Quarto by Dr. Lyndon Walker\nA video introduction to Quarto"
  },
  {
    "objectID": "assignments/introtoquarto.html#other-resources",
    "href": "assignments/introtoquarto.html#other-resources",
    "title": "Introduction to Quarto",
    "section": "Other Resources",
    "text": "Other Resources\n\nQuarto Website Reference Section\n\nThe Quarto website has a very good reference section for any type of document you want to produce. Navigate to the PDF section for help with formatting your assignments.\n\nQuarto Cheat Sheet\n\nLike with the RStudio cheat sheets, this provides a quick overview of the ways you can interact with Quarto"
  },
  {
    "objectID": "assignments/index.html",
    "href": "assignments/index.html",
    "title": "Summary",
    "section": "",
    "text": "Here you will find the problem sets for all your assignments, and any other information related to your assignments.",
    "crumbs": [
      "Assignments",
      "Overview",
      "Summary"
    ]
  },
  {
    "objectID": "assignments/assign1.html",
    "href": "assignments/assign1.html",
    "title": "Assignment 1",
    "section": "",
    "text": "Answer Key\n\n\n\nYou can download the solutions using the links below\n a1solutions.qmd\n a1solutions.pdf"
  },
  {
    "objectID": "assignments/assign1.html#assignment-description",
    "href": "assignments/assign1.html#assignment-description",
    "title": "Assignment 1",
    "section": "",
    "text": "In this assignment you are asked to manipulate data, estimate statistical relationships, and interpret the findings. The questions below guide you through the process of statistical estimation. You are given an R script that generates datasets for you to use. In places where it asks you to execute additional commands (like creating a variable, running a regression), refer to the R script we worked through in class. If anything is unclear, you can use the R help function by typing a question mark and then the name of the command. For example, if I wanted help with the mutate command, I would type “?mutate()”. If you are still looking for help, usually googling the name of the command and the word “example” will provide many useful resources. I am also of course available to help.\nI strongly suggest that you start this assignment early because it will not be possible (in my opinion) to do well if you start close to the due date. There are parts that you may find difficult; you will want to identify them and leave enough time to ask questions if necessary."
  },
  {
    "objectID": "assignments/assign1.html#assignment-instructions",
    "href": "assignments/assign1.html#assignment-instructions",
    "title": "Assignment 1",
    "section": "Assignment Instructions",
    "text": "Assignment Instructions\n\nData analysis\nIn mylearningspace, you will find an R script called “EC655 Assign1.R” that contains some code you need to complete the assignment. All students must use this file to generate their data and write the code to answer the questions. Before using the R script, you need to do the following:\n\nRename the file from “EC655 Assign1.R” to your family name followed by your student number (no spaces)\nIn the two places where the command set.seed() appears, replace INSERT YOUR STUDENT NUMBER HERE with your full student number. Be sure to include the set.seed() command whenever you run the file.\n\nLeave all other commands that currently exist in the R script untouched. Write your code to answer the question in the area indicated inside the comments.\nNote that this file generates random data depending on your student number, so each student’s data will be different, and therefore answers will also be different.\n\n\nSubmission\nYou are required to submit two documents according to the following instructions:\n\nYour .qmd file containing all of the input you used to produce your report. Submit this in MyLearningSpace only.\nA rendered PDF of your .qmd file. Submit this in both MyLearningSpace and Gradescope.\n\nIn the report described in (a) above, please answer all questions in the same order as they are stated on the question sheet. For each question and sub-question, include the relevant R code (if any) that you used, the output generated by that command if there was any, and an interpretation if you are asked to provide it. For example, if you were answering the following hypothetical question, it might look like this:\nYou could also format your own output tables rather than copying and pasting R output if you find it easier. The key is that as long as the questions are answered in order, and the R commands used for each question and associated output are clear, it will be fine.\nA note on plagiarism: this is an independent assignment, which I expect you to complete on your own. It is plagiarism to copy someone else’s work verbatim, which includes R code. Any work you submit should be yours only."
  },
  {
    "objectID": "assignments/assign1.html#preparation",
    "href": "assignments/assign1.html#preparation",
    "title": "Assignment 1",
    "section": "",
    "text": "In this assignment you are asked to manipulate data, estimate statistical relationships, and interpret the findings. The questions below guide you through the process of statistical estimation. If anything is unclear, you can use the R help function by typing a question mark and then the name of the command. For example, if I wanted help with the mutate command, I would type “?mutate()”. If you are still looking for help, usually googling the name of the command and the word “example” will provide many useful resources. I am also of course available to help.\nI strongly suggest that you start this assignment early because it will not be possible (in my opinion) to do well if you start close to the due date. There are parts that you may find difficult; you will want to identify them and leave enough time to ask questions if necessary.\n\n\n\nYou are required to produce your submission in Quarto. As we discussed in class, this is a document publishing system where you can include both the text and the code in the same document for easy reproducibility. See the quarto tutorial we discussed in class to get started.\n\n\n\nPlease download the template below and use it for the assignment. Replace the relevant parts in the YAML section, and fill out the rest with your answers to the questions. Then rename the file with your family name followed by your student ID number.\n a1template.qmd\n\n\n\nPart of the assignment involves data analysis in R, which you will include as code chunks in the Quarto document. Please make sure all of your analysis is contained in your Quarto document and that it runs properly.\nYou will see that in part of the template the set.seed() function appears. This is a random number generator seed that ensures that when you take a random sample of data, it is the same every time so that your results are reproducible. Insert your student ID number inside the brackets; this ensures that you create random samples that are unique to you.\nBecause your are using a random number seed unique to you, each student’s output will be different.\nYou will need the following data files. Be sure to save them in the same directory as your template file.\n econmath.csv\n\n\n\nWhen you are finished, you are required to submit two documents according to the following instructions:\n\nYour .qmd file containing all of the input you used to produce your report. Submit this in MyLearningSpace only.\nA rendered PDF of your .qmd file. Submit this in both MyLearningSpace and Gradescope.\n\nIn your PDF, please include both the code and output for each code chunk you produce (i.e. make sure echo = TRUE for those chunks). Try your best to make sure the output is formatted in a way that is readable, but don’t spend too much time tinkering with it to make it perfect.\n\n\n\nThis is an independent assignment, which I expect you to complete on your own. It is plagiarism to copy someone else’s work verbatim, which includes R code. Any work you submit should be yours only. However, you are encouraged to talk to each other to try to figure out how to do the assignment."
  },
  {
    "objectID": "assignments/assign1.html#instructions",
    "href": "assignments/assign1.html#instructions",
    "title": "Assignment 1",
    "section": "Instructions",
    "text": "Instructions\n\nTemplate\nThe template below contains the assignment questions. Please answer then all within the template in the appropriate place. Replace everything in all caps with your information, and add code where asked.\nWhen you save the file to your computer, please rename it with your family name and student number, with no spaces.\n a1template.qmd\n\n\nData analysis\nPart of the assignment involves data analysis in R, which you will include as code chunks in the Quarto document. Please make sure all of your analysis is contained in your Quarto document and that it runs properly. Make note of the packages used in the file and ensure you have them installed in RStudio. Also make sure you have a Tex distribution installed on your machine.\nPart of the analysis uses the following data file. Save it in the same directory as your template file.\n econmath.csv\nA description of all of the variables in the dataset is here\n datadesc.pdf\n\n\nSubmission\nWhen you are finished, you are required to submit two documents according to the following instructions:\n\nYour .qmd file containing the completed template file. Submit this in MyLearningSpace only.\nA rendered PDF of your .qmd file. Submit this in both MyLearningSpace and Gradescope.\n\nThe template is structured to output both the code and the results of the code. Please ensure that this is the case in your rendered PDF because I will grade only that document. I will go to the .qmd file only in cases when something in your PDF does not make sense.\n\n\nPlagiarism\nThis is an independent assignment, which I expect you to complete on your own. It is plagiarism to copy someone else’s work verbatim, which includes R code. Any work you submit should be yours only. However, you are encouraged to talk to each other to try to figure out how to do the assignment."
  },
  {
    "objectID": "assignments/assign1.html#description",
    "href": "assignments/assign1.html#description",
    "title": "Assignment 1",
    "section": "Description",
    "text": "Description\nIn this assignment you are asked to manipulate data, estimate statistical relationships, and interpret the findings. The questions are based on course content we have covered up to now, so if you get stuck I highly recommend going back over that material because the questions are closely related. This includes both the lecture notes and the extra material posted to the course website.\nYou should start this assignment early because it will not be possible (in my opinion) to do well if you start close to the due date. There are parts that you may find difficult; you will want to identify them and leave enough time to ask questions if necessary."
  },
  {
    "objectID": "content/causality.html#tutorials",
    "href": "content/causality.html#tutorials",
    "title": "Causality",
    "section": "Tutorials",
    "text": "Tutorials\nThe .zip file below contains the files to run a learnr interactive tutorial. To use it, first ensure that you have installed the learnr and shiny packages. Then, download the file, unpack it, open the .Rmd file in RStudio, and click “run document.”\nThere is also a plain, non-interactive PDF version of the file below.\n EC655dag.zip\n EC655dagpdf.pdf"
  },
  {
    "objectID": "slides/ols/index.html#estimation-by-method-of-moments",
    "href": "slides/ols/index.html#estimation-by-method-of-moments",
    "title": "\nOrdinary Least Squares\n",
    "section": "Estimation by Method of Moments",
    "text": "Estimation by Method of Moments\n\nRecall that the population linear regression model is\n\\[y = \\mathbf{x}\\boldsymbol{\\beta} + u\\]\nWe wish to estimate the slope parameters of this model\nThe first step is to collect a sample \\(\\{(\\mathbf{x}_{i},y_{i}): i=1,2,...,n)\\}\\)\n\nSamples are drawn independently from the same distribution\nThis means each is independent and identically distributed (iid)\n\nThe usual method we use for estimation is Ordinary Least Squares (OLS)\n\nMinimize the sum of the squared residuals"
  },
  {
    "objectID": "slides/ols/index.html#estimation-by-method-of-moments-1",
    "href": "slides/ols/index.html#estimation-by-method-of-moments-1",
    "title": "\nOrdinary Least Squares\n",
    "section": "Estimation by Method of Moments",
    "text": "Estimation by Method of Moments\n\nYou get the same result with the Method of Moments\n\nReplace the unknown population moments with their sample equivalents\n\nAbove we found that the population slopes are\n\\[\\boldsymbol{\\beta}=(\\textbf{E}[\\mathbf{x'x}])^{-1} \\textbf{E}[\\mathbf{x}'y]\\]\nMOM replaces population expectations with sample means across \\(n\\) observations\n\\[\\boldsymbol{\\hat{\\beta}}=\\left ( \\frac{1}{n}\\sum_{i=1}^{n}\\mathbf{x_{i}'x_{i}} \\right )^{-1} \\left ( \\frac{1}{n} \\sum_{i=1}^{n}\\mathbf{x}_{i}'y_{i}\\right ) \\]\nHere \\(i\\) indexes the sample observation\n\\(\\mathbf{x}_{i}\\) is a \\(1 \\times (k+1)\\) vector, so \\(\\mathbf{x_{i}'x_{i}}\\) is a \\((k+1) \\times (k+1)\\) matrix"
  },
  {
    "objectID": "slides/ols/index.html#estimation-by-method-of-moments-2",
    "href": "slides/ols/index.html#estimation-by-method-of-moments-2",
    "title": "\nOrdinary Least Squares\n",
    "section": "Estimation by Method of Moments",
    "text": "Estimation by Method of Moments\n\nRecall partitioned matrix multiplication\nWe can rewrite\n\\[\\left ( \\sum_{i=1}^{n}\\mathbf{x_{i}'x_{i}} \\right ) = \\mathbf{X'X}\\] \\[\\left ( \\sum_{i=1}^{n}\\mathbf{x}_{i}'y_{i}\\right ) =  \\mathbf{X'y}\\]\nSubstituting in, an equivalent expression for the estimated slope\n\\[\\boldsymbol{\\hat{\\beta}}=\\left (  \\mathbf{X'X}\\right )^{-1}  \\mathbf{X'y}\\]"
  },
  {
    "objectID": "slides/ols/index.html#ordinary-least-squares",
    "href": "slides/ols/index.html#ordinary-least-squares",
    "title": "\nOrdinary Least Squares\n",
    "section": "Ordinary Least Squares",
    "text": "Ordinary Least Squares\n\n\n\n\n\n\nImportant\n\n\n\nThe Ordinary Least Squares (OLS) estimator is\n\\[\\boldsymbol{\\hat{\\beta}}=\\left (  \\mathbf{X'X}\\right )^{-1}  \\mathbf{X'y}\\]\n\n\n\nYou can use \\(\\boldsymbol{\\hat{\\beta}}\\) to obtain predicted values of \\(y\\)\n\\[\\hat{\\mathbf{y}} = \\mathbf{X}\\boldsymbol{\\hat{\\beta}}\\]\nBy definition, the OLS residual is the difference between \\(\\mathbf{y}\\) and its predicted value\n\\[\\mathbf{y} =  \\mathbf{X}\\boldsymbol{\\hat{\\beta}} + \\mathbf{\\hat{u}}\\]"
  },
  {
    "objectID": "slides/ols/index.html#ordinary-least-squares-1",
    "href": "slides/ols/index.html#ordinary-least-squares-1",
    "title": "\nOrdinary Least Squares\n",
    "section": "Ordinary Least Squares",
    "text": "Ordinary Least Squares"
  },
  {
    "objectID": "slides/ols/index.html#introduction",
    "href": "slides/ols/index.html#introduction",
    "title": "\nOrdinary Least Squares\n",
    "section": "Introduction",
    "text": "Introduction\n\nOLS is one way to estimate a linear regression model\nIt is important to know how well the method works\nOne way is to examine the “fit” of our regression line\n\nHow close to the line are the datapoints?\nDoes \\(\\mathbf{x}\\) explain a large fraction of variation in \\(y\\)?\n\nThese are the algebraic properties of our estimator\n\nMathematical relationships hold true in each sample\n\nDifferent from the statistical properties\n\nThe behaviour of estimators across (hypothetical) repeated samples"
  },
  {
    "objectID": "slides/ols/index.html#properties-of-the-residuals",
    "href": "slides/ols/index.html#properties-of-the-residuals",
    "title": "\nOrdinary Least Squares\n",
    "section": "Properties of the Residuals",
    "text": "Properties of the Residuals\n\nThe first properties relate to the OLS residuals\n\\[\\mathbf{X}'\\hat{\\mathbf{u}} =\n\\begin{bmatrix}\n\\sum_{i=1}^{n}\\hat{u}_{i}\\\\\n\\sum_{i=1}^{n}x_{1i}\\hat{u}_{i}\\\\\n\\vdots\\\\\n\\sum_{i=1}^{n}x_{ki}\\hat{u}_{i}\\\\\n\\end{bmatrix}\n= \\mathbf{0}\\]\n\nThe sum (and the mean) of the residuals is zero\nThe sample covariance between \\(x\\) and the residuals is zero\n\nThese are the sample versions of \\(\\textbf{E}[\\mathbf{x}'\\mathbf{u}]=\\mathbf{0}\\)"
  },
  {
    "objectID": "slides/ols/index.html#r2",
    "href": "slides/ols/index.html#r2",
    "title": "\nOrdinary Least Squares\n",
    "section": "\\(R^2\\)",
    "text": "\\(R^2\\)\n\nThe Coefficient of Determination (\\(R^2\\)) measures the fraction of the variation in \\(y\\) that is explained by the independent variables \\[R^2 = \\frac{ESS}{TSS}\\]\nTSS is the Total Sum of Squares \\[TSS = \\sum_{i=1}^{N} (y_{i} - \\bar{y})^2 = \\mathbf{(Ny)'Ny} = \\mathbf{y'Ny}\\]\n\nwhere \\(\\mathbf{N} = (\\mathbf{I} - \\frac{1}{n}\\mathbf{11'})\\) is a symmetric, idempotent matrix\n\n\\(\\mathbf{1}\\) is a vector of all ones\n\n\\(\\mathbf{N}\\) turns a vector into deviations from means"
  },
  {
    "objectID": "slides/ols/index.html#r2-1",
    "href": "slides/ols/index.html#r2-1",
    "title": "\nOrdinary Least Squares\n",
    "section": "\\(R^2\\)",
    "text": "\\(R^2\\)\n\nESS is the Explained Sum of Squares \\[ESS = \\sum_{i=1}^{N} (\\hat{y}_{i} - \\bar{y})^2 =\\mathbf{(N\\hat{y})'N\\hat{y}} = \\mathbf{\\hat{y}'N\\hat{y}}\\]\nAnd the Residual Sum of Squares (SSR) is \\[SSR= \\sum_{i=1}^{N} (\\hat{u}_{i})^2 = \\hat{\\mathbf{u}}'\\hat{\\mathbf{u}}\\]\n\\(R^2\\) ranges between 0 and 1\n\n\\(R^2 = 0\\) means that \\(\\mathbf{x}\\) explains none of the variation in \\(y\\)\n\\(R^2 = 1\\) means that \\(\\mathbf{x}\\) explains all of the variation in \\(y\\)"
  },
  {
    "objectID": "slides/ols/index.html#r2-2",
    "href": "slides/ols/index.html#r2-2",
    "title": "\nOrdinary Least Squares\n",
    "section": "\\(R^2\\)",
    "text": "\\(R^2\\)\n\n\\(R^2\\) is also equal to the square of correlation coefficient between \\(y_{i}\\) and \\(\\hat{y}_{i}\\)\nAn important relationship between sums of squares is \\[TSS=  ESS + SSR\\]\n\nMovement of \\(y_{i}\\) away from its average is explained by regression and other factors\n\nUsing matrix notation,\n\\[\\mathbf{\\hat{y}'\\mathbf{N}\\hat{y}} = (\\mathbf{X}\\boldsymbol{\\hat{\\beta}} + \\hat{\\mathbf{u}})'\\mathbf{N}(\\mathbf{X}\\boldsymbol{\\hat{\\beta} + \\hat{\\mathbf{u}}} )\\] \\[= (\\boldsymbol{\\hat{\\beta}}' \\mathbf{X}'+ \\hat{\\mathbf{u}}')(\\mathbf{N}\\mathbf{X}\\boldsymbol{\\hat{\\beta} + \\mathbf{N}\\hat{\\mathbf{u}}} )\\] \\[= \\boldsymbol{\\hat{\\beta}}' \\mathbf{X}' N\\mathbf{X}\\boldsymbol{\\hat{\\beta}} + \\boldsymbol{\\hat{\\beta}}' \\mathbf{X}' \\mathbf{N}\\hat{\\mathbf{u}} + \\hat{\\mathbf{u}}'N\\mathbf{X}\\boldsymbol{\\hat{\\beta} +\\hat{\\mathbf{u}}' \\mathbf{N}\\hat{\\mathbf{u}}}\\]"
  },
  {
    "objectID": "slides/ols/index.html#r2-3",
    "href": "slides/ols/index.html#r2-3",
    "title": "\nOrdinary Least Squares\n",
    "section": "\\(R^2\\)",
    "text": "\\(R^2\\)\n\nBecause \\(\\mathbf{N}\\hat{\\mathbf{u}} =\\hat{\\mathbf{u}}\\) and \\(\\mathbf{X}'\\hat{\\mathbf{u}} = \\mathbf{0}\\) we can simplify to\n\\[= \\boldsymbol{\\hat{\\beta}}' N\\mathbf{X}' \\mathbf{X}\\boldsymbol{\\hat{\\beta}} +\\hat{\\mathbf{u}}' \\hat{\\mathbf{u}} = \\mathbf{\\hat{y}'N\\hat{y}}+\\hat{\\mathbf{u}}' \\hat{\\mathbf{u}}\\]\nWe noted above that \\(ESS = \\mathbf{\\hat{y}'N\\hat{y}}\\) and \\(SSR=\\hat{\\mathbf{u}}' \\hat{\\mathbf{u}}\\)\nAs a result, you can reexpress \\[R^2 = \\frac{ESS}{TSS} = 1- \\frac{SSR}{TSS}\\]\n\n\n\n\n\n\nCaution\n\n\n\nBe cautious when using \\(R^2\\). In real applications, \\(R^2\\) is often very low, but this does not mean the regression is “bad” or that we haven’t measured a causal relationship. It just means we have not captured all factors that explain \\(Y\\)"
  },
  {
    "objectID": "slides/ols/index.html#r2-4",
    "href": "slides/ols/index.html#r2-4",
    "title": "E655 - Econometrics",
    "section": "\\(R^2\\)",
    "text": "\\(R^2\\)\n\nA low \\(R^2\\) does not imply a poor estimate of \\(\\mathbf{\\beta}\\)\n\n\\(\\mathbf{\\beta}\\) measures effect on \\(y\\) from changing \\(\\mathbf{x}\\), all else equal\n\\(R^2\\) measures fraction of total variation in \\(y\\) is explained by \\(\\mathbf{x}\\)\nConcepts are independent of each other\n\nWhether estimate of \\(\\mathbf{\\beta}\\) is good or bad depends on statistical properties\n\nConsistency and unbiasedness\nWe cover these in detail below\n\nIn practice, researchers do not pay much attention to \\(R^2\\)"
  },
  {
    "objectID": "slides/ols/index.html#standard-error-of-regression-ser",
    "href": "slides/ols/index.html#standard-error-of-regression-ser",
    "title": "\nOrdinary Least Squares\n",
    "section": "Standard Error of Regression (SER)",
    "text": "Standard Error of Regression (SER)\n\nCan also measure fit with spread of data around regression line\nThe residual \\(\\hat{\\mathbf{u}}\\) is deviation of \\(\\mathbf{y}\\) from prediction \\[\\mathbf{\\hat{u}} = \\mathbf{y} -  \\mathbf{X}\\boldsymbol{\\hat{\\beta}}\\]\nThe standard error of regression (SER) is the standard deviation of \\(\\hat{u}_{i}\\)\n\nThe average distance of \\(y_{i}\\) from its prediction \\(\\hat{y}_{i}\\)\n\n\\[SER = s_{\\hat{u}} = \\sqrt{\\frac{\\hat{\\mathbf{u}}' \\hat{\\mathbf{u}}}{n-k-1} }= \\sqrt{\\frac{SSR}{n-k-1} }\\]"
  },
  {
    "objectID": "slides/ols/index.html#introduction-1",
    "href": "slides/ols/index.html#introduction-1",
    "title": "\nOrdinary Least Squares\n",
    "section": "Introduction",
    "text": "Introduction\n\n\\(\\boldsymbol{\\hat{\\beta}}\\) is an estimator for \\(\\boldsymbol{\\beta}\\)\n\nJust like sample mean is an estimator for population mean\n\\(\\boldsymbol{\\beta}\\) is a population parameter, \\(\\boldsymbol{\\hat{\\beta}}\\) is a function of the sample\n\n\\(\\boldsymbol{\\hat{\\beta}}\\) are random variables with a sampling distribution\n\nRealized values change from sample to sample\n\nWe want estimators to have certain statistical properties\n\nConsistency\nEfficiency (lowest variance)\nUnbiasedness"
  },
  {
    "objectID": "slides/ols/index.html#introduction-2",
    "href": "slides/ols/index.html#introduction-2",
    "title": "\nOrdinary Least Squares\n",
    "section": "Introduction",
    "text": "Introduction\n\nThere are large sample properties and finite sample properties\n\nLarge sample (asymptotic) properties hold as sample size grows large\nFinite sample ones hold in any sample size\n\nWe will focus most on large sample properties\n\nConsistency and large sample distribution\nThese often matter most in applied work\n\nOccasionally we will touch on the finite sample properties like unbiasedness"
  },
  {
    "objectID": "slides/ols/index.html#assumptions",
    "href": "slides/ols/index.html#assumptions",
    "title": "\nOrdinary Least Squares\n",
    "section": "Assumptions",
    "text": "Assumptions\n\nNeed assumptions to derive statistical properties\nFocus on the assumptions necessary for the large sample properties\n\n\n\\(\\textbf{E}[\\mathbf{x}'u]=\\mathbf{0}\\)\n\nSays that the population residual is mean zero and uncorrelated with \\(\\mathbf{x}\\)\nThis is true in our model by definition, so not really an assumption\n\n\\(\\text{rank } \\textbf{E}[\\mathbf{x'x}] = k+1\\)\n\nSays that there is no linear dependence in \\(\\mathbf{x}\\)\nSame as saying there is no perfect multicollinearity among regressors"
  },
  {
    "objectID": "slides/ols/index.html#assumptions-1",
    "href": "slides/ols/index.html#assumptions-1",
    "title": "\nOrdinary Least Squares\n",
    "section": "Assumptions",
    "text": "Assumptions\n\n\\(\\{(\\mathbf{x}_{i},y_{i}): i=1,2,...,n)\\}\\) are a random sample\n\nImplies that the observations are independent and identically distributed (iid)\nThis is necessary to establish consistency\n\n\n\n\n\n\n\n\nImportant\n\n\n\nWhen these assumptions are true, the large sample distribution of \\(\\boldsymbol{\\hat{\\beta}}\\) is\n\\[\\boldsymbol{\\hat{\\beta}} \\sim \\mathcal{N}(\\boldsymbol{\\beta}, n^{-1}[\\mathbf{E}(\\mathbf{x'x})^{-1}]\\mathbf{E}(u^2\\mathbf{x'x})[\\mathbf{E}(\\mathbf{x'x})^{-1}])\\]"
  },
  {
    "objectID": "slides/ols/index.html#consistency",
    "href": "slides/ols/index.html#consistency",
    "title": "\nOrdinary Least Squares\n",
    "section": "Consistency",
    "text": "Consistency\n\nConsistency: an estimator approaches the parameter when the sample gets big\n\nRemoving sampling variation leaves us with the true parameter\n\nEconometricians like estimators to be consistent at minimum\nWhen the three assumptions above are true, the OLS estimator is consistent\n\n\n\n\n\n\nNote\n\n\n\nThe concept of consistency is separate from causality. You can have a consistent estimator that does not represent the casual effect."
  },
  {
    "objectID": "slides/ols/index.html#consistency-1",
    "href": "slides/ols/index.html#consistency-1",
    "title": "\nOrdinary Least Squares\n",
    "section": "Consistency",
    "text": "Consistency\n\nMathematically, write the OLS estimator as\n\\[\\boldsymbol{\\hat{\\beta}}=\\left (  \\mathbf{X'X}\\right )^{-1}  \\mathbf{X'y}\\] \\[=\\left (  \\mathbf{X'X}\\right )^{-1}  \\mathbf{X'(X'\\boldsymbol{\\beta} + u)}\\] \\[=\\left (  \\mathbf{X'X}\\right )^{-1}  \\mathbf{X'X}\\boldsymbol{\\beta} + \\left (  \\mathbf{X'X}\\right )^{-1} \\mathbf{X'}u\\] \\[=\\boldsymbol{\\beta} + \\left (  \\mathbf{X'X}\\right )^{-1} \\mathbf{X'}u\\]\nIf we partition the matrices, we can write this equivalently as\n\\[\\boldsymbol{\\hat{\\beta}}=\\boldsymbol{\\beta} + \\left ( \\frac{1}{n} \\sum_{i=1}^{n}\\mathbf{x_{i}'x_{i}}\\right )^{-1} \\left (\\frac{1}{n}\\sum_{i=1}^{n}\\mathbf{x_{i}'}u_{i} \\right )\\]"
  },
  {
    "objectID": "slides/ols/index.html#consistency-2",
    "href": "slides/ols/index.html#consistency-2",
    "title": "\nOrdinary Least Squares\n",
    "section": "Consistency",
    "text": "Consistency\n\nConsistency means showing \\(\\boldsymbol{\\hat{\\beta}}\\) approaches \\(\\boldsymbol{\\beta}\\) as \\(n\\) gets large\nIt is established with the probability limit\n\nProbability that an estimator lies in small range around a parameter as \\(n \\rightarrow \\infty\\)\nThe probability limit of OLS slope estimator \\(\\hat{\\beta}_{k}\\) is \\(\\beta_{k}\\) if \\[\\lim_{n \\rightarrow \\infty} Pr(\\beta_{k} - \\epsilon &lt; \\hat{\\beta}_{k} &lt; \\beta_{k} + \\epsilon) \\rightarrow 1\\]\nThe short form of this is \\[\\text{plim }(\\hat{\\beta}_{k}) = \\beta_{k}\\]"
  },
  {
    "objectID": "slides/ols/index.html#consistency-3",
    "href": "slides/ols/index.html#consistency-3",
    "title": "\nOrdinary Least Squares\n",
    "section": "Consistency",
    "text": "Consistency\n\nYou can use plim as an operator with the following rules\n\n\\[\\text{plim}(x+y) = \\text{plim}(x) + \\text{plim}(y)\\] \\[\\text{plim}(xy) = \\text{plim}(x)\\text{plim}(y)\\] \\[\\text{plim}(\\frac{x}{y}) = \\frac{\\text{plim}(x)}{ \\text{plim}(y)}\\]"
  },
  {
    "objectID": "slides/ols/index.html#consistency-4",
    "href": "slides/ols/index.html#consistency-4",
    "title": "\nOrdinary Least Squares\n",
    "section": "Consistency",
    "text": "Consistency\n\nApplying this to our slope estimator\n\n\\[\\text{plim}(\\boldsymbol{\\hat{\\beta}})=\\boldsymbol{\\beta} + \\text{plim} \\left( \\left ( \\frac{1}{n} \\sum_{i=1}^{n}\\mathbf{x_{i}'x_{i}}\\right )^{-1} \\left (\\frac{1}{n}\\sum_{i=1}^{n}\\mathbf{x_{i}'}u_{i} \\right )\\right )\\] \\[\\text{plim}(\\boldsymbol{\\hat{\\beta}})=\\boldsymbol{\\beta} + \\text{plim} \\left ( \\frac{1}{n} \\sum_{i=1}^{n}\\mathbf{x_{i}'x_{i}}\\right )^{-1} \\text{plim} \\left(  \\frac{1}{n}\\sum_{i=1}^{n}\\mathbf{x_{i}'}u_{i} \\right )\\]"
  },
  {
    "objectID": "slides/ols/index.html#consistency-5",
    "href": "slides/ols/index.html#consistency-5",
    "title": "\nOrdinary Least Squares\n",
    "section": "Consistency",
    "text": "Consistency\n\nYou can show that\n\\[\\text{plim} \\left ( \\frac{1}{n} \\sum_{i=1}^{n}\\mathbf{x_{i}'x_{i}}\\right )^{-1}  = \\left( \\mathbf{E}[\\mathbf{x'x}]\\right )^{-1}\\] \\[\\text{plim} \\left ( \\frac{1}{n} \\sum_{i=1}^{n}\\mathbf{x'}u\\right )  = \\mathbf{E}\\left( \\mathbf{x'}u\\right )\\]\nA property of our model is \\(\\mathbf{E}\\left( \\mathbf{x'}u\\right ) =\\mathbf{0}\\), so\n\\[\\text{plim}(\\boldsymbol{\\hat{\\beta}})=\\boldsymbol{\\beta}\\]\nGiven our assumptions, the OLS estimator is consistent for \\(\\boldsymbol{\\beta}\\)\nMany economic researchers work with big samples, so asymptotic approach works"
  },
  {
    "objectID": "slides/ols/index.html#unbiasedness",
    "href": "slides/ols/index.html#unbiasedness",
    "title": "\nOrdinary Least Squares\n",
    "section": "Unbiasedness",
    "text": "Unbiasedness\n\nEconomists generally think at minimum an estimator should be consistent\nAnother desirable property is unbiasedness\n\nOn average, the estimator should equal the parameter\n\nThis finite sample property holds for any sample size\nThe OLS estimator is unbiased under stricter assumptions than those made above\nWe need to replace assumption \\(\\textbf{E}[\\mathbf{x}'u]=0\\) with \\(\\textbf{E}[u|\\mathbf{x}]=0\\)\n\nAssumption says that \\(u\\) is unrelated to any function of \\(\\mathbf{x}\\)"
  },
  {
    "objectID": "slides/ols/index.html#unbiasedness-1",
    "href": "slides/ols/index.html#unbiasedness-1",
    "title": "\nOrdinary Least Squares\n",
    "section": "Unbiasedness",
    "text": "Unbiasedness\n\nThis is stronger than assuming \\(\\textbf{E}[\\mathbf{x}'u]=\\mathbf{0}\\)\n\nZero correlation means no linear relationship between \\(u\\) and \\(\\mathbf{x}\\)\n\\(\\textbf{E}[u|\\mathbf{x}]=0\\) means no linear or nonlinear relationship\n\nWith this assumption we can show \\(\\boldsymbol{\\hat{\\beta}}\\) is unbiased\nRecall the OLS estimator is \\[\\boldsymbol{\\hat{\\beta}}=\\boldsymbol{\\beta} + \\left (  \\mathbf{X'X}\\right )^{-1} \\mathbf{X'}\\mathbf{u}\\]\nWe assume \\(u\\) and \\(\\mathbf{x}\\) are unrelated in the population, so \\(\\textbf{E}[\\mathbf{u}|\\mathbf{X}]=\\mathbf{0}\\)\n\nSays each element of \\(\\mathbf{u}\\) is unrelated to all parts of \\(\\mathbf{X}\\)"
  },
  {
    "objectID": "slides/ols/index.html#unbiasedness-2",
    "href": "slides/ols/index.html#unbiasedness-2",
    "title": "\nOrdinary Least Squares\n",
    "section": "Unbiasedness",
    "text": "Unbiasedness\n\nTaking expectations\n\\[\\mathbf{E}[\\boldsymbol{\\hat{\\beta}}|\\mathbf{X}]=\\mathbf{E}[\\boldsymbol{\\beta} + \\left (  \\mathbf{X'X}\\right )^{-1} \\mathbf{X'}\\mathbf{u}|\\mathbf{X}]\\]\nBringing the expectation operator through the bracket we get\n\\[\\mathbf{E}[\\boldsymbol{\\hat{\\beta}}|\\mathbf{X}]=\\boldsymbol{\\beta} + \\mathbf{E}[\\left (  \\mathbf{X'X}\\right )^{-1} \\mathbf{X'}\\mathbf{u}|\\mathbf{X}]\\] \\[=\\boldsymbol{\\beta} + \\mathbf{E}[\\left (  \\mathbf{X'X}\\right )^{-1} \\mathbf{X'}\\mathbf{E}[\\mathbf{u}|\\mathbf{X}]\\] \\[=\\boldsymbol{\\beta}\\]\nIf you take the average across all values of \\(\\mathbf{X}\\), you get \\[\\mathbf{E}[\\boldsymbol{\\hat{\\beta}}] =\\mathbf{E}[\\mathbf{E}[\\boldsymbol{\\hat{\\beta}}|\\mathbf{X}]] = \\boldsymbol{\\beta}\\]"
  },
  {
    "objectID": "slides/ols/index.html#unbiasedness-3",
    "href": "slides/ols/index.html#unbiasedness-3",
    "title": "\nOrdinary Least Squares\n",
    "section": "Unbiasedness",
    "text": "Unbiasedness\n\nImportant to emphasize unbiasedness requires stronger assumptions\nSome estimators are consistent but biased in finite samples\n\nInstrumental variables (IV) estimator is one of them\n\nThis is why researchers focus more on consistency as basis for good estimator\nWe now discuss the distribution and variance of \\(\\boldsymbol{\\hat{\\beta}}\\)\n\nThis will allow us to move on to talking about inference\nWe will emphasize that inference is as important as estimation"
  },
  {
    "objectID": "slides/ols/index.html#large-sample-distribution-of-boldsymbolhatbeta",
    "href": "slides/ols/index.html#large-sample-distribution-of-boldsymbolhatbeta",
    "title": "\nOrdinary Least Squares\n",
    "section": "Large Sample Distribution of \\(\\boldsymbol{\\hat{\\beta}}\\)",
    "text": "Large Sample Distribution of \\(\\boldsymbol{\\hat{\\beta}}\\)\n\nFor hypothesis tests on \\(\\boldsymbol{\\beta}\\), we need to know the distribution of \\(\\boldsymbol{\\hat{\\beta}}\\)\n\nIf our estimate is in the tails of the distribution when null is true, we reject\nIf it is in the center, we fail to reject\n\nWe will focus on the large-sample distribution\n\nDistribution as sample size gets large\nIf you make assumptions about the errors, you can get the finite distribution\n\nTo get large sample distribution, we rely on the Central Limit Theorem (CLT)"
  },
  {
    "objectID": "slides/ols/index.html#large-sample-distribution-of-boldsymbolhatbeta-1",
    "href": "slides/ols/index.html#large-sample-distribution-of-boldsymbolhatbeta-1",
    "title": "\nOrdinary Least Squares\n",
    "section": "Large Sample Distribution of \\(\\boldsymbol{\\hat{\\beta}}\\)",
    "text": "Large Sample Distribution of \\(\\boldsymbol{\\hat{\\beta}}\\)\n\nThe CLT says\n\nIf random vectors \\(w_{i}, i=1,2,...\\) are iid with mean \\(\\mathbf{E}(\\mathbf{w_{i}})\\) and variance \\(\\text{var}(\\mathbf{w_{i}})\\)\nThen \\(\\bar{\\mathbf{w}} = \\frac{1}{n} \\sum_{1=1}^{n}\\mathbf{w_{i}}\\) converges to \\(\\mathcal{N}(\\mathbf{E}(\\mathbf{w_{i}}), n^{-1}\\text{var}(\\mathbf{w_{i}}))\\)\n\nIf you write the slope estimator as\n\\[\\boldsymbol{\\hat{\\beta}}=\\boldsymbol{\\beta} + \\left ( \\frac{1}{n} \\sum_{i=1}^{n}\\mathbf{x_{i}'x_{i}}\\right )^{-1} \\left (\\frac{1}{n}\\sum_{i=1}^{n}\\mathbf{x_{i}'}u_{i} \\right )\\]\nTaking mean of \\(\\boldsymbol{\\hat{\\beta}}-\\boldsymbol{\\beta}\\) is equivalent to a weighted mean of \\(\\mathbf{x_{i}'}u_{i}\\)\nApplying the CLT, \\(\\boldsymbol{\\hat{\\beta}}\\) has a Normal distribution with mean \\(\\boldsymbol{\\beta}\\) and variance\n\\[\\text{var}(\\boldsymbol{\\hat{\\beta}}) = n^{-1}[\\mathbf{E}(\\mathbf{x'x})^{-1}]\\mathbf{E}(u^2\\mathbf{x'x})[\\mathbf{E}(\\mathbf{x'x})^{-1}]\\]"
  },
  {
    "objectID": "slides/ols/index.html#large-sample-distribution-of-boldsymbolhatbeta-2",
    "href": "slides/ols/index.html#large-sample-distribution-of-boldsymbolhatbeta-2",
    "title": "\nOrdinary Least Squares\n",
    "section": "Large Sample Distribution of \\(\\boldsymbol{\\hat{\\beta}}\\)",
    "text": "Large Sample Distribution of \\(\\boldsymbol{\\hat{\\beta}}\\)\n\nThe previous discussion assumes nothing about the distribution of the error terms\nSometimes it makes sense to assume homoskedasticity of the errors\n\nVariation in the errors is not a function of \\(\\mathbf{x}\\)\n\nUsually this is stated as\n\\[\\text{var}(u|\\mathbf{x}) = \\sigma^2\\]\nYou can write the variance of \\(u\\) given \\(\\mathbf{x}\\) as \\[\\text{var}(u|\\mathbf{x})  = \\mathbf{E}(u^2|\\mathbf{x}) - \\left [ \\mathbf{E}(u|\\mathbf{x}) \\right ]^2\\]\n\nThe sum of two conditional expectations"
  },
  {
    "objectID": "slides/ols/index.html#large-sample-distribution-of-boldsymbolhatbeta-3",
    "href": "slides/ols/index.html#large-sample-distribution-of-boldsymbolhatbeta-3",
    "title": "\nOrdinary Least Squares\n",
    "section": "Large Sample Distribution of \\(\\boldsymbol{\\hat{\\beta}}\\)",
    "text": "Large Sample Distribution of \\(\\boldsymbol{\\hat{\\beta}}\\)\n\nTurns out we only need to assume the first component is constant\n\\[\\mathbf{E}(u^2|\\mathbf{x}) = \\sigma^2\\]\nWe can then simplify the expression for \\(\\text{var}(\\boldsymbol{\\hat{\\beta}})\\)\nFirst, because of the law of iterated expectations\n\\[\\mathbf{E}(u^2\\mathbf{x'x}) = \\mathbf{E}(\\mathbf{E}(u^2|\\mathbf{x})\\mathbf{x'x})\\]\nSubstituting in \\(\\mathbf{E}(u^2|\\mathbf{x}) = \\sigma^2\\), we get\n\\[\\mathbf{E}(u^2\\mathbf{x'x}) = \\sigma^2\\mathbf{E}(\\mathbf{x'x})\\]"
  },
  {
    "objectID": "slides/ols/index.html#large-sample-distribution-of-boldsymbolhatbeta-4",
    "href": "slides/ols/index.html#large-sample-distribution-of-boldsymbolhatbeta-4",
    "title": "\nOrdinary Least Squares\n",
    "section": "Large Sample Distribution of \\(\\boldsymbol{\\hat{\\beta}}\\)",
    "text": "Large Sample Distribution of \\(\\boldsymbol{\\hat{\\beta}}\\)\n\nFinally, substituting in to the expression for \\(\\text{var}(\\boldsymbol{\\hat{\\beta}})\\)\n\\[\\text{var}(\\boldsymbol{\\hat{\\beta}}) = n^{-1}[\\mathbf{E}(\\mathbf{x'x})^{-1}]\\sigma^2\\mathbf{E}(\\mathbf{x'x})[\\mathbf{E}(\\mathbf{x'x})^{-1}]\\] \\[= \\sigma^2 n^{-1}[\\mathbf{E}(\\mathbf{x'x})^{-1}]\\mathbf{E}(\\mathbf{x'x})[\\mathbf{E}(\\mathbf{x'x})^{-1}]\\] \\[= \\sigma^2 n^{-1}[\\mathbf{E}(\\mathbf{x'x})^{-1}]\\]\nThis is the version of the variance of \\(\\boldsymbol{\\hat{\\beta}}\\) that is given by default in Stata\nIt is only valid under homoskedasticity\n\nIn practice this is rarely the case\n\nWe cannot use these directly because they are population quantities\nNeed to estimate them"
  },
  {
    "objectID": "slides/ols/index.html#variance-estimator-for-boldsymbolhatbeta",
    "href": "slides/ols/index.html#variance-estimator-for-boldsymbolhatbeta",
    "title": "\nOrdinary Least Squares\n",
    "section": "Variance Estimator for \\(\\boldsymbol{\\hat{\\beta}}\\)",
    "text": "Variance Estimator for \\(\\boldsymbol{\\hat{\\beta}}\\)\n\nFollow the same procedure by replacing population moments with sample ones\n\\[\\text{var}(\\boldsymbol{\\hat{\\beta}}) = n^{-1}[\\mathbf{E}(\\mathbf{x'x})^{-1}]\\mathbf{E}(u^2\\mathbf{x'x})[\\mathbf{E}(\\mathbf{x'x})^{-1}]\\] \\[\\hat{\\text{var}}(\\boldsymbol{\\hat{\\beta}}) = n^{-1}\\left ( \\frac{1}{n} \\sum_{i=1}^{n}\\mathbf{x_{i}'x_{i}}\\right )^{-1}\\left ( \\frac{1}{n} \\sum_{i=1}^{n}\\hat{u}_{i}^2\\mathbf{x_{i}'x_{i}}\\right )\\left ( \\frac{1}{n} \\sum_{i=1}^{n}\\mathbf{x_{i}'x_{i}}\\right )^{-1}\\]\n\\[\\hat{\\text{var}}(\\boldsymbol{\\hat{\\beta}}) = \\left (\\mathbf{X'X}\\right )^{-1}\\left ( \\sum_{i=1}^{n}\\hat{u}_{i}^2\\mathbf{x_{i}'x_{i}}\\right )\\left ( \\mathbf{X'X}\\right )^{-1}\\]\nThis is the Heteroskedasticity-Robust estimator of the variance\n\nSometimes called the robust estimator or sandwich estimator"
  },
  {
    "objectID": "slides/ols/index.html#variance-estimator-for-boldsymbolhatbeta-1",
    "href": "slides/ols/index.html#variance-estimator-for-boldsymbolhatbeta-1",
    "title": "\nOrdinary Least Squares\n",
    "section": "Variance Estimator for \\(\\boldsymbol{\\hat{\\beta}}\\)",
    "text": "Variance Estimator for \\(\\boldsymbol{\\hat{\\beta}}\\)\n\nIt is what Stata produces when you use the “robust” option in regression\nThe square root of the diagonal elements are the Robust Standard Errors\nIf we assume homoskedastic errors, we get\n\\[\\hat{\\text{var}}(\\boldsymbol{\\hat{\\beta}}) = s_{\\hat{u}}^2 \\left (\\mathbf{X'X}\\right )^{-1}\\]\nwhere \\(s_{\\hat{u}}^2\\) is a consistent estimator of \\(\\sigma^2\\) and equals\n\\[s_{\\hat{u}}^2 = \\frac{\\hat{\\mathbf{u}}'\\hat{\\mathbf{u}}}{n-k-1}\\]\nThe square root of the diagonals are Stata’s default standard errors"
  },
  {
    "objectID": "slides/ols/index.html#introduction-3",
    "href": "slides/ols/index.html#introduction-3",
    "title": "\nOrdinary Least Squares\n",
    "section": "Introduction",
    "text": "Introduction\n\nRecall that we will never know the value of the true slope parameters\n\nThis is why we are estimating it\n\nBut, we can use our estimator and estimate to test hypotheses about them\nProcedure is as follows\n\nMake tentative assumption about true slope\nChoose a test statistic, with known distribution under assumption\nFormulate a decision rule\nCheck whether estimate is likely to occur under that rule\n\nIf no, then reject\nIf yes, fail to reject"
  },
  {
    "objectID": "slides/ols/index.html#testing-single-linear-hypotheses",
    "href": "slides/ols/index.html#testing-single-linear-hypotheses",
    "title": "\nOrdinary Least Squares\n",
    "section": "Testing Single Linear Hypotheses",
    "text": "Testing Single Linear Hypotheses\n\nOften in applied econometrics we test hypotheses about one parameter\n\nUsually we are interested in effect of one of regressors on outcome\nWe test whether that slope parameter is zero\n\nThe standard method is to use a \\(t\\)-test\nIn the linear regression model, the null and alternative hypotheses are\n\n\\(H_{0}: \\beta_{j} = \\beta_{j,0}\\)\n\\(H_{1}: \\beta_{j} \\neq \\beta_{j,0}\\)\n\nThe test statistic is the \\(t\\) statistic\n\\[t=\\frac{\\hat{\\beta}_{j} - \\beta_{j,0}}{se(\\hat{\\beta}_{j} )}\\]"
  },
  {
    "objectID": "slides/ols/index.html#testing-single-linear-hypotheses-1",
    "href": "slides/ols/index.html#testing-single-linear-hypotheses-1",
    "title": "\nOrdinary Least Squares\n",
    "section": "Testing Single Linear Hypotheses",
    "text": "Testing Single Linear Hypotheses\n\nThe \\(t\\)-statistic is a random variable that varies across samples\nIt has a Standard Normal distribution in large samples\n\nIt is a standardized version of a Normal random variable\n\nTo compute the \\(t\\)-statistic, we need \\(se(\\hat{\\beta}_{j} )\\)\n\nThis is the square root of the \\(j\\)th diagonal element of \\(\\hat{\\text{var}}(\\boldsymbol{\\hat{\\beta}})\\)\nThe formula we use for \\(\\hat{\\text{var}}(\\boldsymbol{\\hat{\\beta}})\\) depends on whether we assume homoskedasticity\n\nWe then make a decision rule for rejection\n\nUsually this is defined in terms of a Significance Level\n\nThe significance level \\(\\alpha\\) is the maximum proportion of all possible \\(t\\) values unusual enough to reject \\(H_{0}\\)\n\nTypically, this is \\(\\alpha = 0.05\\)"
  },
  {
    "objectID": "slides/ols/index.html#testing-single-linear-hypotheses-2",
    "href": "slides/ols/index.html#testing-single-linear-hypotheses-2",
    "title": "\nOrdinary Least Squares\n",
    "section": "Testing Single Linear Hypotheses",
    "text": "Testing Single Linear Hypotheses\n\nChoice of significance level divides sampling distribution into two regions\n\nRejection Region: values for \\(t\\) where we reject \\(H_{0}\\)\n\nOne-sided test: the upper or lower \\(\\alpha \\%\\) of values\nTwo-sided test: the upper and lower \\(\\frac{\\alpha}{2} \\%\\) of values\n\nAcceptance Region: values for \\(t\\) where we accept \\(H_{0}\\)\n\nOne-sided test: the upper or lower \\((1-\\alpha) \\%\\) of values\nTwo-sided test: the middle \\((1-\\alpha) \\%\\) of values\n\n\nThe Critical Value separates the acceptance and rejection regions\n\nOn graphs below it is value between green and white regions\nFor two-tailed tests, there are two critical values"
  },
  {
    "objectID": "slides/ols/index.html#testing-single-linear-hypotheses-3",
    "href": "slides/ols/index.html#testing-single-linear-hypotheses-3",
    "title": "\nOrdinary Least Squares\n",
    "section": "Testing Single Linear Hypotheses",
    "text": "Testing Single Linear Hypotheses"
  },
  {
    "objectID": "slides/ols/index.html#testing-single-linear-hypotheses-4",
    "href": "slides/ols/index.html#testing-single-linear-hypotheses-4",
    "title": "\nOrdinary Least Squares\n",
    "section": "Testing Single Linear Hypotheses",
    "text": "Testing Single Linear Hypotheses\n\nValue depends on sampling distribution and \\(\\alpha\\)\n\nAt \\(5\\%\\) significance with a t-distribution and a large sample\n\nUpper tailed test: \\(t^{c}\\) = 1.64\nLower tailed test: \\(t^{c}\\) = -1.64\nTwo tailed test: \\(|t^{c}|\\) = 1.96\n\n\nFinally, we compare our realized test statistic to the critical values\n\nIn two-tailed test reject if \\(|t| &gt; |t^{c}|\\)\nIn lower-tailed test reject if \\(t &lt; t^{c}\\)\nIn upper-tailed test reject if \\(t &gt; t^{c}\\)\n\nIf you do not reject, you fail to reject\n\nNot the same as accepting the null hypothesis"
  },
  {
    "objectID": "slides/ols/index.html#testing-multiple-linear-hypotheses",
    "href": "slides/ols/index.html#testing-multiple-linear-hypotheses",
    "title": "\nOrdinary Least Squares\n",
    "section": "Testing Multiple Linear Hypotheses",
    "text": "Testing Multiple Linear Hypotheses\n\nSometimes you need to test multiple hypotheses at the same time\n\nTesting significance of the model\nTesting whether two parameters are equal\n\nWe follow a similar procedure\n\nMake tentative assumption about parameters\nChoose a test statistic with known distribution\nMake decision rule\nCompute test statistic and apply decision rule\n\nKey difference is in the test statistic we use"
  },
  {
    "objectID": "slides/ols/index.html#testing-multiple-linear-hypotheses-1",
    "href": "slides/ols/index.html#testing-multiple-linear-hypotheses-1",
    "title": "\nOrdinary Least Squares\n",
    "section": "Testing Multiple Linear Hypotheses",
    "text": "Testing Multiple Linear Hypotheses\n\nWe can write multiple hypotheses with matrix notation\n\\[H_{0}: \\mathbf{R}\\boldsymbol{\\beta} =\\mathbf{r}\\] \\[H_{1}: \\mathbf{R}\\boldsymbol{\\beta} \\neq \\mathbf{r}\\]\n\n\\(\\mathbf{R}\\) is a \\(q \\times k+1\\) matrix of constants\n\\(\\boldsymbol{\\beta}\\) is a \\(k+1 \\times 1\\) vector of slope parameters\n\\(r\\) is a \\(q \\times 1\\) vector of constants\n\nFor example, suppose you want to test \\(H_{0}: \\beta_{2} = 0\\). In this case\n\\[\\mathbf{R} =\n\\begin{bmatrix}\n0 & 0 & 1 & 0 & \\cdots & 0\n\\end{bmatrix}\\] \\[r = 0\\]"
  },
  {
    "objectID": "slides/ols/index.html#testing-multiple-linear-hypotheses-2",
    "href": "slides/ols/index.html#testing-multiple-linear-hypotheses-2",
    "title": "\nOrdinary Least Squares\n",
    "section": "Testing Multiple Linear Hypotheses",
    "text": "Testing Multiple Linear Hypotheses\n\nIf you multiply this out you get\n\\[\\mathbf{R}\\boldsymbol{\\beta} =\n\\begin{bmatrix}\n0 & 0 & 1 & 0 & \\cdots & 0\n\\end{bmatrix}\n\\begin{bmatrix}\n\\beta_{0}\\\\\n\\beta_{1}\\\\\n\\beta_{2} \\\\\n\\vdots\\\\\n\\beta_{k}\n\\end{bmatrix}\n=\\beta_{2}\\]\nSo that \\(\\mathbf{R}\\boldsymbol{\\beta} =r\\) is equivalent to \\(\\beta_{2} = 0\\)"
  },
  {
    "objectID": "slides/ols/index.html#testing-multiple-linear-hypotheses-3",
    "href": "slides/ols/index.html#testing-multiple-linear-hypotheses-3",
    "title": "\nOrdinary Least Squares\n",
    "section": "Testing Multiple Linear Hypotheses",
    "text": "Testing Multiple Linear Hypotheses\n\nNow imagine you want to test \\(H_{0}: \\beta_{2} = 0, \\beta_{4} = 2\\)\n\\[\\mathbf{R} =\n\\begin{bmatrix}\n0 & 0 & 1 & 0 &0&\\cdots & 0\\\\\n0 & 0 & 0 & 0 &1&\\cdots & 0\n\\end{bmatrix}\\] \\[\\mathbf{r} =\n\\begin{bmatrix}\n0 \\\\\n2\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/ols/index.html#testing-multiple-linear-hypotheses-4",
    "href": "slides/ols/index.html#testing-multiple-linear-hypotheses-4",
    "title": "\nOrdinary Least Squares\n",
    "section": "Testing Multiple Linear Hypotheses",
    "text": "Testing Multiple Linear Hypotheses\n\nIf you multiply out in this case\n\\[\\mathbf{R}\\boldsymbol{\\beta} =\n\\begin{bmatrix}\n0 & 0 & 1 & 0 &0&\\cdots & 0\\\\\n0 & 0 & 0 & 0 &1&\\cdots & 0\n\\end{bmatrix}\n\\begin{bmatrix}\n\\beta_{0}\\\\\n\\beta_{1}\\\\\n\\beta_{2} \\\\\n\\vdots\\\\\n\\beta_{k}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\beta_{2}\\\\\n\\beta_{4}\n\\end{bmatrix}\\]\nSo that \\(\\mathbf{R}\\boldsymbol{\\beta} =r\\) is equivalent to \\[\\begin{bmatrix}\n\\beta_{2}\\\\\n\\beta_{4}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n0\\\\\n2\n\\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/ols/index.html#testing-multiple-linear-hypotheses-5",
    "href": "slides/ols/index.html#testing-multiple-linear-hypotheses-5",
    "title": "\nOrdinary Least Squares\n",
    "section": "Testing Multiple Linear Hypotheses",
    "text": "Testing Multiple Linear Hypotheses\n\nWhen testing multiple linear restrictions, it is common to use the Wald Statistic\n\\[W = (\\mathbf{R}\\boldsymbol{\\hat{\\beta}} -\\mathbf{r} )'(\\mathbf{R}\\hat{\\text{var}}(\\boldsymbol{\\hat{\\beta}})  \\mathbf{R}')^{-1} (\\mathbf{R}\\boldsymbol{\\hat{\\beta}} -\\mathbf{r} )\\]\n\nIntuition is \\(W\\) computes squared distance between estimate and null hypothesis\nDistance is scaled by the variance\nIf that distance is too far, we reject the null\nVery similar to intuition of \\(t\\)-test\n\n\\(\\text{var}(\\boldsymbol{\\hat{\\beta}})\\) is variance matrix of OLS estimator computed above\n\nUse Robust or Homoskedastic version as appropriate"
  },
  {
    "objectID": "slides/ols/index.html#variance-estimator-for-boldsymbolhatbeta-2",
    "href": "slides/ols/index.html#variance-estimator-for-boldsymbolhatbeta-2",
    "title": "\nOrdinary Least Squares\n",
    "section": "Variance Estimator for \\(\\boldsymbol{\\hat{\\beta}}\\)",
    "text": "Variance Estimator for \\(\\boldsymbol{\\hat{\\beta}}\\)\n\n\n\n\n\n\nImportant\n\n\n\nThe Heteroskedasticity-Robust Variance Estimator \\(\\boldsymbol{\\hat{\\beta}}\\) is\n\\[\\hat{\\text{var}}(\\boldsymbol{\\hat{\\beta}}) = \\left (\\mathbf{X'X}\\right )^{-1}\\left ( \\sum_{i=1}^{n}\\hat{u}_{i}^2\\mathbf{x_{i}'x_{i}}\\right )\\left ( \\mathbf{X'X}\\right )^{-1}\\]\nThe Variance Estimator for \\(\\boldsymbol{\\hat{\\beta}}\\) Under Homoskedastic Errors is\n\\[\\hat{\\text{var}}(\\boldsymbol{\\hat{\\beta}}) = s_{\\hat{u}}^2 \\left (\\mathbf{X'X}\\right )^{-1}\\]"
  },
  {
    "objectID": "slides/ols/index.html#testing-multiple-linear-hypotheses-6",
    "href": "slides/ols/index.html#testing-multiple-linear-hypotheses-6",
    "title": "\nOrdinary Least Squares\n",
    "section": "Testing Multiple Linear Hypotheses",
    "text": "Testing Multiple Linear Hypotheses\n\nNote that you can test single restrictions this way\nSuppose you are testing \\(\\beta_{2} = 0\\). The \\(W\\) statistic reduces to\n\n\\[W = \\frac{(\\hat{\\beta}_{2} - 0)^2}{\\text{var}(\\hat{\\beta}_{2})}\\]\n\nThe \\(W\\) statistic has a \\(\\chi^2_{q}\\) distribution in large samples\nIn Stata, this is sometimes implemented as an \\(F\\)-test, where\n\\[F = \\frac{W}{q}\\]\n\\(F\\) has an \\(F\\) distribution with \\((1,n-k-1)\\) degrees of freedom"
  },
  {
    "objectID": "content/ols.html",
    "href": "content/ols.html",
    "title": "Ordinary Least Squares",
    "section": "",
    "text": "AP1 Chapter 3\nAP2 Chapter 2\nC Chapter 2\nCT Chapter 4\nHA Chapters 3,4\nHK Chapter 13\nK Chapter 3\nSW Chapters 4,5,6,7,8\nW1 Chapter 4\nW2 Chapters 2,3"
  },
  {
    "objectID": "content/ols.html#readings",
    "href": "content/ols.html#readings",
    "title": "Ordinary Least Squares",
    "section": "",
    "text": "AP1 Chapter 3\nAP2 Chapter 2\nC Chapter 2\nCT Chapter 4\nHA Chapters 3,4\nHK Chapter 13\nK Chapter 3\nSW Chapters 4,5,6,7,8\nW1 Chapter 4\nW2 Chapters 2,3"
  },
  {
    "objectID": "content/ols.html#slides",
    "href": "content/ols.html#slides",
    "title": "Ordinary Least Squares",
    "section": "Slides",
    "text": "Slides\nThe slides are embedded in this page, and you can scroll through them with the arrow keys. If you prefer you can instead pop them out in a new window"
  },
  {
    "objectID": "content/ols.html#tutorials",
    "href": "content/ols.html#tutorials",
    "title": "Ordinary Least Squares",
    "section": "Tutorials",
    "text": "Tutorials\nThe .zip file below contains the files to run a learnr interactive tutorial. To use it, first ensure that you have installed the learnr and shiny packages. Then, download the file, unpack it, open the .Rmd file in RStudio, and click “run document.”\nThere is also a plain, non-interactive PDF version of the file below.\n EC655regression.zip\n EC655regressionpdf.pdf\n EC655hypothesis.zip\n EC655hypothesispdf.pdf"
  },
  {
    "objectID": "slides/iv/index.html#introduction-1",
    "href": "slides/iv/index.html#introduction-1",
    "title": "E655 - Econometrics",
    "section": "Introduction",
    "text": "Introduction\n\nIn many empirical applications we want to estimate a causal effect\n\nThe independent effect of a particular variable on the outcome\n\nOLS is inconsistent for this parameter when the error is correlated with \\(\\mathbf{x}\\)\n\nThis happens often with omitted variables\nAlso, simultaneous equations, measurement error in \\(\\mathbf{x}\\)\n\nIf we want to consistently estimate causal parameter, we need a different method\nFirst method we will discuss is Instrumental Variables"
  },
  {
    "objectID": "slides/iv/index.html#introduction-2",
    "href": "slides/iv/index.html#introduction-2",
    "title": "E655 - Econometrics",
    "section": "Introduction",
    "text": "Introduction\n\nLike we did with the OLS estimator, we cover the statistical properties of TSLS\n\nWe will be slightly less detailed\n\nWe first need to outline the set of assumptions required for consistency"
  },
  {
    "objectID": "slides/iv/index.html#model",
    "href": "slides/iv/index.html#model",
    "title": "E655 - Econometrics",
    "section": "Model",
    "text": "Model\n\nStart with a population linear model\n\\[y =  \\mathbf{x}\\boldsymbol{\\beta}  + e\\]\nDefine \\(\\boldsymbol{\\beta}\\) as the causal effect\nA model like the above where \\(\\boldsymbol{\\beta}\\) is the causal effect is called a Structural Model\n\n\n\n\n\n\n\nImportant\n\n\nThe model above is not the same as the population regression we discussed previously. In this model we are defining \\(\\boldsymbol{\\beta}\\) specifically as the causal effect, and therefore \\(e\\) is not the same as the regression residual we defined before."
  },
  {
    "objectID": "slides/iv/index.html#model-1",
    "href": "slides/iv/index.html#model-1",
    "title": "E655 - Econometrics",
    "section": "Model",
    "text": "Model\n\nSuppose we think some parts of \\(\\mathbf{x}\\) are correlated with \\(e\\) so that\n\\[\\textbf{E}(\\mathbf{x'}e) \\neq 0\\]\nThe population least squares regression is not equal to the causal effect\n\n\\[\\boldsymbol{\\beta^{*}}=(\\textbf{E}[\\mathbf{x'x}])^{-1} \\textbf{E}[\\mathbf{x}'y]\\] \\[=(\\textbf{E}[\\mathbf{x'x}])^{-1} \\textbf{E}[\\mathbf{x}'(\\mathbf{x}\\boldsymbol{\\beta}  + e)]\\] \\[=\\boldsymbol{\\beta} + (\\textbf{E}[\\mathbf{x'x}])^{-1}\\textbf{E}[\\mathbf{x'}e]\\]"
  },
  {
    "objectID": "slides/iv/index.html#model-2",
    "href": "slides/iv/index.html#model-2",
    "title": "E655 - Econometrics",
    "section": "Model",
    "text": "Model\n\nIn this setup, the OLS estimate of \\(\\boldsymbol{\\beta^{*}}\\) is inconsistent for \\(\\boldsymbol{\\beta}\\)\n\nThis bias could come from omitted variables, but also other sources\n\nIf we want a consistent estimate of \\(\\boldsymbol{\\beta}\\) we need another method\nTo make things simpler, partition the independent variables\n\n\\[=  \\mathbf{x_{1}}\\boldsymbol{\\beta_{1}}  + x_{k}\\beta_{k}  + e\\]\n\nSuppose that \\(x_{k}\\) is correlated with \\(e\\), but \\(\\mathbf{x_{1}}\\) is not\n\n\\(x_{k}\\) is endogenous\n\\(\\mathbf{x_{1}}\\) is exogenous"
  },
  {
    "objectID": "slides/iv/index.html#model-3",
    "href": "slides/iv/index.html#model-3",
    "title": "E655 - Econometrics",
    "section": "Model",
    "text": "Model\n\nNow imagine we have an instrumental variable \\(z_{1}\\) that is\n\nUncorrelated with \\(e\\)\nCorrelated with \\(x_{k}\\)\n\nDefine the vector \\(\\mathbf{z}\\) to be\n\\[\\mathbf{z} = [1,x_{1}, x_{2}, ...,x_{k-1},z_{1}]\\]\n\nIt is the \\(\\mathbf{x}\\) vector with \\(z_{1}\\) in place of \\(x_{k}\\)\n\n\\(\\mathbf{x_{1}}\\) are included instruments\n\\(z_{1}\\) is the excluded instrument because it comes from outside the model"
  },
  {
    "objectID": "slides/iv/index.html#estimation-by-method-of-moments",
    "href": "slides/iv/index.html#estimation-by-method-of-moments",
    "title": "E655 - Econometrics",
    "section": "Estimation by Method of Moments",
    "text": "Estimation by Method of Moments\n\nApplying the method of moments to the population slope\n\\[\\boldsymbol{\\hat{\\beta}}=\\left ( \\frac{1}{n}\\sum_{i=1}^{n}\\mathbf{z_{i}'x_{i}} \\right )^{-1} \\left ( \\frac{1}{n} \\sum_{i=1}^{n}\\mathbf{z}_{i}'y_{i}\\right ) = \\left ( \\sum_{i=1}^{n}\\mathbf{z_{i}'x_{i}} \\right )^{-1} \\left ( \\sum_{i=1}^{n}\\mathbf{z}_{i}'y_{i}\\right )\\]\n\\[=\\left ( \\mathbf{Z'X} \\right )^{-1} \\left ( \\mathbf{Z'y}\\right )\\]\nThe IV estimator is very similar to the OLS estimator, except\n\nThe \\(\\mathbf{X'}\\) matrix that premultiplies the \\(\\mathbf{X}\\) matrix and \\(\\mathbf{y}\\) vector is replaced with \\(\\mathbf{Z'}\\)"
  },
  {
    "objectID": "slides/iv/index.html#model-4",
    "href": "slides/iv/index.html#model-4",
    "title": "E655 - Econometrics",
    "section": "Model",
    "text": "Model\n\nIf all factors in \\(\\mathbf{z}\\) are exogenous,\n\\[\\mathbf{E}(\\mathbf{z}'e) = 0\\]\nIf we take our model\n\\[y =  \\mathbf{x}\\boldsymbol{\\beta}  + e\\]\nPre-multiply by \\(\\mathbf{z}\\) and take expectations\n\\[\\mathbf{E}(\\mathbf{z}'y) = \\mathbf{E}(\\mathbf{z'x}) \\boldsymbol{\\beta}  + \\mathbf{E}(\\mathbf{z}'u)\\]\n\\[\\boldsymbol{\\beta}  = [\\mathbf{E}(\\mathbf{z'x})] ^{-1}\\mathbf{E}(\\mathbf{z}'y)\\]"
  },
  {
    "objectID": "slides/iv/index.html#model-5",
    "href": "slides/iv/index.html#model-5",
    "title": "E655 - Econometrics",
    "section": "Model",
    "text": "Model\n\n\n\n\n\n\nImportant\n\n\nThe population Instrumental Variables slope vector with one instrument for each endogenous variable is\n\\[\\boldsymbol{\\beta}  = [\\mathbf{E}(\\mathbf{z'x})] ^{-1}\\mathbf{E}(\\mathbf{z}'y)\\]"
  },
  {
    "objectID": "slides/iv/index.html#model-6",
    "href": "slides/iv/index.html#model-6",
    "title": "E655 - Econometrics",
    "section": "Model",
    "text": "Model\n\nTo be able to identify \\(\\boldsymbol{\\beta}\\), we need to assume\n\nRank condition: \\(\\text{rank }\\mathbf{E}(\\mathbf{z'z}) = K+1\\)\n\nThe variables in \\(\\mathbf{z}\\) are linearly independent\n\nRelevance condition: \\(\\text{rank }\\mathbf{E}(\\mathbf{z'x}) = K+1\\)\n\nThe instrument is correlated with the endogenous variable\n\n\nCombined with the orthogonality condition \\(\\mathbf{E}(\\mathbf{z}'e) = 0\\) this means an instrument must be\n\nUncorrelated with the error term\nCorrelated with the endogenous variable"
  },
  {
    "objectID": "slides/iv/index.html#model-7",
    "href": "slides/iv/index.html#model-7",
    "title": "E655 - Econometrics",
    "section": "Model",
    "text": "Model\n\nYou can also write this estimator as\n\\[\\boldsymbol{\\beta}  = \\left(\\mathbf{E}(\\mathbf{x^{*'}x^{*}})\\right)^{-1}\\mathbf{E}(\\mathbf{x}^{*'}y)\\]\n\nThis is the slope from a regression of \\(y\\) on \\(\\mathbf{x^{*}}\\)\nIt is the slope from the second stage\n\nTo see how, recall that \\[\\mathbf{x}=   \\mathbf{z}\\boldsymbol{\\Pi} + r= \\mathbf{x}^{*} + r\\]\nPre-multiply by \\(\\mathbf{x}^{*'}\\) and take expectations \\[\\mathbf{E}(\\mathbf{x}^{*'} \\mathbf{x})= \\mathbf{E}(\\mathbf{x}^{*'} \\mathbf{x}^{*}) + \\mathbf{E}(\\mathbf{x}^{*'} r)\\]\nSince by definition \\(\\mathbf{E}(\\mathbf{x}^{*'} r) = 0\\) \\[\\mathbf{E}(\\mathbf{x}^{*'} \\mathbf{x})= \\mathbf{E}(\\mathbf{x}^{*'} \\mathbf{x}^{*})\\]"
  },
  {
    "objectID": "slides/iv/index.html#model-8",
    "href": "slides/iv/index.html#model-8",
    "title": "E655 - Econometrics",
    "section": "Model",
    "text": "Model\n\nFinally, note that the IV estimator is a special case of 2SLS\nAssume we have one endogenous variable and one excluded instrument\n\nThis means that \\(\\mathbf{x}\\) and \\(\\mathbf{z}\\) are both \\(K+1\\) matrices\nThe matrix \\(\\mathbf{\\Pi}\\) is \\(K+1 \\times K+1\\)\n\nSubstitute the definition of \\(\\mathbf{x}^{*'}\\) into the formula for \\(\\boldsymbol{\\beta}\\) \\[\\boldsymbol{\\beta}  = \\left(\\mathbf{E}(\\mathbf{(z\\Pi)'x})\\right)^{-1}\\mathbf{E}((\\mathbf{z\\Pi)'}y)\\]\nDistributing the transpose and pulling \\(\\mathbf{\\Pi}\\) out of the expectation \\[\\boldsymbol{\\beta}  = \\left(\\mathbf{\\Pi'}\\mathbf{E}\\mathbf{(z'x})\\right)^{-1}\\mathbf{\\Pi'}\\mathbf{E}(\\mathbf{z'}y) =  \\left(\\mathbf{E}\\mathbf{(z'x})\\right)^{-1}(\\mathbf{\\Pi'})^{-1}\\mathbf{\\Pi'}\\mathbf{E}(\\mathbf{z'}y)\\] \\[\\boldsymbol{\\beta}  =\\left(\\mathbf{E}(\\mathbf{z}'\\mathbf{x})\\right)^{-1} \\mathbf{E}(\\mathbf{z}'y)\\]"
  },
  {
    "objectID": "slides/iv/index.html#model-9",
    "href": "slides/iv/index.html#model-9",
    "title": "E655 - Econometrics",
    "section": "Model",
    "text": "Model\n\nFinally, note that the IV estimator is a special case of 2SLS\nAssume we have one endogenous variable and one excluded instrument\n\nThis means that \\(\\mathbf{x}\\) and \\(\\mathbf{z}\\) are both \\(K+1\\) matrices\nThe matrix \\(\\mathbf{\\Pi}\\) is \\(K+1 \\times K+1\\)\n\nSubstitute the definition of \\(\\mathbf{x}^{*'}\\) into the formula for \\(\\boldsymbol{\\beta}\\) \\[\\boldsymbol{\\beta}  = \\left(\\mathbf{E}(\\mathbf{(z\\Pi)'x})\\right)^{-1}\\mathbf{E}((\\mathbf{z\\Pi)'}y)\\]\nDistributing the transpose and pulling \\(\\mathbf{\\Pi}\\) out of the expectation \\[\\boldsymbol{\\beta}  = \\left(\\mathbf{\\Pi'}\\mathbf{E}\\mathbf{(z'x})\\right)^{-1}\\mathbf{\\Pi'}\\mathbf{E}(\\mathbf{z'}y) =  \\left(\\mathbf{E}\\mathbf{(z'x})\\right)^{-1}(\\mathbf{\\Pi'})^{-1}\\mathbf{\\Pi'}\\mathbf{E}(\\mathbf{z'}y)\\] \\[\\boldsymbol{\\beta}  =\\left(\\mathbf{E}(\\mathbf{z}'\\mathbf{x})\\right)^{-1} \\mathbf{E}(\\mathbf{z}'y)\\]"
  },
  {
    "objectID": "slides/iv/index.html#model-10",
    "href": "slides/iv/index.html#model-10",
    "title": "E655 - Econometrics",
    "section": "Model",
    "text": "Model\n\nFinally, note that the IV estimator is a special case of 2SLS\nAssume we have one endogenous variable and one excluded instrument\n\nThis means that \\(\\mathbf{x}\\) and \\(\\mathbf{z}\\) are both \\(K+1\\) matrices\nThe matrix \\(\\mathbf{\\Pi}\\) is \\(K+1 \\times K+1\\)\n\nSubstitute the definition of \\(\\mathbf{x}^{*'}\\) into the formula for \\(\\boldsymbol{\\beta}\\) \\[\\boldsymbol{\\beta}  = \\left(\\mathbf{E}(\\mathbf{(z\\Pi)'x})\\right)^{-1}\\mathbf{E}((\\mathbf{z\\Pi)'}y)\\]\nDistributing the transpose and pulling \\(\\mathbf{\\Pi}\\) out of the expectation \\[\\boldsymbol{\\beta}  = \\left(\\mathbf{\\Pi'}\\mathbf{E}\\mathbf{(z'x})\\right)^{-1}\\mathbf{\\Pi'}\\mathbf{E}(\\mathbf{z'}y) =  \\left(\\mathbf{E}\\mathbf{(z'x})\\right)^{-1}(\\mathbf{\\Pi'})^{-1}\\mathbf{\\Pi'}\\mathbf{E}(\\mathbf{z'}y)\\] \\[\\boldsymbol{\\beta}  =\\left(\\mathbf{E}(\\mathbf{z}'\\mathbf{x})\\right)^{-1} \\mathbf{E}(\\mathbf{z}'y)\\]"
  },
  {
    "objectID": "slides/iv/index.html#estimation-by-method-of-moments-1",
    "href": "slides/iv/index.html#estimation-by-method-of-moments-1",
    "title": "E655 - Econometrics",
    "section": "Estimation by Method of Moments",
    "text": "Estimation by Method of Moments\n\nAs before, substitute sample versions of population moments to get\nAlso recall that this is a two-step process\nThe first stage, is the regression of \\(\\mathbf{x}\\) on \\(\\mathbf{z}\\)\nThe population slope vector is is\n\n\\[\\boldsymbol{\\pi} = \\left ( \\mathbf{E}(\\mathbf{z'z}) \\right )^{-1} \\mathbf{E}(\\mathbf{z'x_{k}})\\]\n\nThe sample version is\n\n\\[\\boldsymbol{\\hat{\\pi}} = \\left( \\mathbf{Z'Z} \\right)^{-1}\\mathbf{Z'x_{k}}\\]"
  },
  {
    "objectID": "slides/iv/index.html#estimation-by-method-of-moments-2",
    "href": "slides/iv/index.html#estimation-by-method-of-moments-2",
    "title": "E655 - Econometrics",
    "section": "Estimation by Method of Moments",
    "text": "Estimation by Method of Moments\n\nThe predicted values of \\(x_{k}\\) are\n\n\\[\\mathbf{\\hat{x}}_{k} = \\mathbf{Z}\\boldsymbol{\\hat{\\pi}}\\]\n\nThe second stage replaces \\(x_{k}\\) with \\(\\mathbf{\\hat{x}}_{k}\\)\nThe sample regression slope vector is\n\n\\[\\boldsymbol{\\hat{\\beta}}  = \\left( \\mathbf{\\mathbf{\\hat{X}}'\\mathbf{\\hat{X}}} \\right)^{-1}\\mathbf{\\mathbf{\\hat{X}}'y}\\]"
  },
  {
    "objectID": "slides/iv/index.html#estimation-by-method-of-moments-3",
    "href": "slides/iv/index.html#estimation-by-method-of-moments-3",
    "title": "E655 - Econometrics",
    "section": "Estimation by Method of Moments",
    "text": "Estimation by Method of Moments\n\nWhen there is one endogenous variable, the matrix \\(\\mathbf{\\hat{X}}\\) is\n\\[\\mathbf{\\hat{X}} =\n\\begin{bmatrix}\n1 & x_{11}  & x_{12} &\\cdots&x_{1,k-1} & \\hat{x}_{1k}\\\\\n1 & x_{21}  & x_{22} &\\cdots&x_{2,k-1} & \\hat{x}_{2k}\\\\\n\\vdots  & \\vdots & \\ddots &\\vdots &\\vdots \\\\\n1 & x_{n1}  & x_{n2} &\\cdots&x_{n,k-1} & \\hat{x}_{nk}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\mathbf{X_{1}} & \\mathbf{\\hat{x}_{k}}\n\\end{bmatrix}\\]\n\n\n\n\n\n\n\nImportant\n\n\nThe TSLS estimator is\n\\[\\boldsymbol{\\hat{\\beta}}  = \\left( \\mathbf{\\mathbf{\\hat{X}}'\\mathbf{\\hat{X}}} \\right)^{-1}\\mathbf{\\mathbf{\\hat{X}}'y}\\]"
  },
  {
    "objectID": "slides/iv/index.html#intuition",
    "href": "slides/iv/index.html#intuition",
    "title": "E655 - Econometrics",
    "section": "Intuition",
    "text": "Intuition\n\nThe starting point for TSLS is an endogenous variable\n\nA variable that is correlated with \\(e\\)\nUsually because of omitted variables bias\n\nOLS will not consistently identify the slope vector \\(\\boldsymbol{\\beta}\\)\nWe have access to at least one variable from outside the model that is\n\nUncorrelated with the error term \\(e\\)\nCorrelated with the endogenous variable \\(x_{k}\\)"
  },
  {
    "objectID": "slides/iv/index.html#intuition-1",
    "href": "slides/iv/index.html#intuition-1",
    "title": "E655 - Econometrics",
    "section": "Intuition",
    "text": "Intuition\n\nThe first stage regresses \\(x_{k}\\) on all exogenous variables\n\nSeparates \\(x_{k}\\) into two pieces\n\nThe exogenous part: the piece that is correlated with the exogenous variables\nThe endogenous part: the residual from this regression, which is uncorrelated with the exogenous piece\n\nThe first stage purges the endogenous component from \\(x_{k}\\)\nKeeps only the exogenous component, \\(\\hat{x}_{k}\\)\n\nWe use the only the exogenous piece \\(\\hat{x}_{k}\\) in the second stage regression"
  },
  {
    "objectID": "slides/iv/index.html#introduction-3",
    "href": "slides/iv/index.html#introduction-3",
    "title": "E655 - Econometrics",
    "section": "Introduction",
    "text": "Introduction\n\nThere are two main assumptions for instrumental variables\n\nExclusion restriction: instruments are from outside the model and uncorrelated with \\(e\\)\nRank condition: excluded instruments are sufficiently related to the endogenous variable\n\nThis is sometimes also called the instrument relevance condition\n\n\nFailure of either creates problems\nTo understand these issues, it is useful to study the following model\n\n\\[y = \\beta_{0} + \\beta_{1}x_{1} + e\\]\n\\[x_{1} = \\pi_{0} + \\pi_{1}z_{1} + r\\]"
  },
  {
    "objectID": "slides/iv/index.html#assumptions",
    "href": "slides/iv/index.html#assumptions",
    "title": "E655 - Econometrics",
    "section": "Assumptions",
    "text": "Assumptions\n\n\\(\\mathbf{E}(\\mathbf{z}'e) = 0\\)\n\nThe vector of exogenous variables is uncorrelated with \\(u\\)\nThis is sometimes called the exclusion restriction\n\nThe instruments come from outside the model and are uncorrelated with the error"
  },
  {
    "objectID": "slides/iv/index.html#assumptions-1",
    "href": "slides/iv/index.html#assumptions-1",
    "title": "E655 - Econometrics",
    "section": "Assumptions",
    "text": "Assumptions\n\n\\(\\text{rank } \\mathbf{E}(\\mathbf{z'z}) = L\\) and \\(\\text{rank } \\mathbf{E}(\\mathbf{z'x}) = K\\)\n\nFirst part says that none of the variables in \\(\\mathbf{z}\\) are perfectly collinear\nSecond part is the rank condition\n\nThe instruments must be sufficiently correlated with the endogenous variable\nWe will come back to this when we talk about weak instruments\n\nFor this assumption to hold we also need to meet the order condition\n\nThere are at least as many instruments as endogenous variables\nMathematically, we need \\(L\\ge K+1\\)\n\n\n\\(\\{(\\mathbf{x}_{i},\\mathbf{z_{i}}, y_{i}: i=1,2,...n)\\}\\) are a random sample"
  },
  {
    "objectID": "slides/iv/index.html#consistency",
    "href": "slides/iv/index.html#consistency",
    "title": "E655 - Econometrics",
    "section": "Consistency",
    "text": "Consistency\n\nIf all of the assumptions are met, the TSLS estimator is consistent for \\(\\boldsymbol{\\beta}\\)\nWe will not do the proof, but it is very similar to OLS\nIf any of the assumptions fail, the TSLS estimator is inconsistent"
  },
  {
    "objectID": "slides/iv/index.html#unbiasedness",
    "href": "slides/iv/index.html#unbiasedness",
    "title": "E655 - Econometrics",
    "section": "Unbiasedness",
    "text": "Unbiasedness\n\nIn small samples, the TSLS estimator is generally biased\nWe will not cover the proof\nYou should only use TSLS with large samples"
  },
  {
    "objectID": "slides/iv/index.html#large-sample-distribution-of-boldsymbolhatbeta",
    "href": "slides/iv/index.html#large-sample-distribution-of-boldsymbolhatbeta",
    "title": "E655 - Econometrics",
    "section": "Large Sample Distribution of \\(\\boldsymbol{\\hat{\\beta}}\\)",
    "text": "Large Sample Distribution of \\(\\boldsymbol{\\hat{\\beta}}\\)\n\nWe again appeal to the Central Limit Theorem\nWith large \\(n\\), the TSLS estimator has a Normal distribution with mean \\(\\boldsymbol{\\beta}\\) and variance\n\\[\\text{var}(\\boldsymbol{\\hat{\\beta}}) = n^{-1}[\\mathbf{E}(\\mathbf{x^{*'}x^{*}})^{-1}]\\mathbf{E}(u^2\\mathbf{x^{*'}x^{*}})[\\mathbf{E}(\\mathbf{x^{*'}x^{*}})^{-1}]\\]\nIf we assume homoskedasticity \\(\\mathbf{E}(u^2|\\mathbf{z}) = \\sigma^2\\) this reduces to\n\\[\\text{var}(\\boldsymbol{\\hat{\\beta}}) = \\sigma^2 n^{-1}\\mathbf{E}(\\mathbf{x^{*'}x^{*}})^{-1}\\]"
  },
  {
    "objectID": "slides/iv/index.html#variance-estimator-for-boldsymbolhatbeta",
    "href": "slides/iv/index.html#variance-estimator-for-boldsymbolhatbeta",
    "title": "E655 - Econometrics",
    "section": "Variance Estimator for \\(\\boldsymbol{\\hat{\\beta}}\\)",
    "text": "Variance Estimator for \\(\\boldsymbol{\\hat{\\beta}}\\)\n\nTo estimate the variance, substitute sample versions of the population moments\nThe Heteroskedasticity-Robust variance estimator is\n\\[\\hat{\\text{var}}(\\boldsymbol{\\hat{\\beta}}) = \\left (\\mathbf{\\hat{X}'\\hat{X}}\\right )^{-1}\\left ( \\sum_{i=1}^{n}\\hat{u}_{i}^2\\mathbf{\\hat{x}_{i}'\\hat{x}_{i}}\\right )\\left ( \\mathbf{\\hat{X}'\\hat{X}}\\right )^{-1}\\]\nIf we assume homoskedasticity, it is\n\\[\\hat{\\text{var}}(\\boldsymbol{\\hat{\\beta}}) = s_{\\hat{u}}^2 \\left (\\mathbf{\\hat{X}'\\hat{X}}\\right )^{-1}\\]\nIn both cases, we use the TSLS residuals, which are\n\\[\\mathbf{\\hat{u}} = \\mathbf{y} - \\mathbf{X}\\boldsymbol{\\hat{\\beta}}\\]"
  },
  {
    "objectID": "slides/iv/index.html#variance-estimator-for-boldsymbolhatbeta-1",
    "href": "slides/iv/index.html#variance-estimator-for-boldsymbolhatbeta-1",
    "title": "E655 - Econometrics",
    "section": "Variance Estimator for \\(\\boldsymbol{\\hat{\\beta}}\\)",
    "text": "Variance Estimator for \\(\\boldsymbol{\\hat{\\beta}}\\)\n\nThese are not the residuals from the second stage regression \\(\\mathbf{y} - \\mathbf{\\hat{X}}\\boldsymbol{\\hat{\\beta}}\\)\n\nUse \\(\\mathbf{X}\\) – not \\(\\mathbf{\\hat{X}}\\) – in this calculation\nThis is a common mistake\nUsing the wrong residuals will lead to incorrect estimates of the standard errors"
  },
  {
    "objectID": "slides/iv/index.html#structural-vs-reduced-form-equations",
    "href": "slides/iv/index.html#structural-vs-reduced-form-equations",
    "title": "E655 - Econometrics",
    "section": "Structural vs Reduced form Equations",
    "text": "Structural vs Reduced form Equations\n\nIn this section we present details that are useful for using TSLS in practice\nThis will help you understand when you read papers using TSLS\nSuppose we have a model with one endogenous variable and one instrument\nThe instrumental variables model in scalar notation is\n\n\\[y =  \\beta_{0} + x_{1}\\beta_{1} +...+ x_{k-1}\\beta_{k-1} + x_{k}\\beta_{k}  + e\\] \\[x_{k} =  \\pi_{0} + x_{1}\\pi_{1}+...+x_{k-1}\\pi_{k-1}  +z_{1}\\delta_{1}  + r\\]\n\nThe first equation is the structural equation\n\nThe equation containing the causal effects we are interested in"
  },
  {
    "objectID": "slides/iv/index.html#structural-vs-reduced-form-equations-1",
    "href": "slides/iv/index.html#structural-vs-reduced-form-equations-1",
    "title": "E655 - Econometrics",
    "section": "Structural vs Reduced form Equations",
    "text": "Structural vs Reduced form Equations\n\nThe second equation is the first stage\n\nIt is a reduced form equation\n\nAll of the regressors are exogenous\nThe parameters do not necessarily represent causal effects\n\n\nResearchers often also estimate the reduced form for \\(y\\)\n\nSub the second equation into the first to get\n\n\n\\[y =  (\\beta_{0} + \\beta_{k}\\pi_{0}) + x_{1}(\\beta_{1} + \\beta_{k}\\pi_{1}) +...+ x_{k-1} (\\beta_{k-1}+ \\beta_{k}\\pi_{k-1}) + z_{1}\\beta_{k}\\delta_{1}  + e + \\beta_{k}r\\]\n\\[= \\gamma_{0}+ x_{1}\\gamma_{1}+...+ x_{k-1} \\gamma_{k-1}+ z_{1}\\theta_{1}+ \\epsilon\\]\n\nThis is the regression of \\(y\\) on all the exogenous variables"
  },
  {
    "objectID": "slides/iv/index.html#structural-vs-reduced-form-equations-2",
    "href": "slides/iv/index.html#structural-vs-reduced-form-equations-2",
    "title": "E655 - Econometrics",
    "section": "Structural vs Reduced form Equations",
    "text": "Structural vs Reduced form Equations\n\nIn the reduced form for \\(y\\), the slope \\(\\theta_{1} = \\beta_{k}\\delta_{1}\\)\n\nThe effect of \\(z_{1}\\) on \\(x_{k}\\) times the effect of \\(x_{k}\\) on \\(y\\)\n\nYou can get the slope \\(\\beta_{k}\\) by dividing the reduced form by the first stage\n\\[\\beta_{k}  = \\frac{\\theta_{1}}{\\delta_{1}}\\]\n\\(\\beta_{k}\\) is the reduced form effect scaled by the first stage\n\nEx: returns to schooling\nImagine \\(y\\) is income, \\(x_{k}\\) is years of schooling, \\(z_{1}\\) is kms to nearest university\nIf \\(\\delta_{1} = .5\\), being 1km closer to school leads to .5 more years of schooling\nIf \\(\\theta_{1} = 10000\\), being 1km closer to school leads to $10000 more income\nThen \\(\\beta_{k} = \\frac{10000}{.5} = 20000\\) is effect of a year of additional schooling"
  },
  {
    "objectID": "slides/iv/index.html#introduction-4",
    "href": "slides/iv/index.html#introduction-4",
    "title": "E655 - Econometrics",
    "section": "Introduction",
    "text": "Introduction\n\nIn this model, you can show that\n\n\\[\\text{plim }\\hat{\\beta}_{1} = \\beta_{1} + \\frac{cov(z_{1},e)}{cov(z_{1},x_{1})}\\] \\[= \\beta_{1} + \\frac{\\sigma_{e}}{\\sigma_{x_{1}}}\\frac{corr(z_{1},e)}{corr(z_{1},x_{1})}\\]\n\nWe will use this result to inform ourselves about the failure of our assumptions\nThe key idea is that instruments must be relevant and exogenous"
  },
  {
    "objectID": "slides/iv/index.html#introduction-5",
    "href": "slides/iv/index.html#introduction-5",
    "title": "E655 - Econometrics",
    "section": "Introduction",
    "text": "Introduction\n\nThe Rubin model tells us how to interpret the slope in a regression model\nSpecific interpretation depends on assumptions\n\nIf we make strong assumption that treatment is randomly assigned, regression slope is the average treatment effect (ATE)\nWeaker assumption of mean independence or conditional mean independence of \\(y_{0}\\) gives us average treatment effect on the treated (ATT)\n\nBut in an instrumental variables model, these assumptions are violated\n\nThe error term is correlated with treatment\nSo we cannot assume mean independence of the error\n\nIn this section, we alter the Rubin model to interpret the slope in an IV model"
  },
  {
    "objectID": "slides/iv/index.html#exclusion-restriction",
    "href": "slides/iv/index.html#exclusion-restriction",
    "title": "E655 - Econometrics",
    "section": "Exclusion Restriction",
    "text": "Exclusion Restriction\n\nConsider the plim of the TSLS slope estimator\n\n\\[\\text{plim }\\hat{\\beta}_{1} = \\beta_{1} + \\frac{cov(z_{1},e)}{cov(z_{1},x_{1})}\\]\n\nIf the exclusion restriction holds, then \\(cov(z_{1},e) = 0\\) and \\(\\text{plim }\\hat{\\beta}_{1} = \\beta_{1}\\)\nIf not then \\(\\text{plim }\\hat{\\beta}_{1} \\neq \\beta_{1}\\) and the TSLS estimator is inconsistent\nCan we check to see if this assumption is true?\nIf we have one excluded instrument for each endogenous variable, we cannot\n\nThere are no enough degrees of freedom to test the exclusion restriction\nWe have to rely only on our assumptions in this case"
  },
  {
    "objectID": "slides/iv/index.html#exclusion-restriction-1",
    "href": "slides/iv/index.html#exclusion-restriction-1",
    "title": "E655 - Econometrics",
    "section": "Exclusion Restriction",
    "text": "Exclusion Restriction\n\nWith multiple excluded instruments for the endogenous variable, we can\n\nWe use the extra instruments to test whether the others are endogenous\n\nA useful test when errors are homoskedastic is the Sargan Test\n\nEstimate the model using TSLS\nCompute the TSLS residuals, \\(\\mathbf{\\hat{u}}\\)\nRegress \\(\\mathbf{\\hat{u}}\\) on all instruments \\(\\mathbf{z}\\)\n\nSave \\(R^2_u\\) from this regression\n\nThe test statistic is \\(nR^2_u\\)\n\nHas a \\(\\chi^2_{Q_{1}}\\) distribution, where \\(Q_{1}\\) are overidentifying restrictions\n\nThe null hypothesis is exogeneity"
  },
  {
    "objectID": "slides/iv/index.html#exclusion-restriction-2",
    "href": "slides/iv/index.html#exclusion-restriction-2",
    "title": "E655 - Econometrics",
    "section": "Exclusion Restriction",
    "text": "Exclusion Restriction\n\nThere is a more complicated test with heteroskedastic errors\n\nYou can easily execute this in R or Stata\nWe can discuss the process separately\n\nIf you fail this test (reject the null), then you need to find other instruments"
  },
  {
    "objectID": "slides/iv/index.html#instrument-relevance",
    "href": "slides/iv/index.html#instrument-relevance",
    "title": "E655 - Econometrics",
    "section": "Instrument Relevance",
    "text": "Instrument Relevance\n\nFor TSLS to work, the instrument must be relevant\n\nIt must be sufficiently correlated with the endogenous variable\n\nAn instrument that is not sufficiently relevant is a weak instrument\nWeak instruments can cause several problems\n\n\nInconsistency when the instrument and error are not exactly uncorrelated\n\nConsider the plim of the TSLS slope estimator\n\n\n\\[\\text{plim }\\hat{\\beta}_{1} =  \\beta_{1} + \\frac{\\sigma_{e}}{\\sigma_{x_{1}}}\\frac{corr(z_{1},e)}{corr(z_{1},x_{1})}\\]"
  },
  {
    "objectID": "slides/iv/index.html#instrument-relevance-1",
    "href": "slides/iv/index.html#instrument-relevance-1",
    "title": "E655 - Econometrics",
    "section": "Instrument Relevance",
    "text": "Instrument Relevance\n\nContinued...\n\nWhen \\(corr(z_{1},x_{1}) \\rightarrow 0\\) then \\(\\frac{corr(z_{1},e)}{corr(z_{1},x_{1})} \\rightarrow \\infty\\)\n\nTrue even when \\(corr(z_{1},e)\\) is very close to zero\n\nAlso note that the plim of the OLS estimator is\n\\[\\text{plim }\\hat{\\beta}_{1}^{ols} =  \\beta_{1} + \\frac{\\sigma_{e}}{\\sigma_{x_{1}}}corr(x_{1},e)\\]\nTaking the ratio of the two biases \\[\\frac{\\hat{\\beta}_{1}-\\beta_{1}}{\\hat{\\beta}_{1}^{ols}-\\beta_{1}} =  \\frac{corr(z_{1},e)/corr(x_{1},e)}{corr(z_{1},x_{1})}\\]\nAs \\(corr(z_{1},x_{1}) \\rightarrow 0\\), the inconsistency in 2SLS becomes larger than the inconsistency in OLS"
  },
  {
    "objectID": "slides/iv/index.html#instrument-relevance-2",
    "href": "slides/iv/index.html#instrument-relevance-2",
    "title": "E655 - Econometrics",
    "section": "Instrument Relevance",
    "text": "Instrument Relevance\n\nFinite sample bias in TSLS becomes large\n\nThe expected value of the TSLS estimator can be written as\n\\[\\mathbf{E}(\\hat{\\beta}_{1} - \\beta_{1}) \\approx \\frac{\\sigma_{er}}{\\sigma_{r}^2}\\frac{1}{F+1}\\]\nWhere \\(F\\) is the F-statistic from the test of joint significance of the excluded regressors\nWeak instruments means that \\(F\\) is close to zero\nAs \\(F\\) gets small, the bias tends to \\(\\frac{\\sigma_{er}}{\\sigma_{r}^2}\\)\n\nIf \\(F\\) is exactly zero, that means the instrument is irrelevant \\((\\pi_{1}=0)\\)\nIn this case \\(\\frac{\\sigma_{er}}{\\sigma_{r}^2}\\) is also the OLS bias\nSo 2SLS and OLS produce the same biased result\n\nWhen instruments are weak, TSLS is biased towards OLS"
  },
  {
    "objectID": "slides/iv/index.html#instrument-relevance-3",
    "href": "slides/iv/index.html#instrument-relevance-3",
    "title": "E655 - Econometrics",
    "section": "Instrument Relevance",
    "text": "Instrument Relevance\n\nStandard inference is no longer valid\n\nWe rely in the central limit theorem to show TSLS estimator has a Normal distribution\nWith weak instruments, this no longer holds\n\nThe estimator has the distribution of the ratio of two Normal variables\n\nIn this case the t-statistic no longer has a t-distribution\nHypothesis tests tend to reject the null more than it should"
  },
  {
    "objectID": "slides/iv/index.html#instrument-relevance-4",
    "href": "slides/iv/index.html#instrument-relevance-4",
    "title": "E655 - Econometrics",
    "section": "Instrument Relevance",
    "text": "Instrument Relevance\n\nThere are several tests available to check for weak instruments\n\n\nTest with one endogenous regressor\n\nBased on F-statistic on excluded instruments in first stage\nCritical values for set amount of bias or size distortion\nEx: when \\(F=10\\) maximum TSLS bias is about 10% of OLS bias\nAlso when \\(F=10\\), the rejection rate of a 5% test is no more than 20%\nAs \\(F\\) gets larger, relative bias shrinks and test size distortion falls\n\\(F=10\\) is often called “Staiger Stock rule of thumb”, based on authors who developed it\nGenerally thought that when \\(F&gt;10\\), instruments are not weak"
  },
  {
    "objectID": "slides/iv/index.html#instrument-relevance-5",
    "href": "slides/iv/index.html#instrument-relevance-5",
    "title": "E655 - Econometrics",
    "section": "Instrument Relevance",
    "text": "Instrument Relevance\n\nTest with more than one endogenous regressor\n\nSuppose you have two endogenous variables and two instruments\nYou could compute a first stage \\(F\\) for each endogenous variable\nProblem arises when you have one instrument that is strong in both first stages\nIn this case you have one strong and one weak instrument\nCragg-Donald F-Statistic is modified F-stat for doing this test jointly\n\nTest that are heteroskedasticity-robust\n\nBoth tests described above assume homoskedastic errors\nKelibergen-Paap adjusted the test for heteroskedasticity\nOtherwise, works in the same way as described above"
  },
  {
    "objectID": "slides/iv/index.html#instrument-relevance-6",
    "href": "slides/iv/index.html#instrument-relevance-6",
    "title": "E655 - Econometrics",
    "section": "Instrument Relevance",
    "text": "Instrument Relevance\n\nFinally, what if we fail the weak instrument tests?\n\n\nFind better instruments or drop weak ones\n\nIf your model is overidentified, you can drop the weak instruments\nIf it is exactly identified, you could try to find better instruments\n\nThis is not easy since instruments generally come from natural experiments\n\n\nUse weak instrument robust inference\n\nAs noted, t-tests will reject the null too often with weak instruments\nYou can adjust testing to have the correct size\nThere are several available\n\nAnderson Rubin (AR)\nConditional Likelihood Ration (CLR)\nWe will not cover the details of this, but all are available in Stata"
  },
  {
    "objectID": "slides/iv/index.html#introduction-6",
    "href": "slides/iv/index.html#introduction-6",
    "title": "E655 - Econometrics",
    "section": "Introduction",
    "text": "Introduction\n\nThe Rubin model tells us how to interpret the slope in a regression model\nSpecific interpretation depends on assumptions\n\nIf we make strong assumption that treatment is randomly assigned, regression slope is the average treatment effect (ATE)\nWeaker assumption of mean independence or conditional mean independence of \\(y_{0}\\) gives us average treatment effect on the treated (ATT)\n\nBut in an instrumental variables model, these assumptions are violated\n\nThe error term is correlated with treatment\nSo we cannot assume mean independence of the error\n\nIn this section, we alter the Rubin model to interpret the slope in an IV model"
  },
  {
    "objectID": "slides/iv/index.html#local-average-treatment-effects",
    "href": "slides/iv/index.html#local-average-treatment-effects",
    "title": "E655 - Econometrics",
    "section": "Local Average Treatment Effects",
    "text": "Local Average Treatment Effects\n\nStart with the observed outcomes from the Rubin model \\[y = y_{0} + (y_{1} -y_{0})w\\]\nNow suppose we have a binary instrument \\(z\\)\n\nThis variable measures your assignment to treatment\n\nDefine observed treatment as \\[w = w_{0} + (w_{1} -w_{0})z\\]\n\n\\(w_{1}\\) is potential treatment when assigned to treatment\n\\(w_{0}\\) is potential treatment when not assigned to treatment\nWe observe \\(w=w_{0}\\) when \\(z=0\\) and \\(w=w_{1}\\) when \\(z=1\\)"
  },
  {
    "objectID": "slides/iv/index.html#local-average-treatment-effects-1",
    "href": "slides/iv/index.html#local-average-treatment-effects-1",
    "title": "E655 - Econometrics",
    "section": "Local Average Treatment Effects",
    "text": "Local Average Treatment Effects\n\nAssume that the instrument is independent of treatment and outcomes \\[(y_{0}, y_{1}, w_{0}, w_{1}) \\perp z\\]\nThe TSLS estimator is the reduced form divided by the first stage\nIn this setup with binary \\(y\\), the reduced form is\n\\[E(y|z=1) - E(y|z=0)\\]\nand with binary \\(w\\) the first stage is\n\\[E(w|z=1) - E(w|z=0)\\]\nSo that the IV estimator is\n\\[\\frac{E(y|z=1) - E(y|z=0)}{E(w|z=1) - E(w|z=0)}\\]"
  },
  {
    "objectID": "slides/iv/index.html#local-average-treatment-effects-2",
    "href": "slides/iv/index.html#local-average-treatment-effects-2",
    "title": "E655 - Econometrics",
    "section": "Local Average Treatment Effects",
    "text": "Local Average Treatment Effects\n\nTo get the numerator, first substitute \\(w\\) equation into \\(y\\) equation \\[y = y_{0} + (y_{1} -y_{0})w_{0} +  (y_{1} -y_{0})(w_{1} -w_{0})z\\]\nThis allows us to write the following conditional expectations \\[E(y|z=1) = E(y_{0}) + E((y_{1} -y_{0})w_{0}) +  E((y_{1} -y_{0})(w_{1} -w_{0}))\\] \\[E(y|z=0) = E(y_{0}) + E((y_{1} -y_{0})w_{0})\\]\nSo, \\[E(y|z=1) - E(y|z=0) =  E((y_{1} -y_{0})(w_{1} -w_{0}))\\]"
  },
  {
    "objectID": "slides/iv/index.html#local-average-treatment-effects-3",
    "href": "slides/iv/index.html#local-average-treatment-effects-3",
    "title": "E655 - Econometrics",
    "section": "Local Average Treatment Effects",
    "text": "Local Average Treatment Effects\n\nNote that \\[E((y_{1} -y_{0})(w_{1} -w_{0}))\\] \\[= E(y_{1} -y_{0}|w_{1} -w_{0} = 1)P(w_{1} -w_{0} = 1)\\] \\[- E(y_{1} -y_{0}|w_{1} -w_{0} = -1)P(w_{1} -w_{0} = -1)\\] \\[+0\\times E(y_{1} -y_{0}|w_{1} -w_{0} = 0)P(w_{1} -w_{0} = 0)\\]\nThe last term drops out since it is zero\nReduced form is the difference in treatment effect between two groups\n\n\\(E(y_{1} -y_{0}|w_{1} -w_{0} = 1)\\) is the treatment effect for “compliers”\n\nCompliers have \\(w_{1}=1\\) and \\(w_{0} = 0\\), so that \\(w_{1} -w_{0} = 1\\)\n\n\\(E(y_{1} -y_{0}|w_{1} -w_{0} = -1)\\) is the treatment effect for “defiers”\n\nDefiers have \\(w_{1}=0\\) and \\(w_{0} = 1\\), so that \\(w_{1} -w_{0} = -1\\)"
  },
  {
    "objectID": "slides/iv/index.html#local-average-treatment-effects-4",
    "href": "slides/iv/index.html#local-average-treatment-effects-4",
    "title": "E655 - Econometrics",
    "section": "Local Average Treatment Effects",
    "text": "Local Average Treatment Effects\n\nProblem: reduced form might be 0 even with positive treatment effects for both groups\n\nSuppose \\(E(y_{1} -y_{0}|w_{1} -w_{0} = 1) = E(y_{1} -y_{0}|w_{1} -w_{0} = -1)\\)\nThen \\(E(y|z=1) - E(y|z=0) = 0\\) and reduced form effect is zero\nMakes it difficult to measure treatment effects\n\nTo correct for this, we must assume monotonicity \\[w_{1} \\ge w_{0}\\]\n\nSays effect of instrument goes one way\nIf assigned to treatment you take it, if not you don’t take it\nPrecludes defiers who don’t take treatment when assigned, take it when not assigned"
  },
  {
    "objectID": "slides/iv/index.html#local-average-treatment-effects-5",
    "href": "slides/iv/index.html#local-average-treatment-effects-5",
    "title": "E655 - Econometrics",
    "section": "Local Average Treatment Effects",
    "text": "Local Average Treatment Effects\n\nMonotonicity implies \\(P(w_{1} -w_{0} = -1) = 0\\), so \\[E(y|z=1) - E(y|z=0)\\] \\[= E(y_{1} -y_{0}|w_{1} -w_{0} = 1)P(w_{1} -w_{0} = 1)\\]\nWith monotonicity \\((w_{1} -w_{0})\\) can equal 0 or 1, so\n\\[E(w_{1} - w_{0}) = 1\\times P(w_{1} -w_{0} = 1) + 0\\times P(w_{1} -w_{0} = 0)\\] \\[=P(w_{1} -w_{0} = 1)\\]\nUsing this in the reduced form gives us\n\\[E(y|z=1) - E(y|z=0)\\] \\[= E(y_{1} -y_{0}|w_{1} -w_{0} = 1)E(w_{1} -w_{0})\\]"
  },
  {
    "objectID": "slides/iv/index.html#local-average-treatment-effects-6",
    "href": "slides/iv/index.html#local-average-treatment-effects-6",
    "title": "E655 - Econometrics",
    "section": "Local Average Treatment Effects",
    "text": "Local Average Treatment Effects\n\nTo derive the denominator, remember potential treatment are independent of \\(z\\) \\[E(w |z=1) -E(w|z = 0) = E(w_{1} -w_{0})\\]\nCombining the numerator and denominator \\[\\frac{E(y|z=1) - E(y|z=0)}{E(w|z=1) - E(w|z=0)} = \\frac{E(y_{1} -y_{0}|w_{1} -w_{0} = 1)E(w_{1} -w_{0}) }{E(w_{1} -w_{0}) }\\]\n\\[= E(y_{1} -y_{0}|w_{1} -w_{0} = 1)\\]\nSays the IV estimator equals \\(E(y_{1} -y_{0}|w_{1} -w_{0} = 1)\\)\n\nThis is known as the Local Average Treatment Effect (LATE)\nThe average treatment effect among compliers\nCan interpret as treatment effect among people influenced by instrument"
  },
  {
    "objectID": "slides/iv/index.html#examples-of-late",
    "href": "slides/iv/index.html#examples-of-late",
    "title": "E655 - Econometrics",
    "section": "Examples of LATE",
    "text": "Examples of LATE\n\nSmith (2009)\n\nEffect of school entry age on test scores\nUses “assigned entry age” as instrument for actual entry age\nLATE: measures effect of entry age on test scores for people who follow rules\n\nAngrist (1990)\n\nEffect of military service on earnings\nUses draft eligibility as determined by lottery as instrument for military service\nLATE: measures effect of military service for those who complied with the draft lottery\n\nKey: often the “complier” subpopulation is different from the average population\n\nSo LATE \\(\\neq\\) ATE in general"
  },
  {
    "objectID": "slides/iv/index.html#late-in-regression",
    "href": "slides/iv/index.html#late-in-regression",
    "title": "E655 - Econometrics",
    "section": "LATE in Regression",
    "text": "LATE in Regression\n\nAn instrumental variables model without covariates is \\[y = \\beta_{0} + \\beta_{1}w + e\\] \\[w = \\pi_{0} + \\pi_{1}z + r\\]\nThe reduced form for \\(y\\) is therefore\n\\[y = \\gamma_{0} + \\gamma_{1}z + \\epsilon\\]\nTaking expectations, \\[E(y|z = 1) = \\gamma_{0} + E(\\gamma_{1}|z = 1) +   E[\\epsilon|z=1]\\] \\[E(y|z = 0) = \\gamma_{0}  + E[\\epsilon|z=0]\\]"
  },
  {
    "objectID": "slides/iv/index.html#late-in-regression-1",
    "href": "slides/iv/index.html#late-in-regression-1",
    "title": "E655 - Econometrics",
    "section": "LATE in Regression",
    "text": "LATE in Regression\n\nUnder the LATE assumptions, \\[E(y|z = 1) - E(y|z = 0) = E(\\gamma_{1})\\]\nFrom the reduced form for \\(w\\)\n\\[E(w|z = 1) = \\pi_{0} + E(\\pi_{1}|z = 1) +   E[r|z=1]\\] \\[E(w|z = 0) = \\pi_{0}  + E[r|z=0]\\]\nTaking the difference \\[E(w|z = 1) - E(w|z = 0) = E(\\pi_{1})\\]"
  },
  {
    "objectID": "slides/iv/index.html#late-in-regression-2",
    "href": "slides/iv/index.html#late-in-regression-2",
    "title": "E655 - Econometrics",
    "section": "LATE in Regression",
    "text": "LATE in Regression\n\nTaking the ratio \\[\\frac{E(y|z = 1) - E(y|z = 0)}{E(w|z = 1) - E(w|z = 0)} = \\frac{E(\\gamma_{1})}{E(\\pi_{1})}\\]\nRelating this back to late, note that \\(\\gamma = \\beta_{1}\\pi_{1}\\)\n\\[\\frac{E(\\gamma_{1})}{E(\\pi_{1})} =  \\frac{E(\\beta_{1}\\pi_{1})}{E(\\pi_{1})}\\]\nUsing the monotonicity assumption\n\\[\\frac{E(\\beta_{1}\\pi_{1})}{E(\\pi_{1})} =  \\frac{E(\\beta_{1}|\\pi_{1}&gt;0)P(\\pi_{1}&gt;0)}{E(\\pi_{1})} = E(\\beta_{1}|\\pi_{1}&gt;0)\\]\nBecause \\(P(\\pi_{1}&gt;0)=E(\\pi_{1})\\)"
  },
  {
    "objectID": "slides/iv/index.html#model-11",
    "href": "slides/iv/index.html#model-11",
    "title": "E655 - Econometrics",
    "section": "Model",
    "text": "Model\n\nAs noted, a linear combination of \\(\\mathbf{z}\\) is uncorrelated with \\(u\\), so\n\\[\\mathbf{E}(\\mathbf{x}^{*'}u) = 0\\]\nPremultiplying our structural equation by \\(\\mathbf{x}^{*'}\\) and taking expectations\n\\[\\mathbf{E}(\\mathbf{x}^{*'}y) = \\mathbf{E}(\\mathbf{x^{*'}x}) \\boldsymbol{\\beta}  + \\mathbf{E}(\\mathbf{x}^{*'}u)\\]\nUsing \\(\\mathbf{E}(\\mathbf{x}^{*'}u) = 0\\)\n\\[\\boldsymbol{\\beta}  = \\left(\\mathbf{E}(\\mathbf{x^{*'}x})\\right)^{-1}\\mathbf{E}(\\mathbf{x}^{*'}y)\\]\nThis is the population TSLS slope\n\nWe will cover estimation shortly"
  },
  {
    "objectID": "slides/iv/index.html#model-12",
    "href": "slides/iv/index.html#model-12",
    "title": "E655 - Econometrics",
    "section": "Model",
    "text": "Model\n\nYou can also write this estimator as\n\\[\\boldsymbol{\\beta}  = \\left(\\mathbf{E}(\\mathbf{x^{*'}x^{*}})\\right)^{-1}\\mathbf{E}(\\mathbf{x}^{*'}y)\\]\n\nThis is the slope from a regression of \\(y\\) on \\(\\mathbf{x^{*}}\\)\nIt is the slope from the second stage\n\nTo see how, recall that \\[\\mathbf{x}=   \\mathbf{z}\\boldsymbol{\\Pi} + r= \\mathbf{x}^{*} + r\\]\nPre-multiply by \\(\\mathbf{x}^{*'}\\) and take expectations \\[\\mathbf{E}(\\mathbf{x}^{*'} \\mathbf{x})= \\mathbf{E}(\\mathbf{x}^{*'} \\mathbf{x}^{*}) + \\mathbf{E}(\\mathbf{x}^{*'} r)\\]\nSince by definition \\(\\mathbf{E}(\\mathbf{x}^{*'} r) = 0\\) \\[\\mathbf{E}(\\mathbf{x}^{*'} \\mathbf{x})= \\mathbf{E}(\\mathbf{x}^{*'} \\mathbf{x}^{*})\\]"
  },
  {
    "objectID": "slides/iv/index.html#model-13",
    "href": "slides/iv/index.html#model-13",
    "title": "E655 - Econometrics",
    "section": "Model",
    "text": "Model\n\nFinally, note that the IV estimator is a special case of 2SLS\nAssume we have one endogenous variable and one excluded instrument\n\nThis means that \\(\\mathbf{x}\\) and \\(\\mathbf{z}\\) are both \\(K+1\\) matrices\nThe matrix \\(\\mathbf{\\Pi}\\) is \\(K+1 \\times K+1\\)\n\nSubstitute the definition of \\(\\mathbf{x}^{*'}\\) into the formula for \\(\\boldsymbol{\\beta}\\) \\[\\boldsymbol{\\beta}  = \\left(\\mathbf{E}(\\mathbf{(z\\Pi)'x})\\right)^{-1}\\mathbf{E}((\\mathbf{z\\Pi)'}y)\\]\nDistributing the transpose and pulling \\(\\mathbf{\\Pi}\\) out of the expectation \\[\\boldsymbol{\\beta}  = \\left(\\mathbf{\\Pi'}\\mathbf{E}\\mathbf{(z'x})\\right)^{-1}\\mathbf{\\Pi'}\\mathbf{E}(\\mathbf{z'}y) =  \\left(\\mathbf{E}\\mathbf{(z'x})\\right)^{-1}(\\mathbf{\\Pi'})^{-1}\\mathbf{\\Pi'}\\mathbf{E}(\\mathbf{z'}y)\\] \\[\\boldsymbol{\\beta}  =\\left(\\mathbf{E}(\\mathbf{z}'\\mathbf{x})\\right)^{-1} \\mathbf{E}(\\mathbf{z}'y)\\]"
  },
  {
    "objectID": "slides/iv/index.html#dag",
    "href": "slides/iv/index.html#dag",
    "title": "E655 - Econometrics",
    "section": "DAG",
    "text": "DAG\n\n\n\nInstrumental variables can be depicted in a DAG\nThere is an unobserved confounder \\(e\\)\n\nWe cannot control for it\n\nInstrumental variable \\(z\\) is correlated with \\(x\\) and uncorrelated with \\(e\\)\nIt only affects \\(y\\) through \\(x_k\\)"
  },
  {
    "objectID": "slides/iv/index.html#overview",
    "href": "slides/iv/index.html#overview",
    "title": "E655 - Econometrics",
    "section": "Overview",
    "text": "Overview\n\nIn some cases we have more than one instrument for an endogenous variable\nTwo-Stage Least Squares (TSLS) generalizes the IV model for this situation\n\nNote: In practice, both models are often called Instrumental Variables\n\nThe TSLS procedure is\n\nFirst Stage: regress endogenous variable on all exogenous variables\nSecond Stage: regress dependent variable on exogenous \\(\\mathbf{x}\\) variables and predicted value of endogenous variable from first stage\n\nThis process keeps only exogenous part of endogenous variable in the second stage\n\nPurges the endogenous variable of the endogenous component"
  },
  {
    "objectID": "slides/iv/index.html#structural-equation",
    "href": "slides/iv/index.html#structural-equation",
    "title": "E655 - Econometrics",
    "section": "Structural Equation",
    "text": "Structural Equation\n\nTo see this mathematically, the structural equation is\n\\[y =  \\mathbf{x_{1}}\\boldsymbol{\\beta_{1}}  + x_{k}\\beta_{k}  + e\\]\n\n\\(x_{k}\\) is endogenous, and \\(\\mathbf{x_{1}}\\) are exogenous\n\nThe vector \\(\\mathbf{z}\\) is now\n\\[\\mathbf{z} = [1,x_{1}, x_{2}, ...,x_{k-1},z_{1}, z_{2},...,z_{m}]\\]\n\nContains \\(K\\) exogenous \\(\\mathbf{x}\\) variables and \\(M\\) instruments\nTotal dimension of this vector is \\(L=K+M\\)\n\nThere are at least as many instruments as endogenous variables\nIf \\(\\mathbf{z}\\) is exogenous, \\(\\mathbf{E}(\\mathbf{z}'e) = 0\\)"
  },
  {
    "objectID": "slides/iv/index.html#first-stage",
    "href": "slides/iv/index.html#first-stage",
    "title": "E655 - Econometrics",
    "section": "First Stage",
    "text": "First Stage\n\nIn the first stage regress endogenous variables on \\(\\mathbf{z}\\)\n\n\\[x_{k} =  \\mathbf{z}\\boldsymbol{\\pi}   + r\\]\n\n\\(\\boldsymbol{\\pi}\\) is the population least squares slope vector\n\n\\[\\boldsymbol{\\pi} = \\left ( \\mathbf{E}(\\mathbf{z'z}) \\right )^{-1} \\mathbf{E}(\\mathbf{z'x_{k}})\\]\n\nThe population regression function in this relationship is\n\n\\[\\mathbf{x}_{k}^{*} =  \\mathbf{z}\\boldsymbol{\\pi}\\]"
  },
  {
    "objectID": "slides/iv/index.html#first-stage-1",
    "href": "slides/iv/index.html#first-stage-1",
    "title": "E655 - Econometrics",
    "section": "First Stage",
    "text": "First Stage\n\nThe intuition behind the first stage is\n\nThe first stage regresses the endogenous variable on the instruments\nIt separates the endogenous variable into the exogenous part and the endogenous part\nThe predicted value is the exogenous part\nThe residual is the endogenous part\nWe only keep the exogenous part for the second stage\n\n\n\n\n\n\n\n\nNote\n\n\nIn the first stage regression, regress the endogenous variable \\(x_{k}\\) on all the exogenous variables \\(x_{1}\\) and \\(z_{1} \\ldots z_{m}\\)."
  },
  {
    "objectID": "slides/iv/index.html#second-stage",
    "href": "slides/iv/index.html#second-stage",
    "title": "E655 - Econometrics",
    "section": "Second Stage",
    "text": "Second Stage\n\nIn the second stage, replace \\(x_{k}\\) with \\(\\mathbf{x}_{k}^{*}\\)\nSo the vector \\(\\mathbf{x}^{*}\\) is\n\\[\\mathbf{x}^{*} = [1,x_{1}, x_{2}, ...,x_{k-1},x_{k}^{*}]\\]\nIf \\(\\mathbf{z}\\) is exogenous, then so is a linear combination of the \\(\\mathbf{z}\\)\n\n\\(x_{k}^{*}\\) is a linear combination of \\(\\mathbf{z}\\)\n\nSo we know that \\(\\mathbf{E}(\\mathbf{x}^{*'}e) = 0\\)\nPremultiply structural equation by \\(\\mathbf{x}^{*'}\\) and take expectations\n\\[\\mathbf{E}(\\mathbf{x}^{*'}y) = \\mathbf{E}(\\mathbf{x^{*'}x}) \\boldsymbol{\\beta}  + \\mathbf{E}(\\mathbf{x}^{*'}e)\\]"
  },
  {
    "objectID": "slides/iv/index.html#second-stage-1",
    "href": "slides/iv/index.html#second-stage-1",
    "title": "E655 - Econometrics",
    "section": "Second Stage",
    "text": "Second Stage\n\nUse \\(\\mathbf{E}(\\mathbf{x}^{*'}e) = 0\\) and solve for \\(\\boldsymbol{\\beta}\\)\n\n\\[\\boldsymbol{\\beta}  = \\left(\\mathbf{E}(\\mathbf{x^{*'}x})\\right)^{-1}\\mathbf{E}(\\mathbf{x}^{*'}y)\\]\n\nIt is equivalent to write this as\n\n\\[\\boldsymbol{\\beta}  = \\left(\\mathbf{E}(\\mathbf{x^{*'}x^{*}})\\right)^{-1}\\mathbf{E}(\\mathbf{x}^{*'}y)\\]\n\nIt is the population regression slope of \\(y\\) on \\(\\mathbf{x}^{*}\\)"
  },
  {
    "objectID": "slides/iv/index.html#second-stage-2",
    "href": "slides/iv/index.html#second-stage-2",
    "title": "E655 - Econometrics",
    "section": "Second Stage",
    "text": "Second Stage\n\n\n\n\n\n\nImportant\n\n\nThe TSLS regression slope vector is\n\\[\\boldsymbol{\\beta}  = \\left(\\mathbf{E}(\\mathbf{x^{*'}x^{*}})\\right)^{-1}\\mathbf{E}(\\mathbf{x}^{*'}y)\\]\n\n\n\n\nNote that the IV estimator is equivalent to TSLS when there is one instrument for one endogenous variable\nAs before, these are population moments that we cannot compute directly\nWe need to estimate them"
  },
  {
    "objectID": "slides/iv/index.html#estimation-by-method-of-moments-4",
    "href": "slides/iv/index.html#estimation-by-method-of-moments-4",
    "title": "E655 - Econometrics",
    "section": "Estimation by Method of Moments",
    "text": "Estimation by Method of Moments\n\nsecond stage continued...\n\nThe sample version is\n\\[\\boldsymbol{\\hat{\\beta}}  = \\left(\\mathbf{\\hat{X}'\\hat{X}}\\right)^{-1}\\mathbf{\\hat{X}'y}\\]\n\nThe TSLS estimator is simply an OLS estimator in two stages"
  },
  {
    "objectID": "content/iv.html",
    "href": "content/iv.html",
    "title": "Instrumental Variables",
    "section": "",
    "text": "AP1 Chapter 4\nAP2 Chapter 3\nC Chapter 7\nCT Chapter 4\nHA Chapter 12\nHK Chapter 19\nK Chapter 9\nSW Chapter 12\nW1 Chapter 5\nW2 Chapters 15"
  },
  {
    "objectID": "content/iv.html#readings",
    "href": "content/iv.html#readings",
    "title": "Instrumental Variables",
    "section": "",
    "text": "AP1 Chapter 4\nAP2 Chapter 3\nC Chapter 7\nCT Chapter 4\nHA Chapter 12\nHK Chapter 19\nK Chapter 9\nSW Chapter 12\nW1 Chapter 5\nW2 Chapters 15"
  },
  {
    "objectID": "content/iv.html#slides",
    "href": "content/iv.html#slides",
    "title": "Instrumental Variables",
    "section": "Slides",
    "text": "Slides\nThe slides are embedded in this page, and you can scroll through them with the arrow keys. If you prefer you can instead pop them out in a new window"
  },
  {
    "objectID": "assignments/assign2.html",
    "href": "assignments/assign2.html",
    "title": "Assignment 2",
    "section": "",
    "text": "Answer Key\n\n\n\nYou can download the solutions using the links below\n a2solutions.qmd\n a2solutions.pdf"
  },
  {
    "objectID": "assignments/assign2.html#description",
    "href": "assignments/assign2.html#description",
    "title": "Assignment 2",
    "section": "Description",
    "text": "Description\nIn this assignment you are asked to manipulate data, estimate statistical relationships, and interpret the findings. The questions are based on course content we have covered up to now, so if you get stuck I highly recommend going back over that material because the questions are closely related. This includes both the lecture notes and the extra material posted to the course website.\nYou should start this assignment early because it will not be possible (in my opinion) to do well if you start close to the due date. There are parts that you may find difficult; you will want to identify them and leave enough time to ask questions if necessary."
  },
  {
    "objectID": "assignments/assign2.html#instructions",
    "href": "assignments/assign2.html#instructions",
    "title": "Assignment 2",
    "section": "Instructions",
    "text": "Instructions\n\nTemplate\nThe template below contains the assignment questions. Please answer then all within the template in the appropriate place. Replace everything in all caps with your information, and add code where asked.\nWhen you save the file to your computer, please rename it with your family name and student number, with no spaces.\n a2template.qmd\n\n\nData analysis\nPart of the assignment involves data analysis in R, which you will include as code chunks in the Quarto document. Please make sure all of your analysis is contained in your Quarto document and that it runs properly. Make note of the packages used in the file and ensure you have them installed in RStudio. Also make sure you have a Tex distribution installed on your machine.\n\n\nSubmission\nWhen you are finished, you are required to submit two documents according to the following instructions:\n\nYour .qmd file containing the completed template file. Submit this in MyLearningSpace only.\nA rendered PDF of your .qmd file. Submit this in both MyLearningSpace and Gradescope.\n\nThe template is structured to output both the code and the results of the code. Please ensure that this is the case in your rendered PDF because I will grade only that document. I will go to the .qmd file only in cases when something in your PDF does not make sense.\n\n\nPlagiarism\nThis is an independent assignment, which I expect you to complete on your own. It is plagiarism to copy someone else’s work verbatim, which includes R code. Any work you submit should be yours only. However, you are encouraged to talk to each other to try to figure out how to do the assignment."
  },
  {
    "objectID": "slides/iv/index.html",
    "href": "slides/iv/index.html",
    "title": "\nInstrumental Variables\n",
    "section": "",
    "text": "Instrumental Variables\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\nLoading required package: kableExtra\n\n\nAttaching package: 'kableExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\n\n\nAttaching package: 'ggdag'\n\n\nThe following object is masked from 'package:stats':\n\n    filter"
  },
  {
    "objectID": "content/iv.html#sample-r-code",
    "href": "content/iv.html#sample-r-code",
    "title": "Instrumental Variables",
    "section": "Sample R Code",
    "text": "Sample R Code\nThe code below goes through an exercise estimating TSLS when the instrument is exogenous. It shows how to perform the estimation in R, and why it is interpreted as a Local Average Treatment Effect (LATE)\n EC655instrumental.R"
  },
  {
    "objectID": "slides/rd/index.html#introduction-1",
    "href": "slides/rd/index.html#introduction-1",
    "title": "E655 - Econometrics",
    "section": "Introduction",
    "text": "Introduction\n\nRD is a popular method to identify causal treatment effects\nThe method mimics a randomized experiment\n\nPeople are assigned to treatment or not based on some known continuous variable\n\nThose above some “cutoff” are given the treatment\n\nAround the cutoff people share similar characteristics, except for the treatment\nThus, looking at outcome differences for those just above cutoff compared to just below will reveal causal effect of treatment\n\nIt identifies a local LATE\n\nIt is LATE in the sense we defined in instrumental variables\nAlso, it focuses on people in the immediate vicinity of the discontinuity"
  },
  {
    "objectID": "slides/rd/index.html#example",
    "href": "slides/rd/index.html#example",
    "title": "E655 - Econometrics",
    "section": "Example",
    "text": "Example\n\nExample: Milligan and Lemieux (2008)\n\nEffect of social assistance on employment\n\nExtra dollars of social assistance is the treatment\n\nAmount of social assistance determined by age\n\nBefore 1989, 30+ year olds got roughly $550 in monthly benefits\nThose under 30 got roughly $200\nTreatment is getting more social assistance\n\nPeople around age 30 are roughly similar on average\nCompares employment rates for 30 year olds to those just under 30\n\nAt the cutoff, the only difference between 2 groups is benefit level\n\nReveals causal effect of getting more benefits on employment\nResults show more benefits means lower employment rates"
  },
  {
    "objectID": "slides/rd/index.html#sharp-regression-discontinuity",
    "href": "slides/rd/index.html#sharp-regression-discontinuity",
    "title": "E655 - Econometrics",
    "section": "Sharp Regression Discontinuity",
    "text": "Sharp Regression Discontinuity\n\nRecall the potential outcomes model\n\\[y = y_{0} + (y_{1}  - y_{0})w\\]\nSuppose we also know the following information about the treatment \\[w = 1[S\\ge \\bar{S}]\\]\n\nAll those with \\(S\\ge \\bar{S}\\) get the treatment\n\\(S\\) is called the “running variable” or “forcing variable”\ne.g. if \\(S\\) is age, those 30+ get extra benefits"
  },
  {
    "objectID": "slides/rd/index.html#sharp-regression-discontinuity-1",
    "href": "slides/rd/index.html#sharp-regression-discontinuity-1",
    "title": "E655 - Econometrics",
    "section": "Sharp Regression Discontinuity",
    "text": "Sharp Regression Discontinuity\n\nBased on our assumptions, the key result is \\[E[y|S = \\bar{S}] - lim_{S\\uparrow \\bar{S}} E[y|S]\\] \\[=E[y_{1} -y_{0} |S = \\bar{S}]  = \\rho\\]\nThus, RD estimates the average treatment effect at the cutoff point\n\nThis is a form of local average treatment effect\n\nYou can also make the relationship between \\(y_{0}\\) and \\(S\\) nonlinear \\[y_{0} = f(S) + \\eta\\]\nAll of the previous conclusions still follow"
  },
  {
    "objectID": "slides/rd/index.html#sharp-regression-discontinuity-2",
    "href": "slides/rd/index.html#sharp-regression-discontinuity-2",
    "title": "E655 - Econometrics",
    "section": "Sharp Regression Discontinuity",
    "text": "Sharp Regression Discontinuity\n\nHere is how RD works intuitively\n\nIndividuals are assigned to treatment based on some variable \\(S\\)\nTreatment is a deterministic function of \\(S\\)\nAround the cutoff point \\(\\bar{S}\\), there are no unobserved differences between the groups\nWe simply compare outcomes at the discontinuity, and that is our treatment effect"
  },
  {
    "objectID": "slides/rd/index.html#sharp-regression-discontinuity-3",
    "href": "slides/rd/index.html#sharp-regression-discontinuity-3",
    "title": "E655 - Econometrics",
    "section": "Sharp Regression Discontinuity",
    "text": "Sharp Regression Discontinuity\n\nHere is how RD works intuitively\n\nIndividuals are assigned to treatment based on some variable \\(S\\)\nTreatment is a deterministic function of \\(S\\)\nAround the cutoff point \\(\\bar{S}\\), there are no unobserved differences between the groups\nWe simply compare outcomes at the discontinuity, and that is our treatment effect"
  },
  {
    "objectID": "slides/rd/index.html#sharp-regression-discontinuity-4",
    "href": "slides/rd/index.html#sharp-regression-discontinuity-4",
    "title": "E655 - Econometrics",
    "section": "Sharp Regression Discontinuity",
    "text": "Sharp Regression Discontinuity\n\nProblem: we cannot compute or estimate \\(E[y|S, w = 1] - E[y|S, w = 0]\\)\n\nBecause \\(w=1\\) only for those with \\(S\\ge \\bar{S}\\)\nAnd \\(w=0\\) only for those with \\(S&lt; \\bar{S}\\)\n\nThere is no “overlap” in these functions"
  },
  {
    "objectID": "slides/rd/index.html#sharp-regression-discontinuity-5",
    "href": "slides/rd/index.html#sharp-regression-discontinuity-5",
    "title": "E655 - Econometrics",
    "section": "Sharp Regression Discontinuity",
    "text": "Sharp Regression Discontinuity\n\nRegression discontinuity focuses in on the area near the cutoff \\[E[y|S = \\bar{S}] - lim_{S\\uparrow \\bar{S}} E[y|S]\\] \\[=  E[y_{1} - y_{0}|S = \\bar{S}] +E[y_{0}|S = \\bar{S}]- lim_{S\\uparrow \\bar{S}}E[y_{0}|S]\\] \\[=\\rho  +E[y_{0}|S = \\bar{S}]- lim_{S\\uparrow \\bar{S}}E[y_{0}|S]\\] \\[=\\rho\\]\nThe key assumption is the that \\(E[y_{0}|S = \\bar{S}]\\) is continuous at \\(S=\\bar{S}\\)\n\\[E[y_{0}|S = \\bar{S}] = lim_{S\\uparrow \\bar{S}} E[y_{0}|S]\\]"
  },
  {
    "objectID": "slides/rd/index.html#sharp-regression-discontinuity-6",
    "href": "slides/rd/index.html#sharp-regression-discontinuity-6",
    "title": "E655 - Econometrics",
    "section": "Sharp Regression Discontinuity",
    "text": "Sharp Regression Discontinuity\n\nThe idea behind these assumptions is\n\nCompare average observed outcome just above cutoff to average outcome just below\nThey serve as good counterfactuals if potential outcomes not affected by treatment\ne.g. social assistance benefits and employment\n\nCompare mean employment rate for people just above and below age 30\nWorks if employment rates smooth across age 30 without treatment\nAlso if employment rates smooth across 30 with treatment\n\n\nThe way we have modelled \\(y_{0}\\) and \\(y_{1}\\) builds in this assumption\n\n\\(E[y_{0}|S] = \\beta_{0} + \\beta_{1} S\\) does not jump at \\(w\\)"
  },
  {
    "objectID": "slides/rd/index.html#sharp-regression-discontinuity-7",
    "href": "slides/rd/index.html#sharp-regression-discontinuity-7",
    "title": "E655 - Econometrics",
    "section": "Sharp Regression Discontinuity",
    "text": "Sharp Regression Discontinuity\n\nBased on our assumptions, the key result is \\[E[y|S = \\bar{S}] - lim_{S\\uparrow \\bar{S}} E[y|S]\\] \\[=E[y_{1} -y_{0} |S = \\bar{S}]  = \\rho\\]\nThus, RD estimates the average treatment effect at the cutoff point\n\nThis is a form of local average treatment effect\n\nYou can also make the relationship between \\(y_{0}\\) and \\(S\\) nonlinear \\[y_{0} = f(S) + \\eta\\]\nAll of the previous conclusions still follow"
  },
  {
    "objectID": "slides/rd/index.html#estimation-of-sharp-regression-discontinuity",
    "href": "slides/rd/index.html#estimation-of-sharp-regression-discontinuity",
    "title": "E655 - Econometrics",
    "section": "Estimation of Sharp Regression Discontinuity",
    "text": "Estimation of Sharp Regression Discontinuity\n\nTo do this, you must center the data first at \\(\\bar{S}\\) \\[y = \\beta_{0}  + \\rho w + \\beta_{1}  (S - \\bar{S}) + \\delta_{1} w(S - \\bar{S})+\\eta\\]\nIn RD models, you would typically include a polynomial in \\(S\\) \\[y = \\beta_{0}  + \\rho w + \\beta_{1} (S - \\bar{S}) + \\beta_{2}  (S - \\bar{S})^{2}+ \\beta_{3} (S - \\bar{S})^{2}\\] \\[+ \\delta_{1} w(S - \\bar{S})+ \\delta_{2} w(S - \\bar{S})^{2}+ \\delta_{3} w(S - \\bar{S})^{3}+\\nu\\]\nYou can get more complicated if needed\nAfter specifying the \\(f(S)\\) function, you estimate as usual by OLS"
  },
  {
    "objectID": "slides/rd/index.html#estimation-of-sharp-regression-discontinuity-1",
    "href": "slides/rd/index.html#estimation-of-sharp-regression-discontinuity-1",
    "title": "E655 - Econometrics",
    "section": "Estimation of Sharp Regression Discontinuity",
    "text": "Estimation of Sharp Regression Discontinuity\n\nTo estimate by OLS, you need to specify the function \\(f(S)\\)\nTypically researchers use spline functions for this\nA linear spline with the same slope on each side is the standard linear regression \\[y = \\beta_{0} +  \\beta_{1} S+\\rho w + \\eta\\]\nThis estimates 2 lines with the same slope and an intercept shift at \\(S = \\bar{S}\\)\nIf we want to allow the slopes to differ on each side of the cutoff, \\[y = \\beta_{0}+ \\rho w + \\beta_{1} S + \\delta_{1} wS+\\eta\\]\nThis estimates 2 lines with the different slopes and an intercept shift at \\(S = \\bar{S}\\)\nIssue: \\(\\rho\\) measures the intercept shift when \\(S = 0\\)\n\nWe want to measure it at \\(S=\\bar{S}\\)"
  },
  {
    "objectID": "slides/rd/index.html#estimation-of-sharp-regression-discontinuity-2",
    "href": "slides/rd/index.html#estimation-of-sharp-regression-discontinuity-2",
    "title": "E655 - Econometrics",
    "section": "Estimation of Sharp Regression Discontinuity",
    "text": "Estimation of Sharp Regression Discontinuity\n\nTo do this, you must center the data first at \\(\\bar{S}\\) \\[y = \\beta_{0}  + \\rho w + \\beta_{1}  (S - \\bar{S}) + \\delta_{1} w(S - \\bar{S})+\\eta\\]\nIn RD models, you would typically include a polynomial in \\(S\\) \\[y = \\beta_{0}  + \\rho w + \\beta_{1} (S - \\bar{S}) + \\beta_{2}  (S - \\bar{S})^{2}+ \\beta_{3} (S - \\bar{S})^{2}\\] \\[+ \\delta_{1} w(S - \\bar{S})+ \\delta_{2} w(S - \\bar{S})^{2}+ \\delta_{3} w(S - \\bar{S})^{3}+\\nu\\]\nYou can get more complicated if needed\nAfter specifying the \\(f(S)\\) function, you estimate as usual by OLS"
  },
  {
    "objectID": "slides/rd/index.html#visualizing-regression-discontinuity",
    "href": "slides/rd/index.html#visualizing-regression-discontinuity",
    "title": "E655 - Econometrics",
    "section": "Visualizing Regression Discontinuity",
    "text": "Visualizing Regression Discontinuity"
  },
  {
    "objectID": "slides/rd/index.html#visualizing-regression-discontinuity-1",
    "href": "slides/rd/index.html#visualizing-regression-discontinuity-1",
    "title": "E655 - Econometrics",
    "section": "Visualizing Regression Discontinuity",
    "text": "Visualizing Regression Discontinuity"
  },
  {
    "objectID": "slides/rd/index.html#visualizing-regression-discontinuity-2",
    "href": "slides/rd/index.html#visualizing-regression-discontinuity-2",
    "title": "E655 - Econometrics",
    "section": "Visualizing Regression Discontinuity",
    "text": "Visualizing Regression Discontinuity"
  },
  {
    "objectID": "slides/rd/index.html#fuzzy-regression-discontinuity",
    "href": "slides/rd/index.html#fuzzy-regression-discontinuity",
    "title": "E655 - Econometrics",
    "section": "Fuzzy Regression Discontinuity",
    "text": "Fuzzy Regression Discontinuity\n\nSometimes treatment is not fully determined by \\(S\\)\nSuppose now we define \\[z = 1[S &gt; \\bar{S}]\\]\nand \\[w = g(S) + \\pi z + \\epsilon\\]\nWhat this says is that actual treatment is related to \\(S\\), but it is not a deterministic function of it\nUsing the potential outcomes framework here just as we did before\n\\[w_{0} = g(S) + \\epsilon\\] \\[w_{1} = w_{0} + \\pi\\]"
  },
  {
    "objectID": "slides/rd/index.html#fuzzy-regression-discontinuity-1",
    "href": "slides/rd/index.html#fuzzy-regression-discontinuity-1",
    "title": "E655 - Econometrics",
    "section": "Fuzzy Regression Discontinuity",
    "text": "Fuzzy Regression Discontinuity\n\nIf we make a monotonicity assumption (as we did in the LATE notes) \\[=  E[(y_{1} - y_{0})(w_{1}-w_{0})|S = \\bar{S}] = E[y_{1} - y_{0}|w_{1}-w_{0}=1,S = \\bar{S}]  E[w_{1} - w_{0}|S = \\bar{S}]\\]\nFinally, note that\n\\[E[w_{1} - w_{0}|S = \\bar{S}] = E[w|S = \\bar{S}] - lim_{S\\uparrow \\bar{S}} E[w|S]\\]\nWhich brings us to\n\\[\\frac{E[y|S = \\bar{S}] - lim_{S\\uparrow \\bar{S}} E[y|S] }{E[w|S = \\bar{S}] - lim_{S\\uparrow \\bar{S}} E[w|S] } = E[y_{1} - y_{0}|w_{1}-w_{0}=1,S = \\bar{S}]\\]\nThis says that at the cutoff point\n\nIf we compute differences in outcomes divided by difference in treatment\nThis equals the LATE at the cutoff point"
  },
  {
    "objectID": "slides/rd/index.html#fuzzy-regression-discontinuity-2",
    "href": "slides/rd/index.html#fuzzy-regression-discontinuity-2",
    "title": "E655 - Econometrics",
    "section": "Fuzzy Regression Discontinuity",
    "text": "Fuzzy Regression Discontinuity\n\nLinking back to regression,\n\\[\\frac{E[y|S = \\bar{S}] - lim_{S\\uparrow \\bar{S}} E[y|S] }{E[w|S = \\bar{S}] - lim_{S\\uparrow \\bar{S}} E[w|S] } = \\frac{\\rho\\pi}{\\pi} = \\rho\\]\nThis is the fuzzy regression discontinuity design\n\nDifference in outcomes across the cutoffs\nScaled by the difference in average treatment\n\nKey to note that this is a local LATE\n\nLATE for compliers\nAlso specific to those who have \\(S=\\bar{S}\\)"
  },
  {
    "objectID": "slides/rd/index.html#fuzzy-regression-discontinuity-3",
    "href": "slides/rd/index.html#fuzzy-regression-discontinuity-3",
    "title": "E655 - Econometrics",
    "section": "Fuzzy Regression Discontinuity",
    "text": "Fuzzy Regression Discontinuity\n\nLinking back to regression,\n\\[\\frac{E[y|S = \\bar{S}] - lim_{S\\uparrow \\bar{S}} E[y|S] }{E[w|S = \\bar{S}] - lim_{S\\uparrow \\bar{S}} E[w|S] } = \\frac{\\rho\\pi}{\\pi} = \\rho\\]\nThis is the fuzzy regression discontinuity design\n\nDifference in outcomes across the cutoffs\nScaled by the difference in average treatment\n\nKey to note that this is a local LATE\n\nLATE for compliers\nAlso specific to those who have \\(S=\\bar{S}\\)"
  },
  {
    "objectID": "slides/rd/index.html#visualizing-fuzzy-rd",
    "href": "slides/rd/index.html#visualizing-fuzzy-rd",
    "title": "E655 - Econometrics",
    "section": "Visualizing Fuzzy RD",
    "text": "Visualizing Fuzzy RD"
  },
  {
    "objectID": "slides/rd/index.html#estimation-of-fuzzy-regression-discontinuity",
    "href": "slides/rd/index.html#estimation-of-fuzzy-regression-discontinuity",
    "title": "E655 - Econometrics",
    "section": "Estimation of Fuzzy Regression Discontinuity",
    "text": "Estimation of Fuzzy Regression Discontinuity\n\nIn estimation, a spline function is used in both stages \\[y = \\beta_{0} + \\rho w + \\beta_{1} (S - \\bar{S}) + \\beta_{2} (S - \\bar{S})^{2}+ \\beta_{3} (S - \\bar{S})^{2}\\] \\[+ \\delta_{1} z(S - \\bar{S})+ \\delta_{2} z(S - \\bar{S})^{2}+ \\delta_{3} z(S - \\bar{S})^{3}+\\eta\\] \\[w = \\alpha_{0} + \\pi z + \\alpha_{1} (S - \\bar{S}) + \\alpha{2} (S - \\bar{S})^{2}+ \\alpha_{3} (S - \\bar{S})^{2}\\] \\[+ \\theta_{1} z(S - \\bar{S})+ \\theta_{2} z(S - \\bar{S})^{2}+ \\theta_{3} z(S - \\bar{S})^{3}+\\epsilon\\]\nNotice how both spline functions interact with \\(z\\)\nThis breaks each function up to the left and right of the discontinuity\nAs long as we specify the spline functions to be the same in both equations this is an IV model, with \\(z\\) as an instrument for \\(w\\)\n\nIf they are different, this is not an IV model, but is still acceptable"
  },
  {
    "objectID": "slides/rd/index.html#estimation-of-fuzzy-regression-discontinuity-1",
    "href": "slides/rd/index.html#estimation-of-fuzzy-regression-discontinuity-1",
    "title": "E655 - Econometrics",
    "section": "Estimation of Fuzzy Regression Discontinuity",
    "text": "Estimation of Fuzzy Regression Discontinuity\n\nIn estimation, a spline function is used in both stages \\[y = \\beta_{0} + \\rho w + \\beta_{1} (S - \\bar{S}) + \\beta_{2} (S - \\bar{S})^{2}+ \\beta_{3} (S - \\bar{S})^{2}\\] \\[+ \\delta_{1} z(S - \\bar{S})+ \\delta_{2} z(S - \\bar{S})^{2}+ \\delta_{3} z(S - \\bar{S})^{3}+\\eta\\] \\[w = \\alpha_{0} + \\pi z + \\alpha_{1} (S - \\bar{S}) + \\alpha{2} (S - \\bar{S})^{2}+ \\alpha_{3} (S - \\bar{S})^{2}\\] \\[+ \\theta_{1} z(S - \\bar{S})+ \\theta_{2} z(S - \\bar{S})^{2}+ \\theta_{3} z(S - \\bar{S})^{3}+\\epsilon\\]\nNotice how both spline functions interact with \\(z\\)\nThis breaks each function up to the left and right of the discontinuity\nAs long as we specify the spline functions to be the same in both equations this is an IV model, with \\(z\\) as an instrument for \\(w\\)\n\nIf they are different, this is not an IV model, but is still acceptable"
  },
  {
    "objectID": "slides/rd/index.html#internal-validity-of-rd",
    "href": "slides/rd/index.html#internal-validity-of-rd",
    "title": "E655 - Econometrics",
    "section": "Internal Validity of RD",
    "text": "Internal Validity of RD\n\nThe treatment variable does not have to be binary\n\nSee van der Klaauw (2001), Matsudaira (2008)\n\nThe method only works if the running variable \\(S\\) cannot be manipulated\n\nEx: Matsudaira (2008)\n\nEffect of summer school on future performance with 50% grade cutoff\nKids may know the assignment rule to summer school\nSome more “motivated” kids put in effort to not attend\nTheir non-treated outcomes differ on each side of the cutoff\ni.e. \\(E[y_{0}|S = \\bar{S}] = lim_{S\\uparrow \\bar{S}} E[y_{0}|S]\\)\n\n\nIf running variable is manipulated in a non-random way, RD is invalid and biased"
  },
  {
    "objectID": "slides/rd/index.html#internal-validity-of-rd-1",
    "href": "slides/rd/index.html#internal-validity-of-rd-1",
    "title": "E655 - Econometrics",
    "section": "Internal Validity of RD",
    "text": "Internal Validity of RD\n\nTwo ways to check if the running variable has been manipulated\n\nCheck for discontinuities in baseline variables\n\nTreatment is expected to be discontinuous; this is where our variation comes from\nHowever, near the discontinuity, any other variable must be continuous\nIf we had covariates (\\(X\\)) determined before treatment, we could check to see if they have discontinuities \\[x=\\gamma_{0} + \\gamma_{1}S +  \\delta z + u\\]\nIf \\(\\delta \\neq 0\\), then this may signal a problem\n\nCheck for discontinuities in the density of the running variable\n\nA histogram may show “piling up” of people on one side of discontinuity\nIf so, this may signal a problem\nSee McCrary(2008) for more technical details"
  },
  {
    "objectID": "slides/rd/index.html#sharp-regression-discontinuity-8",
    "href": "slides/rd/index.html#sharp-regression-discontinuity-8",
    "title": "E655 - Econometrics",
    "section": "Sharp Regression Discontinuity",
    "text": "Sharp Regression Discontinuity\n\nHere is how RD works intuitively\n\nIndividuals are assigned to treatment based on some variable \\(S\\)\nTreatment is a deterministic function of \\(S\\)\nAround the cutoff point \\(\\bar{S}\\), there are no unobserved differences between the groups\nWe simply compare outcomes at the discontinuity, and that is our treatment effect"
  },
  {
    "objectID": "slides/rd/index.html#treatment-assignment",
    "href": "slides/rd/index.html#treatment-assignment",
    "title": "E655 - Econometrics",
    "section": "Treatment Assignment",
    "text": "Treatment Assignment\n\nIn RD, treatment is assigned based on the value of \\(S\\) relative to a cutoff \\(\\bar{S}\\)\nIn graph above suppose \\(\\bar{S} = 5\\)\n\nThose with \\(S\\ge \\bar{S}\\) get the treatment\nThose with \\(S&lt; \\bar{S}\\) do not get the treatment\n\nIf the treatment variable is \\(w\\) then\n\n\\[w = 1[S\\ge \\bar{S}]\\]\n\nIn the example paper, \\(w\\) is a dummy for getting extra benefits\n\n\\(\\bar{S} = 30\\) years old and \\(w=1\\) happens when \\(S\\ge 30\\)"
  },
  {
    "objectID": "slides/rd/index.html#bias-in-regression",
    "href": "slides/rd/index.html#bias-in-regression",
    "title": "E655 - Econometrics",
    "section": "Bias in Regression",
    "text": "Bias in Regression\n\nConsider the population least squares regression of \\(y\\) on \\(w\\)\n\n\\[y = \\beta_{0} + \\beta_{1}w + u \\]\n\nThe slope in this regression is\n\n\\[E[y|w=1] - E[y|w=0]\\] \\[=  E[y_{1} - y_{0}|w=1] + E[y_{0}|w=1]- E[y_{0}|w=0]\\]\n\nSelection bias does not disappear because \\(y_{0}\\) is not independent of treatment\n\nThe mean of \\(y_{0}\\) above the cutoff is not the same as below the cutoff\nExample: untreated employment outcomes are different for older and younger people"
  },
  {
    "objectID": "slides/rd/index.html#conditional-mean-independence",
    "href": "slides/rd/index.html#conditional-mean-independence",
    "title": "E655 - Econometrics",
    "section": "Conditional Mean Independence",
    "text": "Conditional Mean Independence\n\nWhat if we instead condition on \\(S\\)?\n\\[E[y|S,w=1] - E[y|S,w=0]\\] \\[=  E[y_{1} - y_{0}|S,w=1] + E[y_{0}|S,w=1]- E[y_{0}|S,w=0]\\]\nIn this case, selection bias will disappear because treatment is determined by \\(S\\)\n\nSo holding \\(S\\) fixed, mean \\(y_{0}\\) is independent of treatment\n\nIn our example, people of the same age have the same average untreated outcome\nBecause \\(E[y_{0}|S] = E[y_{0}|S, w]\\) we can write\n\n\\[E[y|S,w=1] - E[y|S,w=0] =  E[y_{1} - y_{0}|S,w=1] \\]\n\nThis is the ATT conditional on \\(S\\)"
  },
  {
    "objectID": "slides/rd/index.html#conditional-mean-independence-1",
    "href": "slides/rd/index.html#conditional-mean-independence-1",
    "title": "E655 - Econometrics",
    "section": "Conditional Mean Independence",
    "text": "Conditional Mean Independence\n\nProblem: we cannot compute \\(E[y|S, w = 1] - E[y|S, w = 0]\\)\n\nBecause \\(w=1\\) only for those with \\(S\\ge \\bar{S}\\)\nAnd \\(w=0\\) only for those with \\(S&lt; \\bar{S}\\)\n\nThere is no “overlap” in these functions\n\nNo spot in the graph with two solid lines at a value of \\(S\\)"
  },
  {
    "objectID": "slides/rd/index.html#conditional-mean-independence-2",
    "href": "slides/rd/index.html#conditional-mean-independence-2",
    "title": "E655 - Econometrics",
    "section": "Conditional Mean Independence",
    "text": "Conditional Mean Independence\n\nIn our example this means\n\nFor people of the same age, potential employment outcomes do not depend on treatment\n\nProblem: we cannot compute \\(E[y|S, w = 1] - E[y|S, w = 0]\\)\n\nBecause \\(w=1\\) only for those with \\(S\\ge \\bar{S}\\)\nAnd \\(w=0\\) only for those with \\(S&lt; \\bar{S}\\)\n\nThere is no “overlap” in these functions"
  },
  {
    "objectID": "slides/rd/index.html#conditional-mean-at-cutoff",
    "href": "slides/rd/index.html#conditional-mean-at-cutoff",
    "title": "E655 - Econometrics",
    "section": "Conditional Mean at Cutoff",
    "text": "Conditional Mean at Cutoff\n\nRD solves this problem by focusing on the treatment cutoff\n\n\\[E[y|S = \\bar{S}] - lim_{S\\uparrow \\bar{S}} E[y|S]\\] \\[=  E[y_{1} - y_{0}|S = \\bar{S}] +E[y_{0}|S = \\bar{S}]- lim_{S\\uparrow \\bar{S}}E[y_{0}|S]\\]\n\nThe key assumption is the that \\(E[y_{0}|S = \\bar{S}]\\) is continuous at \\(S=\\bar{S}\\)\n\n\\[E[y_{0}|S = \\bar{S}] = lim_{S\\uparrow \\bar{S}} E[y_{0}|S]\\]\n\nIf this is true, selection bias disappears and we get the ATT at the cutoff\n\n\\[E[y|S = \\bar{S}] - lim_{S\\uparrow \\bar{S}} E[y|S] =E[y_{1} -y_{0} |S = \\bar{S}]\\]"
  },
  {
    "objectID": "slides/rd/index.html#conditional-mean-at-cutoff-1",
    "href": "slides/rd/index.html#conditional-mean-at-cutoff-1",
    "title": "E655 - Econometrics",
    "section": "Conditional Mean at Cutoff",
    "text": "Conditional Mean at Cutoff\n\nThe idea behind these assumptions is\n\nCompare average observed outcome just above cutoff to average outcome just below\nThey serve as good counterfactuals if potential outcomes not affected by treatment\ne.g. social assistance benefits and employment\n\nCompare mean employment rate for people just above and below age 30\nWorks if employment rates smooth across age 30 without treatment"
  },
  {
    "objectID": "slides/rd/index.html#visualizing-regression-discontinuity-3",
    "href": "slides/rd/index.html#visualizing-regression-discontinuity-3",
    "title": "E655 - Econometrics",
    "section": "Visualizing Regression Discontinuity",
    "text": "Visualizing Regression Discontinuity"
  },
  {
    "objectID": "slides/rd/index.html#summary-of-model",
    "href": "slides/rd/index.html#summary-of-model",
    "title": "E655 - Econometrics",
    "section": "Summary of Model",
    "text": "Summary of Model\n\nThe key result is\n\n\\[E[y|S = \\bar{S}] - lim_{S\\uparrow \\bar{S}} E[y|S] =E[y_{1} -y_{0} |S = \\bar{S}]  \\]\n\nThis works as long as \\(E[y_{0}|S = \\bar{S}]\\) is continuous at \\(S=\\bar{S}\\)\nThus, RD estimates an average treatment effect at the cutoff point\nAs before, we do not know the conditional expectation, so we must estimate\nThere are various ways, but we will cover OLS regression"
  },
  {
    "objectID": "slides/rd/index.html#estimation",
    "href": "slides/rd/index.html#estimation",
    "title": "E655 - Econometrics",
    "section": "Estimation",
    "text": "Estimation\n\nTo estimate we need to approximate the function \\(E[y|S]\\)\nWe can use a population linear regression of \\(y\\) on \\(S\\), and estimate that by OLS\nImportant: we must allow for an intercept shift at the cutoff point \\(\\bar{S}\\)\n\nThis is the approximation of \\(E[y_{1} -y_{0} |S = \\bar{S}]\\)\n\nThe simplest linear model is\n\n\\[y = \\beta_{0} +  \\beta_{1} S+\\rho w + u\\]\n\nThis is a straight line that jumps at \\(\\bar{S}\\) by \\(\\rho\\)"
  },
  {
    "objectID": "slides/rd/index.html#population-regression-function",
    "href": "slides/rd/index.html#population-regression-function",
    "title": "E655 - Econometrics",
    "section": "Population Regression Function",
    "text": "Population Regression Function"
  },
  {
    "objectID": "slides/rd/index.html#linear-population-regression-function",
    "href": "slides/rd/index.html#linear-population-regression-function",
    "title": "E655 - Econometrics",
    "section": "Linear Population Regression Function",
    "text": "Linear Population Regression Function"
  },
  {
    "objectID": "slides/rd/index.html#ols",
    "href": "slides/rd/index.html#ols",
    "title": "E655 - Econometrics",
    "section": "OLS",
    "text": "OLS\n\nTo estimate the PRF, we can use OLS\nReplace the population parameters with sample estimates\n\n\\[y = \\hat{\\beta}_{0} +  \\hat{\\beta}_{1} S+\\hat{\\rho} w + \\hat{u}\\] - The estimate of \\(\\hat{\\rho}\\) is the predicted difference in \\(y\\) at the cutoff point\n\\[\\hat{\\rho} = (\\hat{\\beta}_{0} +  \\hat{\\beta}_{1} S+\\hat{\\rho}) -   (\\hat{\\beta}_{0} +  \\hat{\\beta}_{1} S)\\]"
  },
  {
    "objectID": "slides/rd/index.html#estimation-1",
    "href": "slides/rd/index.html#estimation-1",
    "title": "E655 - Econometrics",
    "section": "Estimation",
    "text": "Estimation\n\nTo estimate the PRF, we can use OLS\nReplace the population parameters with sample estimates\n\n\\[y = \\hat{\\beta}_{0} +  \\hat{\\beta}_{1} S+\\hat{\\rho} w + \\hat{u}\\]\n\nThe estimate of \\(\\rho\\) is the difference in predicted \\(y\\) at the cutoff point\n\n\\[\\hat{\\rho} = (\\hat{\\beta}_{0} +  \\hat{\\beta}_{1} S+\\hat{\\rho}) -   (\\hat{\\beta}_{0} +  \\hat{\\beta}_{1} S)\\]"
  },
  {
    "objectID": "slides/rd/index.html#estimation-2",
    "href": "slides/rd/index.html#estimation-2",
    "title": "E655 - Econometrics",
    "section": "Estimation",
    "text": "Estimation\n\nA more complicated PRF allows the slope to differ on either side of the cutoff point\n\n\\[y = \\beta_{0} +  \\beta_{1} S+\\rho w + \\beta_{2}(S \\times w) + u\\]\n\nThe interaction term allows the slope to differ on either side of the cutoff point\n\n\\[\\frac{\\partial y}{\\partial S} = \\beta_{1} + \\beta_{2} w\\]\n\nWhen \\(w = 1\\) the slope changes by \\(\\beta_{2}\\)"
  },
  {
    "objectID": "slides/rd/index.html#estimation-3",
    "href": "slides/rd/index.html#estimation-3",
    "title": "E655 - Econometrics",
    "section": "Estimation",
    "text": "Estimation"
  },
  {
    "objectID": "slides/rd/index.html#estimation-4",
    "href": "slides/rd/index.html#estimation-4",
    "title": "E655 - Econometrics",
    "section": "Estimation",
    "text": "Estimation\n\nProblem: as specified, \\(\\rho\\) does not measure the jump at the cutoff\nCall the prediction of \\(y\\) at values of \\(S\\) and \\(w\\) \\(P[y|S, w]\\)\n\n\\[P[y|S, w=1] - P[y|S, w=0] \\] \\[= (\\beta_{0} +  \\beta_{1} S+ \\rho + \\beta_{2}S) - (\\beta_{0} +  \\beta_{1} S) \\] \\[= \\rho +  \\beta_{2} S \\]\n\n\\(\\rho\\) is therefore the jump when \\(S = 0\\), not when \\(S=\\bar{S}\\)"
  },
  {
    "objectID": "slides/rd/index.html#estimation-5",
    "href": "slides/rd/index.html#estimation-5",
    "title": "E655 - Econometrics",
    "section": "Estimation",
    "text": "Estimation\n\nTo ensure \\(\\rho\\) is the jump at the cutoff, we must center \\(S\\) at the cutoff point\nDefine \\(S_{c} = S - \\bar{S}\\)\nReplace \\(S\\) with \\(S_{c}\\) in the PRF\n\n\\[y = \\beta_{0}^{*} +  \\beta_{1} S_{c}+\\rho^{*} w + \\beta_{2}(S_{c} \\times w) + u\\]\n\nDifference in the PRF is now\n\n\\[P[y|S_{c}, w=1] - P[y|S_{c}, w=0] \\] \\[= \\rho^{*} +  \\beta_{2} S_{c} \\]\n\nThis occurs at the cutoff: \\(S_{c} = S - \\bar{S}\\) when \\(S = \\bar{S}\\)"
  },
  {
    "objectID": "slides/rd/index.html#estimation-6",
    "href": "slides/rd/index.html#estimation-6",
    "title": "E655 - Econometrics",
    "section": "Estimation",
    "text": "Estimation"
  },
  {
    "objectID": "slides/rd/index.html#estimation-7",
    "href": "slides/rd/index.html#estimation-7",
    "title": "E655 - Econometrics",
    "section": "Estimation",
    "text": "Estimation\n\nTo estimate \\(\\rho^{*}\\) replace the population parameters with sample estimates\n\n\\[y = \\hat{\\beta}_{0}^{*} +  \\hat{\\beta}_{1} S_{c}+\\hat{\\rho}^{*} w + \\hat{\\beta}_{2}S_{c} \\times w + \\hat{u}\\]\n\nPrior to running OLS regression, ensure you create \\(S_{c} = S - \\bar{S}\\)\n\\(\\hat{\\rho}^{*}\\) is the regression discontinuity estimate of the treatement effect"
  },
  {
    "objectID": "slides/rd/index.html#model",
    "href": "slides/rd/index.html#model",
    "title": "E655 - Econometrics",
    "section": "Model",
    "text": "Model\n\nPerforming a bit of algebra, we get\n\n\\[=  E[(y_{1} - y_{0})(w_{1}-w_{0})|S = \\bar{S}] + (E[y_{0}|S = \\bar{S}] - lim_{S\\uparrow \\bar{S}} E[y_{0} |S] )\\]\n\nIf \\(E[y_{0}|S = \\bar{S}]\\) is continuous at the cutoff, we can drop the second term\n\n\\[=  E[(y_{1} - y_{0})(w_{1}-w_{0})|S = \\bar{S}] \\]"
  },
  {
    "objectID": "slides/rd/index.html#model-1",
    "href": "slides/rd/index.html#model-1",
    "title": "E655 - Econometrics",
    "section": "Model",
    "text": "Model\n\nIf we make a monotonicity assumption (as we did in the LATE notes)\n\n\\[ E[(y_{1} - y_{0})(w_{1}-w_{0})|S = \\bar{S}] = E[y_{1} - y_{0}|w_{1}-w_{0}=1,S = \\bar{S}]  E[w_{1} - w_{0}|S = \\bar{S}]\\]\n\nThe CEF for \\(w\\) is\n\n\\[E[w|S = \\bar{S}] - lim_{S\\uparrow \\bar{S}} E[w|S] = E[w_{1} - w_{0}|S = \\bar{S}] \\]\n\nWhich brings us to\n\n\\[\\frac{E[y|S = \\bar{S}] - lim_{S\\uparrow \\bar{S}} E[y|S] }{E[w|S = \\bar{S}] - lim_{S\\uparrow \\bar{S}} E[w|S] } = E[y_{1} - y_{0}|w_{1}-w_{0}=1,S = \\bar{S}]\\]"
  },
  {
    "objectID": "slides/rd/index.html#model-2",
    "href": "slides/rd/index.html#model-2",
    "title": "E655 - Econometrics",
    "section": "Model",
    "text": "Model\n\nIn the fuzzy RD we divide the mean difference in outcomes by the mean difference in treatment\n\nThis “scales” the difference in outcomes by the difference in treatment probability\n\nThe interpretation is a LATE\n\nThe treatment effect for compliers, at the cutoff\n\nJust like sharp RD, you can allow different slopes, nonlinearities"
  },
  {
    "objectID": "slides/rd/index.html#setup",
    "href": "slides/rd/index.html#setup",
    "title": "E655 - Econometrics",
    "section": "Setup",
    "text": "Setup\n\nRD is best understood visually\nSuppose we have potential outcomes \\(y_{0}\\) and \\(y_{1}\\)\n\n\\(y_{0}\\) is the outcome if not treated\n\\(y_{1}\\) is the outcome if treated\n\nBoth potential outcomes are continuous functions of some variable \\(S\\)\n\n\\(S\\) is called the “running variable” or “forcing variable”\n\nIn the example paper, \\(S\\) is age\n\n\\(y_{0}\\) is employment rate with normal benefits\n\\(y_{1}\\) is employment rate with extra benefits\n\nGraph below plots example CEFs as a function of \\(S\\)"
  },
  {
    "objectID": "slides/rd/index.html#cef-of-potential-outcomes",
    "href": "slides/rd/index.html#cef-of-potential-outcomes",
    "title": "E655 - Econometrics",
    "section": "CEF of Potential Outcomes",
    "text": "CEF of Potential Outcomes"
  },
  {
    "objectID": "slides/rd/index.html#observed-value-of-the-outcome",
    "href": "slides/rd/index.html#observed-value-of-the-outcome",
    "title": "E655 - Econometrics",
    "section": "Observed Value of the Outcome",
    "text": "Observed Value of the Outcome\n\nRecall that the observed outcome \\(y = y_{0} + (y_{1} - y_{0})w\\)\n\n\\(y = y_{0}\\) if \\(w=0\\), \\(y = y_{1}\\) if \\(w=1\\)\n\nSince \\(w = 1[S\\ge \\bar{S}]\\) we can write\n\n\\(y = y_{0}\\) if \\(S&lt; \\bar{S}\\), \\(y = y_{1}\\) if \\(S\\ge \\bar{S}\\)\n\nWe can then draw the CEF \\(E[y|S]\\) on the graph\n\nBlack line is the CEF of \\(E[y|S]\\)\nRed lines are the (unobserved) potential outcomes"
  },
  {
    "objectID": "slides/rd/index.html#observed-value-of-the-outcome-1",
    "href": "slides/rd/index.html#observed-value-of-the-outcome-1",
    "title": "E655 - Econometrics",
    "section": "Observed Value of the Outcome",
    "text": "Observed Value of the Outcome"
  },
  {
    "objectID": "slides/rd/index.html#observed-value-of-the-outcome-2",
    "href": "slides/rd/index.html#observed-value-of-the-outcome-2",
    "title": "E655 - Econometrics",
    "section": "Observed Value of the Outcome",
    "text": "Observed Value of the Outcome"
  },
  {
    "objectID": "slides/rd/index.html#conditional-mean-at-cutoff-2",
    "href": "slides/rd/index.html#conditional-mean-at-cutoff-2",
    "title": "E655 - Econometrics",
    "section": "Conditional Mean at Cutoff",
    "text": "Conditional Mean at Cutoff\n\nWe plotted CEFs of potential outcomes assuming they are linear with equal slopes\nThey do not have to be\nThe two graphs below present situations where\n\nPotential outcomes are linear with different slopes\nThey are nonlinear"
  },
  {
    "objectID": "slides/rd/index.html#linear-cef-with-unequal-slopes",
    "href": "slides/rd/index.html#linear-cef-with-unequal-slopes",
    "title": "E655 - Econometrics",
    "section": "Linear CEF with Unequal Slopes",
    "text": "Linear CEF with Unequal Slopes"
  },
  {
    "objectID": "slides/rd/index.html#nonlinear-cef",
    "href": "slides/rd/index.html#nonlinear-cef",
    "title": "E655 - Econometrics",
    "section": "Nonlinear CEF",
    "text": "Nonlinear CEF"
  },
  {
    "objectID": "slides/rd/index.html#setup-1",
    "href": "slides/rd/index.html#setup-1",
    "title": "E655 - Econometrics",
    "section": "Setup",
    "text": "Setup\n\nWe still have potential outcomes \\(y_{0}\\) and \\(y_{1}\\) that are functions of \\(S\\)\nGraph below plots their CEFs again as a function of \\(S\\)\nThe cutoff point is still \\(\\bar{S}\\)"
  },
  {
    "objectID": "slides/rd/index.html#cef-of-potential-outcomes-1",
    "href": "slides/rd/index.html#cef-of-potential-outcomes-1",
    "title": "E655 - Econometrics",
    "section": "CEF of Potential Outcomes",
    "text": "CEF of Potential Outcomes"
  },
  {
    "objectID": "slides/rd/index.html#treatment",
    "href": "slides/rd/index.html#treatment",
    "title": "E655 - Econometrics",
    "section": "Treatment",
    "text": "Treatment\n\nThe treatment is now only partially determined by \\(S\\)\n\nPeople are assigned to treatment if \\(S &gt; \\bar{S}\\)\nBut they may not take it, so actual treatment could differ\n\nSuppose that assignment to treatment is \\(z\\)\n\n\\[z = 1[S &gt; \\bar{S}]\\]\n\nActual treatment is determined by \\(w\\)\n\n\\[w = w_{0} + (w_{1} - w_{0})z\\]\n\nThe potential treatments are functions of \\(S\\)\nThe observed treatment is \\(w_{0}\\) if \\(S \\leq \\bar{S}\\) and \\(w_{1}\\) if \\(S &gt; \\bar{S}\\)"
  },
  {
    "objectID": "slides/rd/index.html#cef-of-treatment",
    "href": "slides/rd/index.html#cef-of-treatment",
    "title": "E655 - Econometrics",
    "section": "CEF of Treatment",
    "text": "CEF of Treatment"
  },
  {
    "objectID": "slides/rd/index.html#observed-outcomes",
    "href": "slides/rd/index.html#observed-outcomes",
    "title": "E655 - Econometrics",
    "section": "Observed Outcomes",
    "text": "Observed Outcomes\n\nLike before we can plot the CEF of the observed outcome\nUnlike before\n\n\\[E[y|S \\ge \\bar{S}] \\neq E[y_{1}|S \\ge \\bar{S}]\\] \\[E[y|S &lt; \\bar{S}] \\neq E[y_{0}|S &lt; \\bar{S}]\\]\n\nThis is because actual treatment can deviate from assigned treatment"
  },
  {
    "objectID": "slides/rd/index.html#observed-outcomes-1",
    "href": "slides/rd/index.html#observed-outcomes-1",
    "title": "E655 - Econometrics",
    "section": "Observed Outcomes",
    "text": "Observed Outcomes\n\nTo find the CEF of the observed outcome remember\n\n\\[y = y_{0} + (y_{1} - y_{0})w\\]\n\nRearrange\n\n\\[ y = y_{0}(1-w) + y_{1}w\\]\n\nTake expectations conditional on \\(S\\)\n\n\\[E[y|S] = E[y_{0}|S] (1-E[w|S]) + E[y_{1}|S]E[w|S]\\]"
  },
  {
    "objectID": "slides/rd/index.html#cef-of-observed-outcome",
    "href": "slides/rd/index.html#cef-of-observed-outcome",
    "title": "E655 - Econometrics",
    "section": "CEF of Observed Outcome",
    "text": "CEF of Observed Outcome"
  },
  {
    "objectID": "slides/rd/index.html#treatment-effect",
    "href": "slides/rd/index.html#treatment-effect",
    "title": "E655 - Econometrics",
    "section": "Treatment Effect",
    "text": "Treatment Effect\n\nComputing the treatment effect is more complicated\nIt operates like the TSLS model we saw before\n\n\\(z\\) is as an instrument for \\(w\\)\nTreatment effect is ratio of mean difference in \\(y\\) to mean difference in \\(w\\)\n\nThe treatment effect is a LATE, at the cutoff"
  },
  {
    "objectID": "slides/rd/index.html#treatment-effect-1",
    "href": "slides/rd/index.html#treatment-effect-1",
    "title": "E655 - Econometrics",
    "section": "Treatment Effect",
    "text": "Treatment Effect\n\nDifference in CEF on each side of the cutoff\n\n\\[E[y|S = \\bar{S}] - lim_{S\\uparrow \\bar{S}} E[y|S]\\]\n\nReplace \\(y\\) with \\(y = y_{0} + (y_{1} - y_{0})w\\)\n\n\\[=  E[y_{0} + (y_{1} - y_{0})w|S = \\bar{S}] - lim_{S\\uparrow \\bar{S}} E[y_{0} + (y_{1} - y_{0})w|S]\\]\n\nWhen \\(S \\ge \\bar{S}\\) then \\(w = w_{1}\\) and when \\(S &lt; \\bar{S}\\) then \\(w = w_{0}\\)\n\n\\[=  E[y_{0} + (y_{1} - y_{0})w_{1}|S = \\bar{S}] - lim_{S\\uparrow \\bar{S}} E[y_{0} + (y_{1} - y_{0})w_{0}|S]\\]"
  },
  {
    "objectID": "slides/rd/index.html#cef-of-observed-outcome-1",
    "href": "slides/rd/index.html#cef-of-observed-outcome-1",
    "title": "E655 - Econometrics",
    "section": "CEF of Observed Outcome",
    "text": "CEF of Observed Outcome"
  },
  {
    "objectID": "slides/rd/index.html#estimation-8",
    "href": "slides/rd/index.html#estimation-8",
    "title": "E655 - Econometrics",
    "section": "Estimation",
    "text": "Estimation\n\nEstimate using TSLS\n\nTreat \\(w\\) as endogenous, and \\(z\\) as an exogenous instrument\n\\(S\\) is the included instrument\n\nA linear structural model would be\n\n\\[y = \\beta_{0} +  \\beta_{1} S+\\rho w + e\\]\n\nWith first stage\n\n\\[w = \\alpha_{0}  + \\alpha_{1} S + \\pi z + u\\]"
  },
  {
    "objectID": "slides/rd/index.html#estimation-9",
    "href": "slides/rd/index.html#estimation-9",
    "title": "E655 - Econometrics",
    "section": "Estimation",
    "text": "Estimation\n\nEstimating by TSLS the vector of coefficients is\n\n\\[\\boldsymbol{\\hat{\\beta}}  = \\left( \\mathbf{\\mathbf{\\hat{X}}'\\mathbf{\\hat{X}}} \\right)^{-1}\\mathbf{\\mathbf{\\hat{X}}'y} =  \n\\begin{bmatrix}\n\\hat{\\beta}_{0}\\\\\n\\hat{\\beta}_{1}\\\\\n\\hat{\\rho}\n\\end{bmatrix}\\]\n\nThe \\(\\hat{X}\\) matrix contains the constant, \\(S\\), and \\(\\hat{w}\\)\nAs before you can add different slopes, nonlinearities\n\nEnsure you recenter the \\(S\\) variable around the cutoff"
  },
  {
    "objectID": "slides/rd/index.html#estimation-10",
    "href": "slides/rd/index.html#estimation-10",
    "title": "E655 - Econometrics",
    "section": "Estimation",
    "text": "Estimation"
  },
  {
    "objectID": "slides/rd/index.html#external-validity-of-rd",
    "href": "slides/rd/index.html#external-validity-of-rd",
    "title": "E655 - Econometrics",
    "section": "External Validity of RD",
    "text": "External Validity of RD\n\nExternal validity is the ability to extrapolate estimates\nRD estimates are local to the cutoff\nIf there are heteogeneous treatment effects, may not be able to apply to whole population\n\nEx: Estimates of benefits on employment for 30 year olds may not apply to 50 year olds\nEx: Estimates of summer school on test scores for kids around 50% may not apply to high achievers\n\nMust be careful not to overinterpret results"
  },
  {
    "objectID": "content/rd.html",
    "href": "content/rd.html",
    "title": "Regression Discontinuity",
    "section": "",
    "text": "AP1 Chapter 6\nAP2 Chapter 4\nC Chapter 6\nHA Chapter 12\nHK Chapter 20\nW1 Chapter 21.5"
  },
  {
    "objectID": "content/rd.html#readings",
    "href": "content/rd.html#readings",
    "title": "Regression Discontinuity",
    "section": "",
    "text": "AP1 Chapter 6\nAP2 Chapter 4\nC Chapter 6\nHA Chapter 12\nHK Chapter 20\nW1 Chapter 21.5"
  },
  {
    "objectID": "content/rd.html#slides",
    "href": "content/rd.html#slides",
    "title": "Regression Discontinuity",
    "section": "Slides",
    "text": "Slides\nThe slides are embedded in this page, and you can scroll through them with the arrow keys. If you prefer you can instead pop them out in a new window"
  },
  {
    "objectID": "content/rd.html#videos",
    "href": "content/rd.html#videos",
    "title": "Regression Discontinuity",
    "section": "Videos",
    "text": "Videos\nThis is a lecture from Prof. Christopher Walters given for the American Economics Association Continuing Education program (no preview available). View video"
  },
  {
    "objectID": "content/iv.html#videos",
    "href": "content/iv.html#videos",
    "title": "Instrumental Variables",
    "section": "Videos",
    "text": "Videos\nThis is a lecture from Prof. Joshua Angrist given for the American Economics Association Continuing Education program (no preview available). View video"
  },
  {
    "objectID": "slides/rd/index.html#milligan-and-lemieux-2008",
    "href": "slides/rd/index.html#milligan-and-lemieux-2008",
    "title": "E655 - Econometrics",
    "section": "Milligan and Lemieux (2008)",
    "text": "Milligan and Lemieux (2008)\n\n\n\n\n\nFirst Stage\n\n\n\n\n\n\nReduced Form"
  },
  {
    "objectID": "slides/rd/index.html",
    "href": "slides/rd/index.html",
    "title": "\nRegression Discontinuity\n",
    "section": "",
    "text": "Regression Discontinuity\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\nLoading required package: kableExtra\n\n\nAttaching package: 'kableExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\n\n\nAttaching package: 'ggdag'\n\n\nThe following object is masked from 'package:stats':\n\n    filter"
  },
  {
    "objectID": "slides/did/index.html#introduction-1",
    "href": "slides/did/index.html#introduction-1",
    "title": "E655 - Econometrics",
    "section": "Introduction",
    "text": "Introduction\n\nUses a natural experiment to separate data into treatment and control groups\n\nA policy or naturally occurring event that creates exogenous variation in a variable\n\nEx: Increasing the minimum wage in one state but not another\nEx: Mandated fitness policies in some schools but not others\n\n\nUsually data in the form of pooled cross-sections\n\nIndividuals in 2 (or more) time periods\nCould be same or different people in each time period\n\nCan also have data in 2 groups in same time period\n\nIndividuals in 2 different states, countries\nPeople in 2 different schools\n\nDiD is a specific way to compare treatment to control group"
  },
  {
    "objectID": "slides/did/index.html#basic-model",
    "href": "slides/did/index.html#basic-model",
    "title": "E655 - Econometrics",
    "section": "Basic Model",
    "text": "Basic Model\n\nCan also think about this in regression framework\nImagine potential outcomes are defined as \\[y_{0} = \\beta_{0} + \\beta_{1}dA + \\beta_{2}d2 + \\eta\\] \\[y_{1} = y_{0} + \\beta_{3}\\]\nThis model setup says that\n\nThe potential untreated outcome varies across groups and time\n\nThe difference in \\(y_{0}\\) is the same across time for groups A and B\nThe difference in \\(y_{0}\\) is the same across groups in each time period\n\nThe treatment effect \\(\\beta_{3}\\) is constant\n\nIf we plug these into the equation for \\(y\\) we get\n\\[y =\\beta_{0} + \\beta_{1}dA + \\beta_{2}d2 +  \\beta_{3}w +  \\eta\\]"
  },
  {
    "objectID": "slides/did/index.html#basic-model-1",
    "href": "slides/did/index.html#basic-model-1",
    "title": "E655 - Econometrics",
    "section": "Basic Model",
    "text": "Basic Model\n\nTake expected values for each group in period 2 \\[E[y|dA = 1, d2 = 1] = \\beta_{0} + \\beta_{1}   +\\beta_{2}+ \\beta_{3} + E[\\eta|dA = 1, d2 = 1]\\] \\[E[y|dA = 0, d2 = 1] = \\beta_{0}   +\\beta_{2}+ E[\\eta|dA = 0, d2 = 1]\\]\nThen expected values for each group in period 1\n\\[E[y|dA = 1, d2 = 0] = \\beta_{0} + \\beta_{1}    + E[\\eta|dA = 1, d2 = 0]\\] \\[E[y|dA = 0, d2 = 0] = \\beta_{0}  + E[\\eta|dA = 0, d2 = 0]\\]"
  },
  {
    "objectID": "slides/did/index.html#basic-model-2",
    "href": "slides/did/index.html#basic-model-2",
    "title": "E655 - Econometrics",
    "section": "Basic Model",
    "text": "Basic Model\n\nThen compute the difference in differences\n\\[(E[y|dA = 1, d2 = 1] - E[y|dA = 0, d2 = 1] )\\] \\[- (E[y|dA = 1, d2 = 0])-E[y|dA = 0, d2 = 0])\\] \\[= \\beta_{3}\\] \\[+  (E[\\eta|dA = 1, d2 = 1] - E[\\eta|dA = 1, d2 = 0])\\] \\[- (E[\\eta|dA = 0, d2 = 1] - E[\\eta|dA = 0, d2 = 0])\\]\nWhere \\(\\beta_{3}\\) is the treatment effect\nSelection bias is zero when regression error has constant bias/common trends"
  },
  {
    "objectID": "slides/did/index.html#basic-model-3",
    "href": "slides/did/index.html#basic-model-3",
    "title": "E655 - Econometrics",
    "section": "Basic Model",
    "text": "Basic Model\n\nDiD subtracts the difference in outcomes from period 1 to account for selection\n\n\\[E[y|dA = 1, d2 = 1] - E[y|dA = 0, d2 = 1]\\] \\[ -[E[y|dA = 1, d2 = 0] - E[y|dA = 0, d2 = 0]]\\] \\[ = E[y_1|dA = 1, d2 = 1] - E[y_0|dA = 1, d2 = 1] \\] \\[+ E[y_0|dA = 1, d2 = 1]- E[y_0|dA = 0, d2 = 1]\\] \\[ -[E[y_0|dA = 1, d2 = 0] - E[y_0|dA = 0, d2 = 0]]\\]\n\nSelection bias is zero if we assume constant bias or common trends"
  },
  {
    "objectID": "slides/did/index.html#basic-model-4",
    "href": "slides/did/index.html#basic-model-4",
    "title": "E655 - Econometrics",
    "section": "Basic Model",
    "text": "Basic Model\n\nSelection bias is zero if we make the constant bias assumption\nFrom above\n\n\\[+ E[y_0|dA = 1, d2 = 1]- E[y_0|dA = 0, d2 = 1]\\] \\[ -[E[y_0|dA = 1, d2 = 0] - E[y_0|dA = 0, d2 = 0]]\\]\n\nConstant bias means group difference in \\(y_0\\) is the same in both time periods\n\nBetween group differences in prior period are a good counterfactual for difference in treated time period"
  },
  {
    "objectID": "slides/did/index.html#basic-model-5",
    "href": "slides/did/index.html#basic-model-5",
    "title": "E655 - Econometrics",
    "section": "Basic Model",
    "text": "Basic Model\n\nAn equivalent assumption is common trends assumption\nRearrange the selection bias term to be\n\n\\[+ E[y_0|dA = 1, d2 = 1]- E[y_0|dA = 1, d2 = 0]\\] \\[ -[E[y_0|dA = 0, d2 = 1] - E[y_0|dA = 0, d2 = 0]]\\]\n\nSays trend in \\(y_0\\) for group A is the same as group B\n\nTrend in group B is a good counterfactual for trend in group A\n\nBoth assumptions are equivalent and assume no selection bias"
  },
  {
    "objectID": "slides/did/index.html#basic-model-6",
    "href": "slides/did/index.html#basic-model-6",
    "title": "E655 - Econometrics",
    "section": "Basic Model",
    "text": "Basic Model\n\nCan also think about this in regression framework\nImagine potential outcomes are defined as \\[y_{0} = \\beta_{0} + \\beta_{1}dA + \\beta_{2}d2 + \\eta\\] \\[y_{1} = y_{0} + \\beta_{3}\\]\nThis model setup says that\n\nThe potential untreated outcome varies across groups and time\n\nThe difference in \\(y_{0}\\) is the same across time for groups A and B\nThe difference in \\(y_{0}\\) is the same across groups in each time period\n\nThe treatment effect \\(\\beta_{3}\\) is constant\n\nIf we plug these into the equation for \\(y\\) we get\n\\[y =\\beta_{0} + \\beta_{1}dA + \\beta_{2}d2 +  \\beta_{3}w +  \\eta\\]"
  },
  {
    "objectID": "slides/did/index.html#basic-model-7",
    "href": "slides/did/index.html#basic-model-7",
    "title": "E655 - Econometrics",
    "section": "Basic Model",
    "text": "Basic Model\n\nTake expected values for each group in period 2 \\[E[y|dA = 1, d2 = 1] = \\beta_{0} + \\beta_{1}   +\\beta_{2}+ \\beta_{3} + E[\\eta|dA = 1, d2 = 1]\\] \\[E[y|dA = 0, d2 = 1] = \\beta_{0}   +\\beta_{2}+ E[\\eta|dA = 0, d2 = 1]\\]\nThen expected values for each group in period 1\n\\[E[y|dA = 1, d2 = 0] = \\beta_{0} + \\beta_{1}    + E[\\eta|dA = 1, d2 = 0]\\] \\[E[y|dA = 0, d2 = 0] = \\beta_{0}  + E[\\eta|dA = 0, d2 = 0]\\]"
  },
  {
    "objectID": "slides/did/index.html#basic-model-8",
    "href": "slides/did/index.html#basic-model-8",
    "title": "E655 - Econometrics",
    "section": "Basic Model",
    "text": "Basic Model\n\nThen compute the difference in differences\n\\[(E[y|dA = 1, d2 = 1] - E[y|dA = 0, d2 = 1] )\\] \\[- (E[y|dA = 1, d2 = 0])-E[y|dA = 0, d2 = 0])\\] \\[= \\beta_{3}\\] \\[+  (E[\\eta|dA = 1, d2 = 1] - E[\\eta|dA = 1, d2 = 0])\\] \\[- (E[\\eta|dA = 0, d2 = 1] - E[\\eta|dA = 0, d2 = 0])\\]\nWhere \\(\\beta_{3}\\) is the treatment effect\nSelection bias is zero when regression error has constant bias/common trends"
  },
  {
    "objectID": "slides/did/index.html#interpretation-of-did",
    "href": "slides/did/index.html#interpretation-of-did",
    "title": "E655 - Econometrics",
    "section": "Interpretation of DiD",
    "text": "Interpretation of DiD\n\nUnder the assumption of constant treatment effects, \\(\\beta_{3} = ATE = ATT\\)\n\nConstant treatment effects means it is the same for all groups\n\nIf treatment effect can vary across groups, \\(\\beta_{3} = ATT\\)\n\nCard and Krueger: \\(\\beta_{3}\\) is the effect of increase in minimum wage on employment in NJ"
  },
  {
    "objectID": "slides/did/index.html#estimation-1",
    "href": "slides/did/index.html#estimation-1",
    "title": "E655 - Econometrics",
    "section": "Estimation",
    "text": "Estimation\n\nEstimation typically done by OLS \\[y = \\hat{\\beta}_{0} + \\hat{\\beta}_{1}dA +\\hat{\\beta}_{2}d2 + \\hat{\\beta}_{3}(dA\\times d2)+ u\\]\nThe coefficient on \\((dA\\times d2)\\) is the DiD estimator\nIt is given simply by \\[\\hat{\\beta}_{3} = (\\bar{y}_{A2} - \\bar{y}_{B2}) - (\\bar{y}_{A1} -\\bar{y}_{B1})\\]\nYou can also add control variables \\[y= \\beta_{0} + \\beta_{1}dA +\\beta_{2}d2 + \\beta_{3}(dA\\times d2)+\\mathbf{x}\\boldsymbol{\\alpha}+ u\\]\nThe interpretation remains similar, but estimator no longer collapses to the easy formula"
  },
  {
    "objectID": "slides/did/index.html#multiple-treatments",
    "href": "slides/did/index.html#multiple-treatments",
    "title": "E655 - Econometrics",
    "section": "Multiple Treatments",
    "text": "Multiple Treatments\n\nImagine the Card study where NJ raises the minimum wage\nSuppose that NY also raises it \\[y = \\beta_{0} + \\beta_{1}d(NJ,NY) +\\beta_{2}d2 +\\beta_{3}(d(NJ,NY)\\times d2)+  u\\]\n\\(d(NJ,NY)\\) equals 1 if in NJ or NY\nThis restricts the effect to be the same in NJ and NY\n\nAllowing for different impacts in NY and NJ\n\\[y = \\beta_{0} + \\beta_{1}dNJ+\\beta_{2}dNY +\\beta_{3}d2 + \\beta_{4}(dNJ\\times d2)+ \\beta_{5}(dNY\\times d2)+ u\\]\nHere, PA is used as the control group for both treatments"
  },
  {
    "objectID": "slides/did/index.html#multiple-time-periods",
    "href": "slides/did/index.html#multiple-time-periods",
    "title": "E655 - Econometrics",
    "section": "Multiple Time Periods",
    "text": "Multiple Time Periods\n\nImagine again the Card study with only NJ and PA\nSuppose we observe 4 time periods: 2 before, and 2 after policy change\nThe specification could change to \\[y = \\beta_{0} + \\beta_{1}dNJ +\\beta_{2}d2 +\\beta_{3}d3 +\\beta_{4}d4 + \\beta_{5}(dNJ\\times d(3,4))+u\\]\nwhere \\(d(3,4)\\) is a dummy equal to 1 if time period is 3 or 4\nThis would impose that the treatment effect is the same in all years\nA more general way to model this would be \\[y = \\beta_{0} + \\beta_{1}dNJ +\\beta_{2}d2 +\\beta_{3}d3 +\\beta_{4}d4 + \\beta_{5}(dNJ\\times d3)+ \\beta_{6}(dNJ\\times d4)+ u\\]\n\n\\(\\beta_{5}\\) is the treatment effect in time period 3\n\\(\\beta_{6}\\) is the treatment effect in time period 4"
  },
  {
    "objectID": "slides/did/index.html#multiple-treatments-and-time-periods",
    "href": "slides/did/index.html#multiple-treatments-and-time-periods",
    "title": "E655 - Econometrics",
    "section": "Multiple Treatments and Time Periods",
    "text": "Multiple Treatments and Time Periods\n\nIn this most general case, the specification is \\[y = \\beta_{0} + \\mathbf{dG}\\boldsymbol{\\beta_{1}} +\\mathbf{dT}\\boldsymbol{\\beta_{2}}+\\mathbf{z}\\boldsymbol{\\beta_{3}}+ u\\]\nWhere\n\n\\(\\mathbf{dG}\\) is a set of group dummies\n\\(\\mathbf{dT}\\) is a set of time dummies\n\\(\\mathbf{z}\\) are interaction between the time and group dummies post treatment\n\\(\\mathbf{z}\\) could also be a scalar equal to 1 for all groups and time periods post treatment\n\nThis is sometimes called the Two-Way Fixed Effects (TWFE) model"
  },
  {
    "objectID": "slides/did/index.html#standard-errors",
    "href": "slides/did/index.html#standard-errors",
    "title": "E655 - Econometrics",
    "section": "Standard Errors",
    "text": "Standard Errors\n\nYou must use “cluster-robust” standard errors\n\nError is not iid across all individuals\nCommon group component\nMust correct for this or SEs will be biased downward severely\n\nDonald and Lang (2001)\n\nClustered standard errors may not be enough\nAsymptotic results bad when number of groups is small\nUse bootstrap to solve this problem\n\nIn particular the clustered wild bootstrap"
  },
  {
    "objectID": "slides/did/index.html#standard-errors-1",
    "href": "slides/did/index.html#standard-errors-1",
    "title": "E655 - Econometrics",
    "section": "Standard Errors",
    "text": "Standard Errors\n\nBertrand, Duflo, Mullainathan (2004)\n\nErrors may be serially correlated\nOnly a problem when there are many time periods\nTo fix, you can aggregate to 2 time periods\nUse a “block” bootstrap"
  },
  {
    "objectID": "slides/did/index.html#common-treands",
    "href": "slides/did/index.html#common-treands",
    "title": "E655 - Econometrics",
    "section": "Common Treands",
    "text": "Common Treands\n\nWith 2 time periods, hard to check identifying assumption\nWith more than 2 time periods, you may be able to assess it\n\nExamine trends prior to treatment across both groups"
  },
  {
    "objectID": "slides/did/index.html#timing-of-treatment",
    "href": "slides/did/index.html#timing-of-treatment",
    "title": "E655 - Econometrics",
    "section": "Timing of Treatment",
    "text": "Timing of Treatment\n\nYou can have multiple groups who are treated at different times\nDiD estimator is complicated weighted average of treatment and control pairs\nCan be even more complicated if treatment effect varies over time\nSee Roth et. al. (2023) for an overview"
  },
  {
    "objectID": "slides/did/index.html#model-1",
    "href": "slides/did/index.html#model-1",
    "title": "E655 - Econometrics",
    "section": "Model",
    "text": "Model\n\nSometimes even the DiD assumptions are not valid\n\nThe common trend assumption is violated\n\nExample: Health care policy aimed at elderly (Wooldridge (2007))\n\nSuppose we have two groups\n\nElderly in state with policy\nElderly in state without policy\nBoth are observed in 2 time periods\n\nCould do DiD using difference in non-policy state as control\n\nThis alternative state might evolve differently somehow\n\nNow, imagine in each state we have\n\nElderly and non-elderly\nBoth are observed in 2 time periods"
  },
  {
    "objectID": "slides/did/index.html#model-2",
    "href": "slides/did/index.html#model-2",
    "title": "E655 - Econometrics",
    "section": "Model",
    "text": "Model\n\nCould do DiD in treatment state using difference in non-elderly as control group\n\nHealth of elderly and non-elderly might evolve differently\n\nWith 2 potential DiDs, which one do we choose?\nThe DDD estimator is an extension of the DiD estimator\n\nUses both DiDs in the same specification\nUses controls from within the treatment state (non-elderly) and from the other state (non-policy state) simultaneously"
  },
  {
    "objectID": "slides/did/index.html#model-3",
    "href": "slides/did/index.html#model-3",
    "title": "E655 - Econometrics",
    "section": "Model",
    "text": "Model\n\nSuppose we separate the sample into these groups\n\nGroup A: People in treatment state\nGroup B: People in control state\nGroup E: Elderly\nGroup N: Non Elderly\n\nThe regression would be \\[y = \\beta_{0} + \\beta_{1}dA + \\beta_{2}dE +\\beta_{3}d2 + \\beta_{3}(dA\\times d2)\\] \\[+ \\beta_{4}(dE\\times d2) + \\beta_{5}(dE\\times dA) + \\beta_{6}(dE\\times dA \\times d2)\n    + u\\]"
  },
  {
    "objectID": "slides/did/index.html#estimation-2",
    "href": "slides/did/index.html#estimation-2",
    "title": "E655 - Econometrics",
    "section": "Estimation",
    "text": "Estimation\n\nThe DDD estimator is \\[\\hat{\\beta}_{6} = [(\\bar{y}_{AE2} - \\bar{y}_{AN2}) - (\\bar{y}_{AE1} - \\bar{y}_{AN1})]\\] \\[- [(\\bar{y}_{BE2} - \\bar{y}_{BN2}) - (\\bar{y}_{BE1} - \\bar{y}_{BN1})]\\]\nIntuition\n\nDo a separate DiD in treatment and control state\nSubtract the 2 DiD estimates\n\nUses one DiD as a control for the other\n\nThere are actually several ways to interpret this estimator\n\nThe same problems with DiD apply to DDD estimators\n\nYou must be careful with the standard errors\nYou must be careful with the interpretation"
  },
  {
    "objectID": "slides/did/index.html#setup",
    "href": "slides/did/index.html#setup",
    "title": "E655 - Econometrics",
    "section": "Setup",
    "text": "Setup\n\nImagine the following scenario\n\nWe have data on 2 groups of people (A, and B)\nWe have data during 2 time periods (1 and 2)\nGroup A was exposed to some treatment in period 2\n\nEx: Minimum Wages (Card and Krueger (1994))\nGroup A (New Jersey) increases their minimum wage in period 2\nGroup B (Pennsylvania) does not change its minimum wage\nWe observe both groups before and after the wage change\n\n\nWe want to measure the causal effect of the policy"
  },
  {
    "objectID": "slides/did/index.html#potential-outcomes",
    "href": "slides/did/index.html#potential-outcomes",
    "title": "E655 - Econometrics",
    "section": "Potential Outcomes",
    "text": "Potential Outcomes\n\nWe will couch this estimator in the potential outcomes framework\nRecall that observed outcomes are \\[y = (y_{1} - y_{0} )w +  y_{0}\\]\n\n\\(y_{0}\\) is outcome without treatment\n\\(y_{1}\\) is outcome with treatment\n\nDefine the following dummy variables\n\n\\(dA = 1\\) if in group A, 0 if in group B\n\\(d2 = 1\\) of in time period 2, 0 if in period 1\n\n\\(w\\) is the binary treatment indicator\n\nEquals 1 for group A in period 2, and 0 otherwise\nIt is equivalent to \\(dA \\times d2\\)"
  },
  {
    "objectID": "slides/did/index.html#cef",
    "href": "slides/did/index.html#cef",
    "title": "E655 - Econometrics",
    "section": "CEF",
    "text": "CEF\n\nTake difference in observed outcome between treatment and control in period 2\n\n\\[E[y|dA = 1, d2 = 1] - E[y|dA = 0, d2 = 1]\\] \\[ = E[y_1|dA = 1, d2 = 1] - E[y_0|dA = 0, d2 = 1]\\]\n\\[ = E[y_1|dA = 1, d2 = 1] - E[y_0|dA = 1, d2 = 1] \\] \\[+ E[y_0|dA = 1, d2 = 1]- E[y_0|dA = 0, d2 = 1]\\]\n\nThis is the ATT plus selection bias\nSelection bias possibly not zero because \\(y_0\\) different between groups A and B in period 2"
  },
  {
    "objectID": "slides/did/index.html#cef-1",
    "href": "slides/did/index.html#cef-1",
    "title": "E655 - Econometrics",
    "section": "CEF",
    "text": "CEF\n\nDiD subtracts the difference in outcomes from period 1 to account for selection\n\n\\[E[y|dA = 1, d2 = 1] - E[y|dA = 0, d2 = 1]\\] \\[ -[E[y|dA = 1, d2 = 0] - E[y|dA = 0, d2 = 0]]\\] \\[ = E[y_1|dA = 1, d2 = 1] - E[y_0|dA = 1, d2 = 1] \\] \\[+ E[y_0|dA = 1, d2 = 1]- E[y_0|dA = 0, d2 = 1]\\] \\[ -[E[y_0|dA = 1, d2 = 0] - E[y_0|dA = 0, d2 = 0]]\\]\n\nSelection bias is zero if we assume constant bias or common trends"
  },
  {
    "objectID": "slides/did/index.html#constant-bias",
    "href": "slides/did/index.html#constant-bias",
    "title": "E655 - Econometrics",
    "section": "Constant Bias",
    "text": "Constant Bias\n\nSelection bias is zero if we make the constant bias assumption\nFrom above\n\n\\[+ E[y_0|dA = 1, d2 = 1]- E[y_0|dA = 0, d2 = 1]\\] \\[ -[E[y_0|dA = 1, d2 = 0] - E[y_0|dA = 0, d2 = 0]]\\]\n\nConstant bias means group difference in \\(y_0\\) is the same in both time periods\n\nBetween group differences in prior period are a good counterfactual for difference in treated time period"
  },
  {
    "objectID": "slides/did/index.html#common-trends",
    "href": "slides/did/index.html#common-trends",
    "title": "E655 - Econometrics",
    "section": "Common Trends",
    "text": "Common Trends\n\nAn equivalent assumption is common trends assumption\nRearrange the selection bias term to be\n\n\\[+ E[y_0|dA = 1, d2 = 1]- E[y_0|dA = 1, d2 = 0]\\] \\[ -[E[y_0|dA = 0, d2 = 1] - E[y_0|dA = 0, d2 = 0]]\\]\n\nSays trend in \\(y_0\\) for group A is the same as group B\n\nTrend in group B is a good counterfactual for trend in group A\n\nBoth assumptions are equivalent and assume no selection bias"
  },
  {
    "objectID": "slides/did/index.html#regression",
    "href": "slides/did/index.html#regression",
    "title": "E655 - Econometrics",
    "section": "Regression",
    "text": "Regression\n\nWe can model the CEF with a regression because it is a saturated model\n\n\\[y = \\beta_0 + \\beta_1 dA + \\beta_2 d2 + \\beta_3 (dA \\times d2) + u\\]\n\nThe parameter \\(\\beta_3\\) is the population difference in differences\n\n\\[\\beta_3 = E[y|dA = 1, d2 = 1] - E[y|dA = 0, d2 = 1] \\] \\[- E[y|dA = 1, d2 = 0]- E[y|dA = 0, d2 = 0 ]\\]\n\nRecall that \\(\\beta_3\\) is the ATT if we assume common trends or constant bias\n\nIf those do not hold, we have selection bias"
  },
  {
    "objectID": "slides/did/index.html#did-graphically",
    "href": "slides/did/index.html#did-graphically",
    "title": "E655 - Econometrics",
    "section": "DiD Graphically",
    "text": "DiD Graphically"
  },
  {
    "objectID": "slides/did/index.html#did-graphically-1",
    "href": "slides/did/index.html#did-graphically-1",
    "title": "E655 - Econometrics",
    "section": "DiD Graphically",
    "text": "DiD Graphically"
  },
  {
    "objectID": "slides/did/index.html#visual-representation",
    "href": "slides/did/index.html#visual-representation",
    "title": "E655 - Econometrics",
    "section": "Visual Representation",
    "text": "Visual Representation"
  },
  {
    "objectID": "slides/did/index.html#visual-representation-1",
    "href": "slides/did/index.html#visual-representation-1",
    "title": "E655 - Econometrics",
    "section": "Visual Representation",
    "text": "Visual Representation"
  },
  {
    "objectID": "slides/did/index.html",
    "href": "slides/did/index.html",
    "title": "\nDifference in Differences\n",
    "section": "",
    "text": "Difference in Differences"
  },
  {
    "objectID": "slides/did/index.html#checking-validity-of-did",
    "href": "slides/did/index.html#checking-validity-of-did",
    "title": "E655 - Econometrics",
    "section": "Checking Validity of DiD",
    "text": "Checking Validity of DiD\n\nRecall that a required assumption is common trends\nYou can check that empirically by looking at trends for treatment and control groups prior to treatment\n\nRequires more than 2 time periods\n\nTo do this, you can\n\nEstimate regression with sample before treatment\nInclude time dummy variables, group variables, interactions\nDo F-test on interactions"
  },
  {
    "objectID": "content/did.html",
    "href": "content/did.html",
    "title": "Difference in Differences",
    "section": "",
    "text": "AP1 Chapter 5\nAP2 Chapter 5\nC Chapter 9\nHA Chapter 18\nHK Chapter 18\nW1 Chapter 6.5\nW2 Chapter 13"
  },
  {
    "objectID": "content/did.html#readings",
    "href": "content/did.html#readings",
    "title": "Difference in Differences",
    "section": "",
    "text": "AP1 Chapter 5\nAP2 Chapter 5\nC Chapter 9\nHA Chapter 18\nHK Chapter 18\nW1 Chapter 6.5\nW2 Chapter 13"
  },
  {
    "objectID": "content/did.html#slides",
    "href": "content/did.html#slides",
    "title": "Difference in Differences",
    "section": "Slides",
    "text": "Slides\nThe slides are embedded in this page, and you can scroll through them with the arrow keys. If you prefer you can instead pop them out in a new window"
  },
  {
    "objectID": "content/did.html#videos",
    "href": "content/did.html#videos",
    "title": "Difference in Differences",
    "section": "Videos",
    "text": "Videos\nThis is a lecture from Prof. Christopher Walters given for the American Economics Association Continuing Education program (no preview available). View video"
  },
  {
    "objectID": "content/rd.html#sample-r-code",
    "href": "content/rd.html#sample-r-code",
    "title": "Regression Discontinuity",
    "section": "Sample R Code",
    "text": "Sample R Code\nThe code below goes through an exercise estimating various RD models, both sharp and fuzzy.\n EC655rd.R"
  },
  {
    "objectID": "content/did.html#sample-r-code",
    "href": "content/did.html#sample-r-code",
    "title": "Difference in Differences",
    "section": "Sample R Code",
    "text": "Sample R Code\nThe code below goes through an exercise estimating Difference in Differences models.\n EC655did.R"
  },
  {
    "objectID": "slides/paneldata/index.html#introduction-1",
    "href": "slides/paneldata/index.html#introduction-1",
    "title": "E655 - Econometrics",
    "section": "Introduction",
    "text": "Introduction\n\nRepeated observations of some individual unit along some dimension\n\nTypically, observing same people/firms/countries over time\nSecond dimension does not have to be time\n\nPanel data can be used in several ways\n\nDeal with individual heterogeneity\nIncrease variation (reduce standard errors)\nStudy dynamics\n\nIn microeconometrics, panel data mostly controls for individual heterogeneity\nWe will study\n\nBasic panel data methods\nUsing panel data to identify parameters"
  },
  {
    "objectID": "slides/paneldata/index.html#structure-of-panel-data",
    "href": "slides/paneldata/index.html#structure-of-panel-data",
    "title": "E655 - Econometrics",
    "section": "Structure of Panel Data",
    "text": "Structure of Panel Data\n\nPanels have at least 2 dimensions\n\nVariation occurs over \\(i=1,\\ldots,N\\) people, and \\(t=1,\\ldots,T\\) time\n\nA balanced panel is one where all individuals are observed in every time period\nAn unbalanced panel has at least one person not observed in a time period\n\n\n\n\nBalanced Panel\n\n\n\nID\nYear\nIncome\n\n\n1\n1990\n60000\n\n\n1\n1991\n65000\n\n\n1\n1992\n90000\n\n\n2\n1990\n20000\n\n\n2\n1991\n21000\n\n\n2\n1992\n24000\n\n\n\n\n\n\nUnbalanced Panel\n\n\n\nID\nYear\nEducation\n\n\n1\n1990\n60000\n\n\n1\n1991\n90000\n\n\n2\n1990\n20000\n\n\n2\n1991\n21000\n\n\n2\n1992\n24000"
  },
  {
    "objectID": "slides/paneldata/index.html#unobserved-effects-model",
    "href": "slides/paneldata/index.html#unobserved-effects-model",
    "title": "E655 - Econometrics",
    "section": "Unobserved Effects Model",
    "text": "Unobserved Effects Model\n\nLike regular regression model, but with unobserved variable that only varies over individuals\nThe regression model is \\[y_{it} =  \\mathbf{x_{it}}\\boldsymbol{\\beta} +a_{i} + u_{it}\\]\n\n\\(\\mathbf{x_{ij}}\\) contains a constant\n\\(a_{i}\\) is the unobserved effect\n\nAssume we are not interested in the effect of \\(a_{i}\\) on \\(y_{ij}\\)\n\nUsually it is not observed, or unmeasurable anyway\nThis is why it is not written with a parameter\n\nSeveral models we can use to estimate the parameters \\(\\boldsymbol{\\beta}\\)\n\nDepends on assumption about relationship between \\(\\mathbf{x_{ij}}\\) and \\(a_{i}\\)"
  },
  {
    "objectID": "slides/paneldata/index.html#strict-exogeneity",
    "href": "slides/paneldata/index.html#strict-exogeneity",
    "title": "E655 - Econometrics",
    "section": "Strict Exogeneity",
    "text": "Strict Exogeneity\n\nWe learned regression model was structural when error was mean independent\nPanel model is structural when we assume Strict Exogeneity\n\nError term \\(u_{ij}\\) has zero mean conditional on \\(a_{i}\\) and \\(\\mathbf{x_{ij}}\\) in all time periods.\n\nMathematically, strict exogeneity is written as \\[E[u_{ij} | \\mathbf{x_{i1}}, \\mathbf{x_{i2}}, \\ldots, \\mathbf{x_{iJ}}, a_{i}] =0\\]\nIt implies that \\(u_{ij}\\) in each time period is uncorrelated with \\(\\mathbf{x_{ij}}\\) in each time period \\[E[\\mathbf{x_{is}^{'}}u_{ij}] =0, \\forall s,j = 1,2,\\ldots, J\\]"
  },
  {
    "objectID": "slides/paneldata/index.html#strict-exogeneity-1",
    "href": "slides/paneldata/index.html#strict-exogeneity-1",
    "title": "E655 - Econometrics",
    "section": "Strict Exogeneity",
    "text": "Strict Exogeneity\n\nIt also implies that the unobserved effect is uncorrelated with \\(u_{ij}\\) in every time period \\[E[a_{i}u_{is}] =0, \\forall s = 1,2,\\ldots, J\\]\nStrict exogeneity assumptions are necessary for consistency of estimators we discuss below\nNote that strict exogeneity says nothing about the correlation between \\(\\mathbf{x_{ij}}\\) and \\(a_{i}\\)\n\nWe must make an additional assumption\nIt is this assumption that determines what model we use"
  },
  {
    "objectID": "slides/paneldata/index.html#fixed-effects",
    "href": "slides/paneldata/index.html#fixed-effects",
    "title": "E655 - Econometrics",
    "section": "Fixed Effects",
    "text": "Fixed Effects\n\nIf we assume \\(\\mathbf{x_{ij}}\\) and \\(a_{i}\\) are correlated, then fixed effects is the appropriate method \\[y_{ij} =  \\mathbf{x_{ij}}\\boldsymbol{\\beta} +a_{i} + u_{ij}\\]\nThis is the most popular panel data method\n\nMain use of panel data is to account for an unobserved factors correlated with \\(\\mathbf{x_{ij}}\\)\nIn this case, we assume the unobserved factor is time constant\n\nFixed effects is a method to remove the influence of \\(a_{i}\\) to get estimates of \\(\\boldsymbol{\\beta}\\)\nThere are two main ways to estimate a fixed model"
  },
  {
    "objectID": "slides/paneldata/index.html#fixed-effects-1",
    "href": "slides/paneldata/index.html#fixed-effects-1",
    "title": "E655 - Econometrics",
    "section": "Fixed Effects",
    "text": "Fixed Effects\n\nFor a couple of reasons we usually do not use the DVR approach\n\nIf \\(N\\) is large, it takes forever to estimate\nWe do not care about \\(a_{i}\\) normally\nThe estimator for fixed effects is not consistent as \\(N \\rightarrow \\infty\\)\n\nWith the DVR approach, you would use the variance estimator we discussed in the OLS section"
  },
  {
    "objectID": "slides/paneldata/index.html#fixed-effects-2",
    "href": "slides/paneldata/index.html#fixed-effects-2",
    "title": "E655 - Econometrics",
    "section": "Fixed Effects",
    "text": "Fixed Effects\n\nFixed effects is frequently used to infer causality\n\nUnobserved variables are “controlled” with the fixed effect\nThis is only appropriate if all unobserved heterogeneity is constant over time\n\nIf unobserved variables differ over time, no causality can be inferred"
  },
  {
    "objectID": "slides/paneldata/index.html#fixed-effects-3",
    "href": "slides/paneldata/index.html#fixed-effects-3",
    "title": "E655 - Econometrics",
    "section": "Fixed Effects",
    "text": "Fixed Effects\n\nThe matrix \\(\\mathbf{X^{*}}\\) contains all observations over time and persons and is \\((N\\times J)\\) by \\(K\\)\nIt is easiest to think of them as stacked cross-sectional observations\nFor each cross-sectional observation we have \\[\\mathbf{X_{i}} = \\begin{bmatrix} x_{i1}^{1}  &x_{i1}^{2}&\\ldots &x_{i1}^{K}\\\\\n                            x_{i2}^{1} &x_{i2}^{2}&\\ldots &x_{i2}^{K} \\\\\n                            \\vdots &\\ddots & \\ldots & \\vdots \\\\\n                            x_{iJ}^{1}&x_{iJ}^{2}&\\ldots &x_{iJ}^{K} \\\\\n                            \\end{bmatrix} ,  \\mathbf{\\bar{X}_{i}}  =\\begin{bmatrix} \\bar{x_{i}}^{1}  &\\bar{x_{i}}^{2}&\\ldots &\\bar{x_{i}}^{K}\\\\\n                            \\bar{x_{i}}^{1}  &\\bar{x_{i}}^{2}&\\ldots &\\bar{x_{i}}^{K} \\\\\n                            \\vdots &\\ddots & \\ldots & \\vdots \\\\\n                            \\bar{x_{i}}^{1}  &\\bar{x_{i}}^{2}&\\ldots &\\bar{x_{i}}^{K} \\\\\n                            \\end{bmatrix}\\] \\[\\mathbf{X^{*}_{i}} = \\begin{bmatrix} (x_{i1}^{1} - \\bar{x}_{i}^{1}) &(x_{i1}^{2}-\\bar{x}_{i}^{2})&\\ldots &(x_{i1}^{K}-\\bar{x}_{i}^{K})\\\\\n                            (x_{i2}^{1}-\\bar{x}_{i}^{1}) &(x_{i2}^{2}-\\bar{x}_{i}^{2})&\\ldots &(x_{i2}^{K}-\\bar{x}_{i}^{K}) \\\\\n                            \\vdots &\\ddots & \\ldots & \\vdots \\\\\n                            (x_{iJ}^{1} -\\bar{x}_{i}^{1})&(x_{iJ}^{2}-\\bar{x}_{i}^{2})&\\ldots &(x_{iJ}^{K}-\\bar{x}_{i}^{K}) \\\\\n                            \\end{bmatrix} =  \\mathbf{X_{i}}  - \\mathbf{\\bar{X}_{i}}\\]"
  },
  {
    "objectID": "slides/paneldata/index.html#fixed-effects-4",
    "href": "slides/paneldata/index.html#fixed-effects-4",
    "title": "E655 - Econometrics",
    "section": "Fixed Effects",
    "text": "Fixed Effects\n\nThese matrices are then stacked on top of each other \\[\\mathbf{X^{*}} = \\begin{bmatrix} \\mathbf{X^{*}_{1}} \\\\ \\mathbf{X^{*}_{2}} \\\\ \\vdots \\\\ \\mathbf{X^{*}_{N}}  \\end{bmatrix}\\]\nThe fixed effects estimator can be derived using the time-demeaning matrix\nLet \\(\\mathbf{i}\\) be a \\(J \\times 1\\) column of ones\nDefine the \\(J \\times J\\) matrix \\(\\mathbf{M_{0}}\\) as one that turns the columns of any matrix with \\(J\\) rows into deviations from means \\[\\mathbf{M_{0}} = \\mathbf{I}_{J} - \\frac{1}{J}\\mathbf{ii'}\\]"
  },
  {
    "objectID": "slides/paneldata/index.html#fixed-effects-5",
    "href": "slides/paneldata/index.html#fixed-effects-5",
    "title": "E655 - Econometrics",
    "section": "Fixed Effects",
    "text": "Fixed Effects\n\nNext, define the following \\(NJ \\times NJ\\) matrix \\(\\mathbf{M_{D}}\\) \\[\\mathbf{M_{D}}  = \\begin{bmatrix} \\mathbf{M_{0}} & 0 & \\ldots &0\\\\\n                               0 & \\mathbf{M_{0}}& \\ldots &0 \\\\\n                               \\vdots &\\ddots & \\ldots & \\vdots \\\\\n                               0 & 0& \\ldots & \\mathbf{M_{0}}   \\\\\n                            \\end{bmatrix}\\]\nThe Fixed Effects estimator can be written as \\[\\boldsymbol{\\hat{\\beta}_{fe}} = \\mathbf{(X^{'}M_{D}X)^{-1}X^{'}M_{D} Y}\\]"
  },
  {
    "objectID": "slides/paneldata/index.html#fixed-effects-6",
    "href": "slides/paneldata/index.html#fixed-effects-6",
    "title": "E655 - Econometrics",
    "section": "Fixed Effects",
    "text": "Fixed Effects\n\nThe robust estimator for the variance covariance matrix for \\(\\boldsymbol{\\hat{\\beta}_{fe}}\\) is \\[\\hat{var}(\\boldsymbol{\\hat{\\beta}_{fe}})= \\mathbf{(X^{*'}_{i} X^{*}_{i})^{-1}} \\left ( \\sum_{i=1}^{n} \\mathbf{X^{*'}_{i} \\hat{u}_{i}^{*} \\hat{u}_{i}^{*'}X^{*}_{i}}\\right ) \\mathbf{(X^{*'}_{i} X^{*}_{i})^{-1}}\\]\nThis estimator is robust to both heteroskedasticity and serial correlation\n\nSerial correlation is an issue because the data have a time element\nHeteroskedasticity can happen because the data have a cross-sectional element\n\nIf error has no heteroskedasticity and no serial correlation, you can simplify this variance estimator"
  },
  {
    "objectID": "slides/paneldata/index.html#fixed-effects-7",
    "href": "slides/paneldata/index.html#fixed-effects-7",
    "title": "E655 - Econometrics",
    "section": "Fixed Effects",
    "text": "Fixed Effects\n\nA second estimation method is the Dummy Variable Regression\n\n\nIn this model, we include a dummy variable for each cross-sectional unit\n\nThe interpretation of \\(a_{i}\\) changes\nIt is now considered a parameter and not a variable\nIn practice it does not matter because it produces the same results as within estimator\n\nThe regression is \\[y_{ij} =  \\mathbf{x_{ij}}\\boldsymbol{\\beta} + \\mathbf{D_{i}}\\boldsymbol{\\alpha} + u_{ij}\\]\nWhere \\(D_{i}\\) is a vector of dummy variables indicating the cross-sectional unit, and \\(\\alpha\\) is an \\(N-1\\) vector (we exclude 1 of the dummies to identify the model)\nThe vector \\(\\boldsymbol{\\hat{\\beta}_{DVR}}\\) will be identical to \\(\\boldsymbol{\\hat{\\beta}_{fe}}\\)"
  },
  {
    "objectID": "slides/paneldata/index.html#fixed-effects-8",
    "href": "slides/paneldata/index.html#fixed-effects-8",
    "title": "E655 - Econometrics",
    "section": "Fixed Effects",
    "text": "Fixed Effects\n\nFor a couple of reasons we usually do not use the DVR approach\n\nIf \\(N\\) is large, it takes forever to estimate\nWe do not care about \\(a_{i}\\) normally\nThe estimator for fixed effects is not consistent as \\(N \\rightarrow \\infty\\)\n\nWith the DVR approach, you would use the variance estimator we discussed in the OLS section"
  },
  {
    "objectID": "slides/paneldata/index.html#first-differencing",
    "href": "slides/paneldata/index.html#first-differencing",
    "title": "E655 - Econometrics",
    "section": "First Differencing",
    "text": "First Differencing\n\nStill assume \\(\\mathbf{x_{ij}}\\) and \\(a_{i}\\) are correlated\nThe unobserved effects model is \\[y_{it} =  \\mathbf{x_{it}}\\boldsymbol{\\beta} +a_{i} + u_{it}\\]\nThe unobserved effect is eliminated by differencing adjacent time periods\n\n\\[y_{it-1} =  \\mathbf{x_{it-1}}\\boldsymbol{\\beta} +a_{i} + u_{it-1}\\]\n\\[y_{it} -  y_{it-1} =  \\mathbf{(x_{it} -x_{it-1}) }\\boldsymbol{\\beta} +a_{i}-a_{i} + u_{it} -u_{it-1}\\] \\[\\Delta y_{it}=  \\mathbf{(\\Delta x_{it}  ) }\\boldsymbol{\\beta}   + \\Delta u_{it}\\]\n\nSince \\(a_{i}\\) is constant over time for each cross-sectional unit, it is eliminated when we difference"
  },
  {
    "objectID": "slides/paneldata/index.html#first-differencing-1",
    "href": "slides/paneldata/index.html#first-differencing-1",
    "title": "E655 - Econometrics",
    "section": "First Differencing",
    "text": "First Differencing\n\nThe amount of data we have left after differencing depends on the number of time periods\n\nIf T = 2, then we are left with 1 observation per person\nIf T = 3, then we are left with 2 observations per person\netc...\n\nThe first difference estimator is the OLS estimator applied to the differenced data\n\n\\[\\boldsymbol{\\hat{\\beta}_{fd}} = \\mathbf{((\\Delta X)^{'}(\\Delta X))^{-1}(\\Delta X)^{'}(\\Delta Y)}\\]"
  },
  {
    "objectID": "slides/paneldata/index.html#first-differencing-2",
    "href": "slides/paneldata/index.html#first-differencing-2",
    "title": "E655 - Econometrics",
    "section": "First Differencing",
    "text": "First Differencing\n\nThe cluster-robust variance covariance matrix for \\(\\boldsymbol{\\beta_{fd}}\\) is\n\n\\[\\hat{var}(\\boldsymbol{\\hat{\\beta}_{fd}}) = \\mathbf{(\\Delta X' \\Delta X)^{-1}} \\left ( \\sum_{i=1}^{n} \\mathbf{\\Delta X'_{i} \\Delta\\hat{u}_{i} \\Delta\\hat{u}'_{i}\\Delta X_{i}}\\right ) \\mathbf{(\\Delta X' \\Delta X)^{-1}}\\]\n\nAgain this is robust to both heteroskedasticity and serial correlation\nWhen using this method:\n\nThere must be variation in a variable over time for it to be included\nTo infer a causal relationship, the unobserved heterogeneity must be time constant"
  },
  {
    "objectID": "slides/paneldata/index.html#random-effects",
    "href": "slides/paneldata/index.html#random-effects",
    "title": "E655 - Econometrics",
    "section": "Random Effects",
    "text": "Random Effects\n\nFixed Effects and First Differencing are appropriate with a correlated unobserved effect\nIf the unobserved effect is not correlated with \\(\\mathbf{x_{it}}\\), we do not need to control for it\nIn theory we can use a pooled regression in this case\nBut it not efficient because it ignores the unobserved effect in the error\nRandom Effects is appropriate in this case"
  },
  {
    "objectID": "slides/paneldata/index.html#random-effects-1",
    "href": "slides/paneldata/index.html#random-effects-1",
    "title": "E655 - Econometrics",
    "section": "Random Effects",
    "text": "Random Effects\n\nTogether these assumptions imply that\n\n\\[E(e_{i}|\\mathbf{x_{i}})  = 0\\]\n\\[E(\\mathbf{e_{i}}\\mathbf{e_{i}'}|\\mathbf{x_{i}})  =\\begin{bmatrix} \\sigma_{a}^2 + \\sigma_{u}^2&  \\sigma_{a}^2  & \\ldots &  \\sigma_{a}^2\\\\\n                                     \\sigma_{a}^2 & \\sigma_{a}^2 + \\sigma_{u}^2& \\ldots & \\sigma_{a}^2 \\\\\n                                   \\vdots &\\ddots & \\ldots & \\vdots \\\\\n                                    \\sigma_{a}^2 &  \\sigma_{a}^2& \\ldots & \\sigma_{a}^2 + \\sigma_{u}^2 \\\\\n                                \\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/paneldata/index.html#random-effects-2",
    "href": "slides/paneldata/index.html#random-effects-2",
    "title": "E655 - Econometrics",
    "section": "Random Effects",
    "text": "Random Effects\n\nThe variance covariance matrix of the errors for the whole data set is\n\n\\[\\boldsymbol{\\Omega} =     \\begin{bmatrix} \\boldsymbol{\\Sigma}& \\mathbf{0}  & \\ldots & \\mathbf{0}\\\\\n                                     \\mathbf{0}& \\boldsymbol{\\Sigma}& \\ldots & \\mathbf{0} \\\\\n                                   \\vdots &\\ddots & \\ldots & \\vdots \\\\\n                                   \\mathbf{0}&  \\mathbf{0}& \\ldots & \\boldsymbol{\\Sigma}\\\\\n                                \\end{bmatrix}\\]\n\nThis is the “random effects structure”\n\nErrors are correlated within \\(i\\), but not across \\(i\\)"
  },
  {
    "objectID": "slides/paneldata/index.html#random-effects-3",
    "href": "slides/paneldata/index.html#random-effects-3",
    "title": "E655 - Econometrics",
    "section": "Random Effects",
    "text": "Random Effects\n\nThe random effects estimator is Generalized Least Squares (GLS) applied to the data using the random effects error structure\n\nGLS “transforms” the data, and runs OLS on the transformed data\n\nThe Random Effects Estimator is\n\n\\[\\boldsymbol{\\hat{\\beta}_{re}} =  \\mathbf{(X' \\hat{\\Omega}^{-1}X)^{-1}X'\\hat{\\Omega}^{-1}Y}\\]\n\n\\(\\boldsymbol{\\hat{\\Omega}}\\) is the estimated variance covariance matrix with \\(\\sigma_{u}\\) and \\(\\sigma_{a}\\) replaced by estimates\nFinding estimates of \\(\\sigma_{u}\\) and \\(\\sigma_{a}\\) is outlined in Wooldridge (2002)\n\nIt is applied automatically in Stata or R"
  },
  {
    "objectID": "slides/paneldata/index.html#random-effects-4",
    "href": "slides/paneldata/index.html#random-effects-4",
    "title": "E655 - Econometrics",
    "section": "Random Effects",
    "text": "Random Effects\n\nSince we have assumed homoskedasticity, we can write the variance estimator\n\n\\[\\hat{var}( \\boldsymbol{\\hat{\\beta}_{re}}) = \\mathbf{(X'\\boldsymbol{\\hat{\\Omega}}^{-1}X)^{-1} }\\]\n\nCan compare to a cluster-robust estimator\n\n\\[\\hat{var}(\\boldsymbol{\\hat{\\beta}_{re}})= \\mathbf{(X'\\boldsymbol{\\hat{\\Omega}}^{-1}X)^{-1} }\\left ( \\sum_{i=1}^{n} \\mathbf{X^{'}_{i} \\hat{\\Sigma}^{-1} \\hat{u}_{i} \\hat{u}_{i}^{'}\\hat{\\Sigma}^{-1}X_{i}}\\right ) \\mathbf{(X'\\boldsymbol{\\hat{\\Omega}}^{-1}X)^{-1} }\\]\n\nAgain, this is computed automatically using software so no need to worry about the complex formula"
  },
  {
    "objectID": "slides/paneldata/index.html#random-effects-5",
    "href": "slides/paneldata/index.html#random-effects-5",
    "title": "E655 - Econometrics",
    "section": "Random Effects",
    "text": "Random Effects\n\nBecause of our previous assumptions, \\[\\sigma_{v}^2 = \\frac{1}{J}\\sum_{j=1}^{J}E(v_{ij}^2)\\]\n\nThis is true for each individual\nReplace \\(E(v_{ij}^2)\\) with a sample average across \\(i\\) using consistent estimates of \\(v_{ij}\\)\n\nBecause we have assumed \\(\\mathbf{x_{ij}}\\) and \\(a_{i}\\) are uncorrelated, we can obtain consistent estimates of \\(v_{ij}\\) from pooled OLS\n\nRegress \\(y_{ij} = \\mathbf{x_{ij}}\\boldsymbol{\\beta} +v_{ij}\\)\nKeep the residuals from this regression, \\(\\hat{v}_{ij}\\)\nThen for the estimate of \\(\\sigma_{v}^2\\) \\[\\hat{\\sigma}_{v}^2 = \\frac{1}{NJ-K}\\sum_{i=1}^{N}\\sum_{j=1}^{J}\\hat{v}_{ij}^2\\]"
  },
  {
    "objectID": "slides/paneldata/index.html#random-effects-6",
    "href": "slides/paneldata/index.html#random-effects-6",
    "title": "E655 - Econometrics",
    "section": "Random Effects",
    "text": "Random Effects\n\nNow, we obtain an estimate of \\(\\sigma_{a}\\) using a similar method \\[\\sigma_{a}^2 = \\frac{1}{J(J-1)/2}\\sum_{j=1}^{J-1}\\sum_{s = j+1}^{J}E(v_{ij}v_{is})\\]\n\nThis is true for each individual\nReplace \\(E(v_{ij}v_{is})\\) with a sample average across \\(i\\) using consistent estimates of \\(v_{ij}\\)"
  },
  {
    "objectID": "slides/paneldata/index.html#random-effects-7",
    "href": "slides/paneldata/index.html#random-effects-7",
    "title": "E655 - Econometrics",
    "section": "Random Effects",
    "text": "Random Effects\n\nThe estimate of \\(\\sigma_{a}^2\\) is \\[\\hat{\\sigma}_{a}^2 = \\frac{1}{NJ(J-1)/2 - K}\\sum_{j=1}^{J-1}\\sum_{s = j+1}^{J}\\sum_{i=1}^{N}\\hat{v}_{ij}\\hat{v}_{is}\\]\nThe idea is that there are \\(J(J-1)/2\\) cross-products of errors for each individual\nAveraging these errors together for each person, then averaging across all people, we get a consistent estimate\nOnce we have \\(\\hat{\\sigma}_{a}^2\\) and \\(\\hat{\\sigma}_{v}^2\\), we obtain \\(\\hat{\\sigma}_{u}^2 = \\hat{\\sigma}_{v}^2-\\hat{\\sigma}_{a}^2\\)\n\nUse these values in \\(\\boldsymbol{\\hat{\\Omega}}\\), and we have all that is required for the Random Effects Estimator"
  },
  {
    "objectID": "slides/paneldata/index.html#random-effects-8",
    "href": "slides/paneldata/index.html#random-effects-8",
    "title": "E655 - Econometrics",
    "section": "Random Effects",
    "text": "Random Effects\n\nWith all of these assumptions, the variance estimate of the random effects estimator is\n\\[\\hat{var}( \\boldsymbol{\\hat{\\beta}_{re}}) = \\mathbf{(X'\\boldsymbol{\\hat{\\Omega}}^{-1}X)^{-1} }\\]\nThis procedure depends on the assumptions we have made about the random effects structure\nWe could also avoid those assumptions and use a robust variance estimator \\[\\hat{var}(\\boldsymbol{\\hat{\\beta}_{re}})= \\mathbf{(X'\\boldsymbol{\\hat{\\Omega}}^{-1}X)^{-1} }\\left ( \\sum_{i=1}^{n} \\mathbf{X^{'}_{i} \\hat{\\Sigma}^{-1} \\hat{u}_{i} \\hat{u}_{i}^{'}\\hat{\\Sigma}^{-1}X_{i}}\\right ) \\mathbf{(X'\\boldsymbol{\\hat{\\Omega}}^{-1}X)^{-1} }\\]\nBut Random Effects is generally all about the structure of the errors\n\nSo if you are going to avoid making those assumptions, then you can use OLS"
  },
  {
    "objectID": "slides/paneldata/index.html#introduction",
    "href": "slides/paneldata/index.html#introduction",
    "title": "E655 - Econometrics",
    "section": "Introduction",
    "text": "Introduction\n\nRepeated observations of some individual unit along some dimension\n\nObserving same people/firms/countries over time\nSecond dimension does not have to be time\n\nPanel data can be used in several ways\n\nEliminate individual heterogeneity\nIncrease variation (reduce standard errors)\nStudy dynamics\n\nIn microeconometrics, panel data mostly controls for individual heterogeneity\nWe will study\n\nBasic panel data methods\nUsing panel data to identify parameters"
  },
  {
    "objectID": "slides/paneldata/index.html#model",
    "href": "slides/paneldata/index.html#model",
    "title": "E655 - Econometrics",
    "section": "Model",
    "text": "Model\n\nWrite the regression model as\n\n\\[y_{it} =  \\mathbf{x_{it}}\\boldsymbol{\\beta} + e_{it}\\]\n\nRecall that \\(i\\) indexes individuals, and \\(t\\) indexes time\nOne approach is to ignore the panel structure\nThis is called Pooled Regression since it pools data across people and time\nThe slope from population least squares is\n\n\\[\\boldsymbol{\\beta}^{*} = E[\\mathbf{x_{it}}'\\mathbf{x_{it}}]^{-1}E[\\mathbf{x_{it}}'y_{it}]\\]"
  },
  {
    "objectID": "slides/paneldata/index.html#model-1",
    "href": "slides/paneldata/index.html#model-1",
    "title": "E655 - Econometrics",
    "section": "Model",
    "text": "Model\n\nIf \\(\\boldsymbol{\\beta}\\) is defined as the population least squares slope\n\nThe error term \\(e_{it}\\) is the population least squares residual\nBy definition \\(E[\\mathbf{x_{it}}'e_{it}] = 0\\)\nCan proceed with OLS to estimate \\(\\boldsymbol{\\beta}\\)\n\nIf \\(\\boldsymbol{\\beta}\\) is a structural parameter (like a causal effect)\n\nWe need to assume that \\(E[\\mathbf{x_{it}}'e_{it}] = 0\\)\nThis may or may not be true\nIf it is true, we can proceed with OLS to estimate \\(\\boldsymbol{\\beta}\\)\nIf it is not true, we cannot use OLS to estimate \\(\\boldsymbol{\\beta}\\)"
  },
  {
    "objectID": "slides/paneldata/index.html#estimation",
    "href": "slides/paneldata/index.html#estimation",
    "title": "E655 - Econometrics",
    "section": "Estimation",
    "text": "Estimation\n\nThe pooled regression estimator is\n\n\\[\\hat{\\boldsymbol{\\beta}} = \\left(\\sum_{i=1}^{N}\\sum_{t=1}^{T}\\mathbf{x_{it}}'\\mathbf{x_{it}}\\right)^{-1}\\left(\\sum_{i=1}^{N}\\sum_{t=1}^{T}\\mathbf{x_{it}}'y_{it}\\right) = (X'X)^{-1}X'Y\\] - Perform OLS on the data as though there was no separate individual and time dimension\n\nIf \\(E[\\mathbf{x_{it}}'e_{it}] = 0\\), then \\(\\hat{\\boldsymbol{\\beta}}\\) is consistent for \\(\\boldsymbol{\\beta}\\)"
  },
  {
    "objectID": "slides/paneldata/index.html#estimation-1",
    "href": "slides/paneldata/index.html#estimation-1",
    "title": "E655 - Econometrics",
    "section": "Estimation",
    "text": "Estimation\n\nFor inference we need the variance of \\(\\hat{\\boldsymbol{\\beta}}\\)\nWith variation across individuals and time this is more complicated\n\nNeed to worry about heteroskedasticity and serial correlation\n\nAssuming no heteroskedasticity or serial correlation\n\nVariance of \\(\\hat{\\boldsymbol{\\beta}}\\) is the homoskedasticity-only variance estimator we covered before\n\nAssuming heteroskedasticity but no serial correlation\n\nVariance of \\(\\hat{\\boldsymbol{\\beta}}\\) is the robust variance estimator we covered before"
  },
  {
    "objectID": "slides/paneldata/index.html#estimation-2",
    "href": "slides/paneldata/index.html#estimation-2",
    "title": "E655 - Econometrics",
    "section": "Estimation",
    "text": "Estimation\n\nIf we think there is serial correlation, need to adjust the variance estimator\nMain issue is that the error term is correlated across time within units\nA method that accounts for this is the cluster-robust variance estimator\n\n\\[\\hat{V}_{CR}(\\hat{\\boldsymbol{\\beta}}) = (\\mathbf{X'X)^{-1}} \\left( \\sum_{i=1}^{N}\\mathbf{X_{i}'}\\mathbf{\\hat{e_{i}}}\\mathbf{\\hat{e_{i}}'}\\mathbf{X_{i}}\\right)(\\mathbf{X'X)^{-1}}\\]\n\n\\(\\mathbf{X_{i}}\\) is the matrix of observations for individual \\(i\\)\n\\(\\mathbf{\\hat{e_{i}}}\\) is the vector of residuals for individual \\(i\\)"
  },
  {
    "objectID": "slides/paneldata/index.html#model-2",
    "href": "slides/paneldata/index.html#model-2",
    "title": "E655 - Econometrics",
    "section": "Model",
    "text": "Model\n\nPooled regression ignores the panel structure of the data\nWe can do more by leveraging the variation over time and individuals\nUsually researchers do this by modelling the error term in the following way\n\n\\[e_{it} =  a_{i} + u_{it}\\]\n\nThere are two components to the error\n\n\\(a_{i}\\) is the unobserved effect or individual effect\n\\(u_{it}\\) is the idiosyncratic error\n\nPutting this together the unobserved effects model is\n\n\\[y_{it} =  \\mathbf{x_{it}}\\boldsymbol{\\beta} + a_{i} + u_{it}\\]"
  },
  {
    "objectID": "slides/paneldata/index.html#unobserved-effect",
    "href": "slides/paneldata/index.html#unobserved-effect",
    "title": "E655 - Econometrics",
    "section": "Unobserved Effect",
    "text": "Unobserved Effect\n\nThe unobserved effect \\(a_{i}\\) is a constant that varies across individuals\nIt is usually treated as some unknown omitted variable\n\nEffect of a school on test scores\nEffect of a firm on wages\n\nWe do not care about estimating its effect\nBut may need to control for it to estimate structural parameters\nMethods we cover differ in how they deal with \\(a_{i}\\)"
  },
  {
    "objectID": "slides/paneldata/index.html",
    "href": "slides/paneldata/index.html",
    "title": "\nPanel Data\n",
    "section": "",
    "text": "Panel Data"
  },
  {
    "objectID": "slides/paneldata/index.html#model-3",
    "href": "slides/paneldata/index.html#model-3",
    "title": "E655 - Econometrics",
    "section": "Model",
    "text": "Model\n\nThe key to this model is assumption that \\(a_{i}\\) is correlated with \\(\\mathbf{x_{it}}\\)\nExample: Effect of school size on achievement\n\nOutcome is student achievement\nMain independent variable is school size\nThere is unobserved school quality\nSchools that are larger may be better quality\nIf school size and quality affect achievement, this causes bias\n\nThis is illustrated graphically below using a general example"
  },
  {
    "objectID": "slides/paneldata/index.html#graphical-illustration",
    "href": "slides/paneldata/index.html#graphical-illustration",
    "title": "E655 - Econometrics",
    "section": "Graphical Illustration",
    "text": "Graphical Illustration"
  },
  {
    "objectID": "slides/paneldata/index.html#fixed-effects-9",
    "href": "slides/paneldata/index.html#fixed-effects-9",
    "title": "E655 - Econometrics",
    "section": "Fixed Effects",
    "text": "Fixed Effects\n\nFixed effects is frequently used to infer causality\n\nUnobserved variables are “controlled” with the fixed effect\nThis is only appropriate if all unobserved heterogeneity is constant over time\n\nIf unobserved variables differ over time, no causality can be inferred"
  },
  {
    "objectID": "assignments/assign3.html",
    "href": "assignments/assign3.html",
    "title": "Assignment 3",
    "section": "",
    "text": "Answer Key\n\n\n\nYou can download the solutions using the links below\n a3solutions.qmd\n a3solutions.pdf"
  },
  {
    "objectID": "assignments/assign3.html#description",
    "href": "assignments/assign3.html#description",
    "title": "Assignment 3",
    "section": "Description",
    "text": "Description\nIn this assignment you are asked to manipulate data, estimate statistical relationships, and interpret the findings. The questions are based on course content we have covered up to now, so if you get stuck I highly recommend going back over that material because the questions are closely related. This includes both the lecture notes and the extra material posted to the course website.\nYou should start this assignment early because it will not be possible (in my opinion) to do well if you start close to the due date. There are parts that you may find difficult; you will want to identify them and leave enough time to ask questions if necessary."
  },
  {
    "objectID": "assignments/assign3.html#instructions",
    "href": "assignments/assign3.html#instructions",
    "title": "Assignment 3",
    "section": "Instructions",
    "text": "Instructions\n\nTemplate\nThe template below contains the assignment questions. Please answer then all within the template in the appropriate place. Replace everything in all caps with your information, and add code where asked.\nWhen you save the file to your computer, please rename it with your family name and student number, with no spaces.\n a3template.qmd\n\n\nData analysis\nPart of the assignment involves data analysis in R, which you will include as code chunks in the Quarto document. Please make sure all of your analysis is contained in your Quarto document and that it runs properly. Make note of the packages used in the file and ensure you have them installed in RStudio. Also make sure you have a Tex distribution installed on your machine.\nPart of the analysis uses the following data files. Save them in the same directory as your template file.\n a3data1.csv\n a3data2.csv\n\n\nSubmission\nWhen you are finished, you are required to submit two documents according to the following instructions:\n\nYour .qmd file containing the completed template file. Submit this in MyLearningSpace only.\nA rendered PDF of your .qmd file. Submit this in both MyLearningSpace and Gradescope.\n\nThe template is structured to output both the code and the results of the code. Please ensure that this is the case in your rendered PDF because I will grade only that document. I will go to the .qmd file only in cases when something in your PDF does not make sense.\n\n\nPlagiarism\nThis is an independent assignment, which I expect you to complete on your own. It is plagiarism to copy someone else’s work verbatim, which includes R code. Any work you submit should be yours only. However, you are encouraged to talk to each other to try to figure out how to do the assignment."
  },
  {
    "objectID": "content/paneldata.html",
    "href": "content/paneldata.html",
    "title": "Panel Data",
    "section": "",
    "text": "Fixed Effects\n\nAP1 Chapter 5\nC Chapter 8\nCT Chapter 21\nHA Chapter 17\nHK Chapter 16\nW1 Chapter 14\nW2 Chapter 10"
  },
  {
    "objectID": "content/paneldata.html#readings",
    "href": "content/paneldata.html#readings",
    "title": "Panel Data",
    "section": "",
    "text": "Fixed Effects\n\nAP1 Chapter 5\nC Chapter 8\nCT Chapter 21\nHA Chapter 17\nHK Chapter 16\nW1 Chapter 14\nW2 Chapter 10"
  },
  {
    "objectID": "content/paneldata.html#slides",
    "href": "content/paneldata.html#slides",
    "title": "Panel Data",
    "section": "Slides",
    "text": "Slides\nThe slides are embedded in this page, and you can scroll through them with the arrow keys. If you prefer you can instead pop them out in a new window"
  },
  {
    "objectID": "content/paneldata.html#sample-r-code",
    "href": "content/paneldata.html#sample-r-code",
    "title": "Panel Data",
    "section": "Sample R Code",
    "text": "Sample R Code\nThe code below goes through an exercise estimating with various panel data approaches under scenarios where the unobserved effect is or is not correlated with the main independent variable, and whether strict exogeneity holds.\n EC655panel.R"
  },
  {
    "objectID": "slides/paneldata/index.html#model-4",
    "href": "slides/paneldata/index.html#model-4",
    "title": "E655 - Econometrics",
    "section": "Model",
    "text": "Model\n\nData is generated for three individuals over 10 time periods\nFor each individual the outcome is negatively related to \\(x_it\\)\nThe exact function is\n\n\\[y_{it} = 9 - x_{it} + a_{i} + u_{it}\\]\n\nBut there is an unobserved effect \\(a_{i}\\) that is positively correlated with \\(x_{it}\\)\nThis creates three distinct clusters of points\n\nEach individual has a different colour"
  },
  {
    "objectID": "slides/paneldata/index.html#bias-with-pooled-ols",
    "href": "slides/paneldata/index.html#bias-with-pooled-ols",
    "title": "E655 - Econometrics",
    "section": "Bias with Pooled OLS",
    "text": "Bias with Pooled OLS\n\nSuppose we ignore the unobserved individual effect\nAs illustrated in the graph below, the estimated slope is positive\nThis is because \\(a_{i}\\) is positively correlated with \\(x_{it}\\) and we have omitted variables bias"
  },
  {
    "objectID": "slides/paneldata/index.html#background",
    "href": "slides/paneldata/index.html#background",
    "title": "E655 - Econometrics",
    "section": "Background",
    "text": "Background\n\nThe key to this model is assumption that \\(a_{i}\\) is correlated with \\(\\mathbf{x_{it}}\\)\nExample: Effect of school size on achievement\n\nOutcome is student achievement\nMain independent variable is school size\nThere is unobserved school quality\nSchools that are larger may be better quality\nIf school size and quality affect achievement, this causes bias\n\nThis is illustrated graphically below using a general example"
  },
  {
    "objectID": "slides/paneldata/index.html#background-1",
    "href": "slides/paneldata/index.html#background-1",
    "title": "E655 - Econometrics",
    "section": "Background",
    "text": "Background\n\nData is generated for three individuals over 10 time periods\nFor each individual the outcome is negatively related to \\(x_it\\)\nThe exact function is\n\n\\[y_{it} = 9 - x_{it} + a_{i} + u_{it}\\]\n\nBut there is an unobserved effect \\(a_{i}\\) that is positively correlated with \\(x_{it}\\)\nThis creates three distinct clusters of points\n\nEach individual has a different colour"
  },
  {
    "objectID": "slides/paneldata/index.html#graphical-illustration-1",
    "href": "slides/paneldata/index.html#graphical-illustration-1",
    "title": "E655 - Econometrics",
    "section": "Graphical Illustration",
    "text": "Graphical Illustration"
  },
  {
    "objectID": "slides/paneldata/index.html#fixed-effects-model",
    "href": "slides/paneldata/index.html#fixed-effects-model",
    "title": "E655 - Econometrics",
    "section": "Fixed Effects Model",
    "text": "Fixed Effects Model\n\nThe Fixed Effects model is a special case of the unobserved effects model\nIt assumes that the unobserved effect is correlated with the independent variables\nThen makes an adjustment to control for the unobserved effect\nThe unobserved effects model is\n\n\\[y_{it} =  \\mathbf{x_{it}}\\boldsymbol{\\beta} + a_{i} + u_{it}\\]\n\nAssume this is a structural model and we want to estimate \\(\\boldsymbol{\\beta}\\)"
  },
  {
    "objectID": "slides/paneldata/index.html#fixed-effects-model-1",
    "href": "slides/paneldata/index.html#fixed-effects-model-1",
    "title": "E655 - Econometrics",
    "section": "Fixed Effects Model",
    "text": "Fixed Effects Model\n\nA necessary assumption is Strict Exogeneity\n\n\\[E(\\mathbf{x_{is}'}u_{it}) = 0 \\text{ for all } s = 1,...,T \\]\n\nIn words, this means that all lags and leads of \\(u_{it}\\) are uncorrelated with \\(\\mathbf{x_{it}}\\)\nThis is an extension of what we learned in instrumental variables\n\nThe exogeneity extends to all time periods\nNot just the current time period"
  },
  {
    "objectID": "slides/paneldata/index.html#fixed-effects-model-2",
    "href": "slides/paneldata/index.html#fixed-effects-model-2",
    "title": "E655 - Econometrics",
    "section": "Fixed Effects Model",
    "text": "Fixed Effects Model\n\nWith strict exogeneity, we need an estimator that controls for \\(a_{i}\\)\nOne way to do this is the Within Transformation\nTo do this, compute the mean over time for each variable for each individual\n\n\\[\\bar{y}_{i} = \\frac{1}{T}\\sum_{t=1}^{T}y_{it}\\]\n\\[\\bar{x}_{i} = \\frac{1}{T}\\sum_{t=1}^{T}x_{it}\\]"
  },
  {
    "objectID": "slides/paneldata/index.html#fixed-effects-model-3",
    "href": "slides/paneldata/index.html#fixed-effects-model-3",
    "title": "E655 - Econometrics",
    "section": "Fixed Effects Model",
    "text": "Fixed Effects Model\n\nThen subtract the within unit mean from each observation\n\n\\[y_{ij} - \\bar{y}_{i} = (\\mathbf{x_{ij}} - \\mathbf{\\bar{x}_{i}})\\boldsymbol{\\beta} + a_{i} - a_{i} + u_{ij} - \\bar{u}_{i}\\] \\[y_{it} - \\bar{y}_{i} = (\\mathbf{x_{it}} - \\mathbf{\\bar{x}_{i}})\\boldsymbol{\\beta}   + u_{it} - \\bar{u}_{i}\\] \\[y_{it}^{*} = \\mathbf{x_{it}}^{*}\\boldsymbol{\\beta}   + u_{it}^{*}\\]\n\nNotice that this transformed model does not depend on \\(a_{i}\\)\nWe can use regression on this transformed model to get the slope vector\n\n\\[\\boldsymbol{\\beta}_{fe} = E[\\mathbf{x_{it}^{*}}'\\mathbf{x_{it}^{*}}]^{-1}E[\\mathbf{x_{it}^{*}}'y_{it}^{*}]\\]"
  },
  {
    "objectID": "slides/paneldata/index.html#fixed-effects-model-4",
    "href": "slides/paneldata/index.html#fixed-effects-model-4",
    "title": "E655 - Econometrics",
    "section": "Fixed Effects Model",
    "text": "Fixed Effects Model\n\nSince \\(a_{i}\\) does not vary across \\(j\\), \\(a_{i}\\) is eliminated when we subtract the means\nIf we estimate the equation above by OLS, we get the Fixed Effects Estimator \\[\\boldsymbol{\\hat{\\beta}_{fe}} = \\mathbf{(X^{*'} X^{*})^{-1}X^{*'} Y^{*}}\\] ## Unobserved Effects Model\nLike regular regression model, but with unobserved variable that only varies over individuals\nThe regression model is \\[y_{it} =  \\mathbf{x_{it}}\\boldsymbol{\\beta} +a_{i} + u_{it}\\]\n\n\\(\\mathbf{x_{ij}}\\) contains a constant\n\\(a_{i}\\) is the unobserved effect\n\nAssume we are not interested in the effect of \\(a_{i}\\) on \\(y_{ij}\\)\n\nUsually it is not observed, or unmeasurable anyway\nThis is why it is not written with a parameter\n\nSeveral models we can use to estimate the parameters \\(\\boldsymbol{\\beta}\\)\n\nDepends on assumption about relationship between \\(\\mathbf{x_{ij}}\\) and \\(a_{i}\\)"
  },
  {
    "objectID": "slides/paneldata/index.html#estimation-3",
    "href": "slides/paneldata/index.html#estimation-3",
    "title": "E655 - Econometrics",
    "section": "Estimation",
    "text": "Estimation\n\nIf we estimate by OLS, we get the Fixed Effects Estimator\n\n\\[\\boldsymbol{\\hat{\\beta}_{fe}} = \\mathbf{(X^{*'} X^{*})^{-1}X^{*'} Y^{*}}\\]\n\nFor each cross-sectional observation we have\n\n\\[\\mathbf{X_{i}} = \\begin{bmatrix} x_{i1}^{1}  &x_{i1}^{2}&\\ldots &x_{i1}^{K}\\\\\n                                x_{i2}^{1} &x_{i2}^{2}&\\ldots &x_{i2}^{K} \\\\\n                                \\vdots &\\ddots & \\ldots & \\vdots \\\\\n                                x_{iJ}^{1}&x_{iJ}^{2}&\\ldots &x_{iJ}^{K} \\\\\n                                \\end{bmatrix} ,  \\mathbf{\\bar{X}_{i}}  =\\begin{bmatrix} \\bar{x_{i}}^{1}  &\\bar{x_{i}}^{2}&\\ldots &\\bar{x_{i}}^{K}\\\\\n                                \\bar{x_{i}}^{1}  &\\bar{x_{i}}^{2}&\\ldots &\\bar{x_{i}}^{K} \\\\\n                                \\vdots &\\ddots & \\ldots & \\vdots \\\\\n                                \\bar{x_{i}}^{1}  &\\bar{x_{i}}^{2}&\\ldots &\\bar{x_{i}}^{K} \\\\\n                                \\end{bmatrix}\\]"
  },
  {
    "objectID": "slides/paneldata/index.html#estimation-4",
    "href": "slides/paneldata/index.html#estimation-4",
    "title": "E655 - Econometrics",
    "section": "Estimation",
    "text": "Estimation\n\nAfter the within transformation it looks like\n\n\\[\\mathbf{X^{*}_{i}} = \\begin{bmatrix} (x_{i1}^{1} - \\bar{x}_{i}^{1}) &(x_{i1}^{2}-\\bar{x}_{i}^{2})&\\ldots &(x_{i1}^{K}-\\bar{x}_{i}^{K})\\\\\n                                (x_{i2}^{1}-\\bar{x}_{i}^{1}) &(x_{i2}^{2}-\\bar{x}_{i}^{2})&\\ldots &(x_{i2}^{K}-\\bar{x}_{i}^{K}) \\\\\n                                \\vdots &\\ddots & \\ldots & \\vdots \\\\\n                                (x_{iJ}^{1} -\\bar{x}_{i}^{1})&(x_{iJ}^{2}-\\bar{x}_{i}^{2})&\\ldots &(x_{iJ}^{K}-\\bar{x}_{i}^{K}) \\\\\n                                \\end{bmatrix} =  \\mathbf{X_{i}}  - \\mathbf{\\bar{X}_{i}}\\]\n\nThese matrices are then stacked on top of each other\n\n\\[\\mathbf{X^{*}} = \\begin{bmatrix} \\mathbf{X^{*}_{1}} \\\\ \\mathbf{X^{*}_{2}} \\\\ \\vdots \\\\ \\mathbf{X^{*}_{N}}  \\end{bmatrix}\\]\n\nIf strict exogeneity holds, then \\(\\boldsymbol{\\hat{\\beta}_{fe}}\\) consistently estimates \\(\\boldsymbol{\\beta}\\)"
  },
  {
    "objectID": "slides/paneldata/index.html#estimation-5",
    "href": "slides/paneldata/index.html#estimation-5",
    "title": "E655 - Econometrics",
    "section": "Estimation",
    "text": "Estimation\n\nThe cluster- robust estimator for the variance covariance matrix for \\(\\boldsymbol{\\hat{\\beta}_{fe}}\\) is\n\n\\[\\hat{var}(\\boldsymbol{\\hat{\\beta}_{fe}})= \\mathbf{(X^{*'}_{i} X^{*}_{i})^{-1}} \\left ( \\sum_{i=1}^{n} \\mathbf{X^{*'}_{i} \\hat{u}_{i}^{*} \\hat{u}_{i}^{*'}X^{*}_{i}}\\right ) \\mathbf{(X^{*'}_{i} X^{*}_{i})^{-1}}\\]\n\nThis estimator is robust to both heteroskedasticity and serial correlation\n\nSerial correlation is an issue because the data have a time element\nHeteroskedasticity can happen because the data have a cross-sectional element\n\nIf error has no heteroskedasticity and no serial correlation, you can simplify this variance estimator"
  },
  {
    "objectID": "slides/paneldata/index.html#dummy-variable-regression",
    "href": "slides/paneldata/index.html#dummy-variable-regression",
    "title": "E655 - Econometrics",
    "section": "Dummy Variable Regression",
    "text": "Dummy Variable Regression\n\nA second way to control for the unobserved effect is the Dummy Variable Regression\nIn this model, include a dummy variable for each cross-sectional unit\n\nThe interpretation of \\(a_{i}\\) changes\nIt is now considered a parameter and not a variable\nIn practice it does not matter because it produces the same results as within estimator\n\nThe regression is\n\n\\[y_{it} =  \\mathbf{x_{it}}\\boldsymbol{\\beta} + \\mathbf{D_{i}}\\boldsymbol{\\alpha} + u_{it}\\]\n\n\\(D_{i}\\) is a vector of dummy variables indicating the cross-sectional unit, and \\(\\alpha\\) is an \\(N-1\\) vector\n\nExclude 1 of the dummies to identify the model"
  },
  {
    "objectID": "slides/paneldata/index.html#graphical-illustration-2",
    "href": "slides/paneldata/index.html#graphical-illustration-2",
    "title": "E655 - Econometrics",
    "section": "Graphical Illustration",
    "text": "Graphical Illustration"
  },
  {
    "objectID": "slides/paneldata/index.html#considerations",
    "href": "slides/paneldata/index.html#considerations",
    "title": "E655 - Econometrics",
    "section": "Considerations",
    "text": "Considerations\n\nThe within estimator wipes out the unobserved effect\nBut it also wipes out any time-invariant variables\n\nSo you cannot add them to the regression\n\nIt also reduces the variation in the data\n\nSo it is less efficient than OLS if the unobserved effect is not related to \\(x\\)"
  },
  {
    "objectID": "slides/paneldata/index.html#dummy-variable-regression-1",
    "href": "slides/paneldata/index.html#dummy-variable-regression-1",
    "title": "E655 - Econometrics",
    "section": "Dummy Variable Regression",
    "text": "Dummy Variable Regression\n\nApply regression to the model above to get the dummy variable regression\nEstimate by OLS\nThe vector \\(\\boldsymbol{\\hat{\\beta}_{DVR}}\\) will be identical to \\(\\boldsymbol{\\hat{\\beta}_{fe}}\\)\nThe variance estimator is also the same as the within estimator\nFor a couple of reasons we usually do not use the DVR approach\n\nIf \\(N\\) is large, it takes forever to estimate\nWe do not care about \\(a_{i}\\) normally\nThe estimator for fixed effects is not consistent as \\(N \\rightarrow \\infty\\)"
  },
  {
    "objectID": "slides/paneldata/index.html#assumptions-of-random-effects",
    "href": "slides/paneldata/index.html#assumptions-of-random-effects",
    "title": "E655 - Econometrics",
    "section": "Assumptions of Random Effects",
    "text": "Assumptions of Random Effects\n\nTo use this method, we need to make a series of assumptions\n\n\n\\(E(u_{it}|\\mathbf{x_{i}}) = 0\\)\n\\(E(u_{it}u_{is}|\\mathbf{x_{i}}) = 0\\) for \\(t \\neq s\\)\n\\(E(u_{it}^{2}|\\mathbf{x_{i}}) = \\sigma^{2}_{u}\\)\n\\(E(a_{i}|\\mathbf{x_{i}}) = 0\\)\n\\(E(a_{i}^2|\\mathbf{x_{i}}) = \\sigma^{2}_{a}\\)\n\\(E(a_{i}u_{it}|\\mathbf{x_{i}}) = 0\\)\n\n\nThese state that the unobserved effect is uncorrelated with \\(\\mathbf{x_{it}}\\) and the error\nAlso that the error is homoskedastic and has no serial correlation\nResearchers are usually skeptical of these assumptions\n\nSo this method is not used much in economics"
  },
  {
    "objectID": "slides/paneldata/index.html#fixed-effect-or-random-effects",
    "href": "slides/paneldata/index.html#fixed-effect-or-random-effects",
    "title": "E655 - Econometrics",
    "section": "Fixed Effect or Random Effects",
    "text": "Fixed Effect or Random Effects\n\nDepends on assumptions about the error\nFixed effects is valid in either case, but is less efficient if \\(a_{i}\\) is uncorrelated with \\(\\mathbf{x_{it}}\\)\nEconomists tend to value robustness over efficiency\nSo fixed effects is almost always used\nTo test between them, there is a Hausman test you can use\nBut again, fixed effects is usually the default"
  },
  {
    "objectID": "slides/limdep/index.html#introduction",
    "href": "slides/limdep/index.html#introduction",
    "title": "E655 - Econometrics",
    "section": "Introduction",
    "text": "Introduction\n\nMany economic outcomes are qualitative in nature\n\nGrouped into categories\n\nWork or not\nDrive, take bus, cycle to work\nNumber of visits to Doctor\n\n\nPeople sometimes use alternative methods in this context\n\nThough linear regression does still work in many cases\n\nIn this section we cover models for these types of variables"
  },
  {
    "objectID": "slides/limdep/index.html#binary-choice",
    "href": "slides/limdep/index.html#binary-choice",
    "title": "E655 - Econometrics",
    "section": "Binary Choice",
    "text": "Binary Choice\n\nIn models with more variables and where they are continuous\n\n\\[Pr(y=1|\\mathbf{x}) = \\Phi \\left(\\frac{\\mathbf{x}\\boldsymbol{\\beta}}{\\sigma^{2}_{e}} \\right)\\]\n\nThe marginal effect for continuous variable \\(x_{j}\\)\n\n\\[\\frac{\\partial Pr(y=1|\\mathbf{x})}{\\partial x_{j}} = \\phi \\left(\\frac{\\mathbf{x}\\boldsymbol{\\beta}}{\\sigma^{2}_{e}} \\right) \\frac{\\beta_{j}}{\\sigma^{2}_{e}}\\]\n\nThis is a function of the entire vector \\(\\mathbf{x}\\)\n\nYou need to specify their values to get the marginal effect\nNormally people hold them at the mean\nIn theory you can get a distribution of marginal effects"
  },
  {
    "objectID": "slides/limdep/index.html#binary-choice-1",
    "href": "slides/limdep/index.html#binary-choice-1",
    "title": "E655 - Econometrics",
    "section": "Binary Choice",
    "text": "Binary Choice\nLogit Model\n\nAssuming \\(\\eta \\sim \\text{Logistic}(0,\\sigma^{2}_{\\eta})\\) leads to the Logit Model\n\n\\[Pr(y=1|w) = \\Lambda \\left(\\frac{\\beta_{0} + \\beta_{1}w}{\\sigma^{2}_{e}} \\right)\\]\n\nwhere\n\\[\\Lambda (z) =  \\frac{e^z}{1+e^z}\\]\nAgain, because \\(\\Lambda(.)\\) is a CDF, \\(Pr(y=1|w)\\) is always between 0 and 1"
  },
  {
    "objectID": "slides/limdep/index.html#binary-choice-2",
    "href": "slides/limdep/index.html#binary-choice-2",
    "title": "E655 - Econometrics",
    "section": "Binary Choice",
    "text": "Binary Choice\n\nThe observed difference in probabilities is\n\\[Pr(y=1|w = 1) - Pr(y=1|w=0)\\] \\[=  \\Lambda \\left(\\frac{\\beta_{0} + \\beta_{1}}{\\sigma^{2}_{\\eta}} \\right) - \\Lambda \\left(\\frac{\\beta_{0}}{\\sigma^{2}_{\\eta}}  \\right)\\]\nIn models with more variables and where they are continuous\n\\[Pr(y=1|\\mathbf{x}) = \\Lambda \\left(\\frac{\\mathbf{x}\\boldsymbol{\\beta}}{\\sigma^{2}_{\\eta}} \\right)\\]\nThe marginal effect for continuous variable \\(x_{j}\\)\n\\[\\frac{\\partial Pr(y=1|\\mathbf{x})}{\\partial x_{j}} = \\Lambda \\left(\\frac{\\mathbf{x}\\boldsymbol{\\beta}}{\\sigma^{2}_{\\eta}} \\right) \\left( 1-\\Lambda \\left(\\frac{\\mathbf{x}\\boldsymbol{\\beta}}{\\sigma^{2}_{\\eta}} \\right) \\right)\\frac{\\beta_{j}}{\\sigma^{2}_{\\eta}}\\]"
  },
  {
    "objectID": "slides/limdep/index.html#binary-choice-3",
    "href": "slides/limdep/index.html#binary-choice-3",
    "title": "E655 - Econometrics",
    "section": "Binary Choice",
    "text": "Binary Choice\nEstimation of Probit and Logit\n\nBoth models usually estimated by Maximum Likelihood\nMethod maximizes the probability of getting our sample by choosing parameters\n\nTheLikelihood Function is the function of the parameters given the data\n\nThe probability distribution of \\(y_i\\) is\n\\[f(y_i| \\mathbf{x_{i}};\\boldsymbol{\\beta})= F \\left(\\frac{\\mathbf{x_{i}}\\boldsymbol{\\beta}}{\\sigma^{2}_{\\eta}} \\right)^{y_i} \\left(1- F \\left(\\frac{\\mathbf{x_{i}}\\boldsymbol{\\beta}}{\\sigma^{2}_{\\eta}} \\right) \\right) ^{1-y_{i}}\\]\nThe joint probability of observing the all the \\(y_{i}\\) in the data is\n\\[f(\\mathbf{y}| \\mathbf{X};\\boldsymbol{\\beta})=\\Pi_{i=1}^n F \\left(\\frac{\\mathbf{x_{i}}\\boldsymbol{\\beta}}{\\sigma^{2}_{\\eta}} \\right)^{y_{i}}  \\left(1- F \\left(\\frac{\\mathbf{x_{i}}\\boldsymbol{\\beta}}{\\sigma^{2}_{\\eta}} \\right) \\right) ^{1-y_{i}}\\]"
  },
  {
    "objectID": "slides/limdep/index.html#binary-choice-4",
    "href": "slides/limdep/index.html#binary-choice-4",
    "title": "E655 - Econometrics",
    "section": "Binary Choice",
    "text": "Binary Choice\n\nThe Likelihood Function recasts as a function of the parameters given the data\n\\[\\mathcal{L}(\\boldsymbol{\\beta}|\\mathbf{y}, \\mathbf{X})=\\Pi_{i=1}^n F \\left(\\frac{\\mathbf{x_{i}}\\boldsymbol{\\beta}}{\\sigma^{2}_{\\eta}} \\right)^{y_{i}}  \\left(1- F \\left(\\frac{\\mathbf{x_{i}}\\boldsymbol{\\beta}}{\\sigma^{2}_{\\eta}} \\right) \\right) ^{1-y_{i}}\\]\nBoth models usually estimated by Maximum Likelihood\nMethod maximizes the joint probability of \\(y\\) values conditional on \\(\\mathbf{x}\\)\n\nThis is called the Likelihood Function\n\nIn the case of a binary \\(y\\), the likelihood function is\n\\[f[y| \\mathbf{x};\\boldsymbol{\\beta}]=P[Y_{1} = y_{1}, Y_{2} = y_{2}, \\ldots, Y_{n} = y_{n}|\\mathbf{x_{i}};\\boldsymbol{\\beta}]\\] \\[=\\Pi_{y_{i}=1}F \\left(\\frac{\\mathbf{x_{i}}\\boldsymbol{\\beta}}{\\sigma^{2}_{\\eta}} \\right) \\Pi_{y_{i}=0} \\left[1-F \\left(\\frac{\\mathbf{x_{i}}\\boldsymbol{\\beta}}{\\sigma^{2}_{\\eta}} \\right) \\right]\\] \\[=\\Pi_{i=1}^{n} F \\left(\\frac{\\mathbf{x_{i}}\\boldsymbol{\\beta}}{\\sigma^{2}_{\\eta}} \\right)^{y_{i}} \\left[1-F \\left(\\frac{\\mathbf{x_{i}}\\boldsymbol{\\beta}}{\\sigma^{2}_{\\eta}} \\right)\\right] ^{1-y_{i}}\\]"
  },
  {
    "objectID": "slides/limdep/index.html#binary-choice-5",
    "href": "slides/limdep/index.html#binary-choice-5",
    "title": "E655 - Econometrics",
    "section": "Binary Choice",
    "text": "Binary Choice\n\nResearchers usually focus on the log of the likelihood instead\n\nIt is a monotonic (increasing) transformation of the likelihood\nThe same parameter vector solves both versions\nLog likelihoods are easier to work with\n\nLog Likelihood \\[ln\\mathcal{L}(\\boldsymbol{\\beta}|\\mathbf{y}, \\mathbf{X})= \\sum_{i=1}^{N}\\{ y_{i}lnF \\left(\\frac{\\mathbf{x_{i}}\\boldsymbol{\\beta}}{\\sigma^{2}_{\\eta}} \\right)+  (1-y_{i})ln (1-F \\left(\\frac{\\mathbf{x_{i}}\\boldsymbol{\\beta}}{\\sigma^{2}_{\\eta}} \\right))  \\}\\]\nTo solve this equation, you need numerical methods\n\nA grid search algorithm that finds the maximum value"
  },
  {
    "objectID": "slides/limdep/index.html#binary-choice-6",
    "href": "slides/limdep/index.html#binary-choice-6",
    "title": "E655 - Econometrics",
    "section": "Binary Choice",
    "text": "Binary Choice\n\nIn ML environments, the estimated variance of \\(\\boldsymbol{\\hat{\\beta}}\\) is estimated as the negative of the expected value of the Hessian (information matrix) \\[\\hat{Var}(\\boldsymbol{\\hat{\\beta}}) = -E[(\\frac{\\partial^2 lnL}{\\partial\\boldsymbol{\\hat{\\beta}} \\partial \\boldsymbol{\\hat{\\beta}^{'}}})^{-1}]\\] \\[= (\\sum_{i=1}^{n} \\frac{f(\\mathbf{x_{i}^{'}}\\boldsymbol{\\hat{\\beta}})^2 }{ F(\\mathbf{x_{i}^{'}}\\boldsymbol{\\hat{\\beta}})(1- F(\\mathbf{x_{i}^{'}}\\boldsymbol{\\hat{\\beta}}) ) }  \\mathbf{x_{i}x_{i}^{'}} )^{-1}\\]\nwhere \\(F(.)\\) is either the Normal or Logistic CDF, and \\(f(.)\\) is the associated PDF\n\nHypothesis Testing in Probit and Logit\n\nSimple tests for coefficient significance is done by the usual \\(t\\)-test method\n\nAssume \\(\\boldsymbol{\\hat{\\beta}}\\) has normal distribution (asymptotically)\nTest statistic \\(Z = \\frac{\\hat{\\beta}_{k}}{\\hat{SE}(\\hat{\\beta}_{k})}\\)"
  },
  {
    "objectID": "slides/limdep/index.html#binary-choice-7",
    "href": "slides/limdep/index.html#binary-choice-7",
    "title": "E655 - Econometrics",
    "section": "Binary Choice",
    "text": "Binary Choice\n\nMore complicated tests done using one of 3 methods:\n\nLikelihood Ratio (LR) Test\n\nTest statistic \\(LR = 2[ln\\hat{L}_{U} - ln\\hat{L}_{R}]\\)\n\\(ln\\hat{L}_{R}\\) is log likelihood evaluated at restricted parameter vector\n\nWald (W) Test\n\nTest statistic \\(W = \\hat{g}^{'}[\\hat{G}\\hat{Var}(\\boldsymbol{\\hat{\\beta}})\\hat{G}^{'}]\\hat{g}\\)\n\\(\\hat{g}\\) is a vector of restrictions evaluated at \\(\\boldsymbol{\\hat{\\beta}}\\)\n\\(\\hat{G}\\) is the derivative of a vector of restrictions evaluated at \\(\\boldsymbol{\\hat{\\beta}}\\)\n\nLagrange Multiplier (LM) Test\n\nTest statistic \\(LM = \\hat{d}^{'}[\\hat{Var}(\\boldsymbol{\\hat{\\beta}})]\\hat{d}\\)\n\\(\\hat{d}\\) is the derivative of \\(lnL\\) evaluated at restricted \\(\\boldsymbol{\\hat{\\beta}}\\)\n\n\nRestrictions can be linear or non-linear"
  },
  {
    "objectID": "slides/limdep/index.html#binary-choice-8",
    "href": "slides/limdep/index.html#binary-choice-8",
    "title": "E655 - Econometrics",
    "section": "Binary Choice",
    "text": "Binary Choice\n\nSource: Kennedy (2008)"
  },
  {
    "objectID": "slides/limdep/index.html#binary-choice-9",
    "href": "slides/limdep/index.html#binary-choice-9",
    "title": "E655 - Econometrics",
    "section": "Binary Choice",
    "text": "Binary Choice\nGoodness of Fit in Probit and Logit\n\nConfusion Matrix\n\n\n\n\nActual\n\n\n\n\n\n\nPredicted\n0\n1\nTotal\n\n\n0\n# Correct 0\n# Incorrect 1\n# Pred 0\n\n\n1\n# Incorrect 0\n#Correct 1\n# Pred 1\n\n\nTotal\n# True 0\n# True 1\n\n\n\n\nPseudo-\\(R^{2}\\)\n\nMcFadden \\(\\rightarrow\\) \\(R^{2} = 1 - \\frac{ln\\hat{L}_{U}}{ln\\hat{L}_{0}}\\)\n\n\\(ln\\hat{L}_{0}\\) is log-likelihood with no explanatory variables\n\nOthers are possible, but goodness of fit is not incredibly important"
  },
  {
    "objectID": "slides/limdep/index.html#binary-choice-10",
    "href": "slides/limdep/index.html#binary-choice-10",
    "title": "E655 - Econometrics",
    "section": "Binary Choice",
    "text": "Binary Choice\n\nSource: Kennedy (2008)"
  },
  {
    "objectID": "slides/limdep/index.html#binary-choice-11",
    "href": "slides/limdep/index.html#binary-choice-11",
    "title": "E655 - Econometrics",
    "section": "Binary Choice",
    "text": "Binary Choice\nGoodness of Fit in Probit and Logit\n\nConfusion Matrix\n\n\n\n\nActual\n\n\n\n\n\n\nPredicted\n0\n1\nTotal\n\n\n0\n# Correct 0\n# Incorrect 1\n# Pred 0\n\n\n1\n# Incorrect 0\n#Correct 1\n# Pred 1\n\n\nTotal\n# True 0\n# True 1\n\n\n\n\nPseudo-\\(R^{2}\\)\n\nMcFadden \\(\\rightarrow\\) \\(R^{2} = 1 - \\frac{ln\\hat{L}_{U}}{ln\\hat{L}_{0}}\\)\n\n\\(ln\\hat{L}_{0}\\) is log-likelihood with no explanatory variables\n\nOthers are possible, but goodness of fit is not incredibly important"
  },
  {
    "objectID": "slides/limdep/index.html#binary-choice-12",
    "href": "slides/limdep/index.html#binary-choice-12",
    "title": "E655 - Econometrics",
    "section": "Binary Choice",
    "text": "Binary Choice\n\nMore complicated tests done using one of 3 methods:\n\nLikelihood Ratio (LR) Test\n\nTest statistic \\(LR = 2[ln\\hat{L}_{U} - ln\\hat{L}_{R}]\\)\n\\(ln\\hat{L}_{R}\\) is log likelihood evaluated at restricted parameter vector\n\nWald (W) Test\n\nTest statistic \\(W = \\hat{g}^{'}[\\hat{G}\\hat{Var}(\\boldsymbol{\\hat{\\beta}})\\hat{G}^{'}]\\hat{g}\\)\n\\(\\hat{g}\\) is a vector of restrictions evaluated at \\(\\boldsymbol{\\hat{\\beta}}\\)\n\\(\\hat{G}\\) is the derivative of a vector of restrictions evaluated at \\(\\boldsymbol{\\hat{\\beta}}\\)\n\nLagrange Multiplier (LM) Test\n\nTest statistic \\(LM = \\hat{d}^{'}[\\hat{Var}(\\boldsymbol{\\hat{\\beta}})]\\hat{d}\\)\n\\(\\hat{d}\\) is the derivative of \\(lnL\\) evaluated at restricted \\(\\boldsymbol{\\hat{\\beta}}\\)\n\n\nRestrictions can be linear or non-linear"
  },
  {
    "objectID": "slides/limdep/index.html#binary-choice-13",
    "href": "slides/limdep/index.html#binary-choice-13",
    "title": "E655 - Econometrics",
    "section": "Binary Choice",
    "text": "Binary Choice\n\nSource: Kennedy (2008)"
  },
  {
    "objectID": "slides/limdep/index.html#binary-choice-14",
    "href": "slides/limdep/index.html#binary-choice-14",
    "title": "E655 - Econometrics",
    "section": "Binary Choice",
    "text": "Binary Choice\nGoodness of Fit in Probit and Logit\n\nConfusion Matrix\n\n\n\n\nActual\n\n\n\n\n\n\nPredicted\n0\n1\nTotal\n\n\n0\n# Correct 0\n# Incorrect 1\n# Pred 0\n\n\n1\n# Incorrect 0\n#Correct 1\n# Pred 1\n\n\nTotal\n# True 0\n# True 1\n\n\n\n\nPseudo-\\(R^{2}\\)\n\nMcFadden \\(\\rightarrow\\) \\(R^{2} = 1 - \\frac{ln\\hat{L}_{U}}{ln\\hat{L}_{0}}\\)\n\n\\(ln\\hat{L}_{0}\\) is log-likelihood with no explanatory variables\n\nOthers are possible, but goodness of fit is not incredibly important"
  },
  {
    "objectID": "slides/limdep/index.html#binary-choice-15",
    "href": "slides/limdep/index.html#binary-choice-15",
    "title": "E655 - Econometrics",
    "section": "Binary Choice",
    "text": "Binary Choice\n\nSource: Kennedy (2008)"
  },
  {
    "objectID": "slides/limdep/index.html#binary-choice-16",
    "href": "slides/limdep/index.html#binary-choice-16",
    "title": "E655 - Econometrics",
    "section": "Binary Choice",
    "text": "Binary Choice\nGoodness of Fit in Probit and Logit\n\nConfusion Matrix\n\n\n\n\nActual\n\n\n\n\n\n\nPredicted\n0\n1\nTotal\n\n\n0\n# Correct 0\n# Incorrect 1\n# Pred 0\n\n\n1\n# Incorrect 0\n#Correct 1\n# Pred 1\n\n\nTotal\n# True 0\n# True 1\n\n\n\n\nPseudo-\\(R^{2}\\)\n\nMcFadden \\(\\rightarrow\\) \\(R^{2} = 1 - \\frac{ln\\hat{L}_{U}}{ln\\hat{L}_{0}}\\)\n\n\\(ln\\hat{L}_{0}\\) is log-likelihood with no explanatory variables\n\nOthers are possible, but goodness of fit is not incredibly important"
  },
  {
    "objectID": "slides/limdep/index.html#binary-choice-17",
    "href": "slides/limdep/index.html#binary-choice-17",
    "title": "E655 - Econometrics",
    "section": "Binary Choice",
    "text": "Binary Choice\nGoodness of Fit in Probit and Logit\n\nConfusion Matrix\n\n\n\n\nActual\n\n\n\n\n\n\nPredicted\n0\n1\nTotal\n\n\n0\n# Correct 0\n# Incorrect 1\n# Pred 0\n\n\n1\n# Incorrect 0\n#Correct 1\n# Pred 1\n\n\nTotal\n# True 0\n# True 1\n\n\n\n\nPseudo-\\(R^{2}\\)\n\nMcFadden \\(\\rightarrow\\) \\(R^{2} = 1 - \\frac{ln\\hat{L}_{U}}{ln\\hat{L}_{0}}\\)\n\n\\(ln\\hat{L}_{0}\\) is log-likelihood with no explanatory variables\n\nOthers are possible, but goodness of fit is not incredibly important"
  },
  {
    "objectID": "slides/limdep/index.html#binary-choice-18",
    "href": "slides/limdep/index.html#binary-choice-18",
    "title": "E655 - Econometrics",
    "section": "Binary Choice",
    "text": "Binary Choice\n\nResearchers usually focus on the log of the likelihood instead\n\nIt is a monotonic (increasing) transformation of the likelihood\nThe same parameter vector solves both versions\nLog likelihoods are easier to work with\n\nLog Likelihood \\[ln\\mathcal{L}(\\boldsymbol{\\beta}|\\mathbf{y}, \\mathbf{X})= \\sum_{i=1}^{N}\\{ y_{i}lnF \\left(\\frac{\\mathbf{x_{i}}\\boldsymbol{\\beta}}{\\sigma^{2}_{\\eta}} \\right)+  (1-y_{i})ln (1-F \\left(\\frac{\\mathbf{x_{i}}\\boldsymbol{\\beta}}{\\sigma^{2}_{\\eta}} \\right))  \\}\\]\nTo solve this equation, you need numerical methods\n\nA grid search algorithm that finds the maximum value"
  },
  {
    "objectID": "slides/limdep/index.html#binary-choice-19",
    "href": "slides/limdep/index.html#binary-choice-19",
    "title": "E655 - Econometrics",
    "section": "Binary Choice",
    "text": "Binary Choice\n\nIn ML environments, the estimated variance of \\(\\boldsymbol{\\hat{\\beta}}\\) is estimated as the negative of the expected value of the Hessian (information matrix) \\[\\hat{Var}(\\boldsymbol{\\hat{\\beta}}) = -E[(\\frac{\\partial^2 lnL}{\\partial\\boldsymbol{\\hat{\\beta}} \\partial \\boldsymbol{\\hat{\\beta}^{'}}})^{-1}]\\] \\[= (\\sum_{i=1}^{n} \\frac{f(\\mathbf{x_{i}^{'}}\\boldsymbol{\\hat{\\beta}})^2 }{ F(\\mathbf{x_{i}^{'}}\\boldsymbol{\\hat{\\beta}})(1- F(\\mathbf{x_{i}^{'}}\\boldsymbol{\\hat{\\beta}}) ) }  \\mathbf{x_{i}x_{i}^{'}} )^{-1}\\]\nwhere \\(F(.)\\) is either the Normal or Logistic CDF, and \\(f(.)\\) is the associated PDF\n\nHypothesis Testing in Probit and Logit\n\nSimple tests for coefficient significance is done by the usual \\(t\\)-test method\n\nAssume \\(\\boldsymbol{\\hat{\\beta}}\\) has normal distribution (asymptotically)\nTest statistic \\(Z = \\frac{\\hat{\\beta}_{k}}{\\hat{SE}(\\hat{\\beta}_{k})}\\)"
  },
  {
    "objectID": "slides/limdep/index.html#binary-choice-20",
    "href": "slides/limdep/index.html#binary-choice-20",
    "title": "E655 - Econometrics",
    "section": "Binary Choice",
    "text": "Binary Choice\n\nMore complicated tests done using one of 3 methods:\n\nLikelihood Ratio (LR) Test\n\nTest statistic \\(LR = 2[ln\\hat{L}_{U} - ln\\hat{L}_{R}]\\)\n\\(ln\\hat{L}_{R}\\) is log likelihood evaluated at restricted parameter vector\n\nWald (W) Test\n\nTest statistic \\(W = \\hat{g}^{'}[\\hat{G}\\hat{Var}(\\boldsymbol{\\hat{\\beta}})\\hat{G}^{'}]\\hat{g}\\)\n\\(\\hat{g}\\) is a vector of restrictions evaluated at \\(\\boldsymbol{\\hat{\\beta}}\\)\n\\(\\hat{G}\\) is the derivative of a vector of restrictions evaluated at \\(\\boldsymbol{\\hat{\\beta}}\\)\n\nLagrange Multiplier (LM) Test\n\nTest statistic \\(LM = \\hat{d}^{'}[\\hat{Var}(\\boldsymbol{\\hat{\\beta}})]\\hat{d}\\)\n\\(\\hat{d}\\) is the derivative of \\(lnL\\) evaluated at restricted \\(\\boldsymbol{\\hat{\\beta}}\\)\n\n\nRestrictions can be linear or non-linear"
  },
  {
    "objectID": "slides/limdep/index.html#binary-choice-21",
    "href": "slides/limdep/index.html#binary-choice-21",
    "title": "E655 - Econometrics",
    "section": "Binary Choice",
    "text": "Binary Choice\n\nSource: Kennedy (2008)"
  },
  {
    "objectID": "slides/limdep/index.html#binary-choice-22",
    "href": "slides/limdep/index.html#binary-choice-22",
    "title": "E655 - Econometrics",
    "section": "Binary Choice",
    "text": "Binary Choice\nGoodness of Fit in Probit and Logit\n\nConfusion Matrix\n\n\n\n\nActual\n\n\n\n\n\n\nPredicted\n0\n1\nTotal\n\n\n0\n# Correct 0\n# Incorrect 1\n# Pred 0\n\n\n1\n# Incorrect 0\n#Correct 1\n# Pred 1\n\n\nTotal\n# True 0\n# True 1\n\n\n\n\nPseudo-\\(R^{2}\\)\n\nMcFadden \\(\\rightarrow\\) \\(R^{2} = 1 - \\frac{ln\\hat{L}_{U}}{ln\\hat{L}_{0}}\\)\n\n\\(ln\\hat{L}_{0}\\) is log-likelihood with no explanatory variables\n\nOthers are possible, but goodness of fit is not incredibly important"
  },
  {
    "objectID": "slides/limdep/index.html#introduction-1",
    "href": "slides/limdep/index.html#introduction-1",
    "title": "E655 - Econometrics",
    "section": "Introduction",
    "text": "Introduction\n\nMany economic outcomes are qualitative in nature\n\nGrouped into categories\n\nWork or not\nDrive, take bus, cycle to work\nNumber of visits to Doctor\n\n\nPeople sometimes use alternative methods in this context\n\nThough linear regression does still work in many cases\n\nIn this section we cover models for these types of variables"
  },
  {
    "objectID": "slides/limdep/index.html#potential-outcomes",
    "href": "slides/limdep/index.html#potential-outcomes",
    "title": "E655 - Econometrics",
    "section": "Potential Outcomes",
    "text": "Potential Outcomes\n\nStart with the same potential outcomes setup\n\n\\(y_{1}\\) is the outcome with treatment\n\\(y_{0}\\) is the outcome without treatment\n\\(w\\) is a binary variable with 1 denoting treatment, and 0 no treatment\n\nWe observe \\((y, w)\\), where\n\n\\[y = y_{0} + (y_{1} -y_{0})w\\]\n\nKey difference here is that \\(y_{1}\\) and \\(y_{0}\\) are binary\n\n\\[y_{0} \\in \\{0,1\\}\\] \\[y_{1} \\in \\{0,1\\}\\]"
  },
  {
    "objectID": "slides/limdep/index.html#regression",
    "href": "slides/limdep/index.html#regression",
    "title": "E655 - Econometrics",
    "section": "Regression",
    "text": "Regression\n\nThe slope in a regression of \\(y\\) on \\(w\\) is\n\n\\[E(y|w=1) - E(y|w=0)\\] \\[= \\left [ E(y_{1}|w=1) - E(y_{0}|w=1) \\right ] + E(y_{0}|w=1) - E(y_{0}|w=0)\\]\n\nFirst part is ATT, second part is selection bias\nMechanics are the same as when we had continuous outcomes\nThere is a difference in interpretation\n\\(y\\) is a Bernoulli random variable,\n\n\\[E(y|w) = 1 \\times Pr(y=1|w) + 0 \\times Pr(y=0|w) = Pr(y=1|w)\\]"
  },
  {
    "objectID": "slides/limdep/index.html#regression-1",
    "href": "slides/limdep/index.html#regression-1",
    "title": "E655 - Econometrics",
    "section": "Regression",
    "text": "Regression\n\nSo you can restate the difference in observed means as\n\\[Pr(y=1|w=1) - Pr(y=1|w=0)\\] \\[= \\left [ Pr(y_{1}=1|w=1) - Pr(y_{0}=1|w=1) \\right ] + Pr(y_{0}=1|w=1) - Pr(y_{0}=1|w=0)\\]\nYou can interpret as the difference in response probabilities\nDifference in response probabilities is causal effect if\n\nIndependence of potential outcomes\nMean independence of potential outcomes\nConditional mean independence of potential outcomes"
  },
  {
    "objectID": "slides/limdep/index.html#issues-with-linear-probability-model",
    "href": "slides/limdep/index.html#issues-with-linear-probability-model",
    "title": "E655 - Econometrics",
    "section": "Issues with Linear Probability Model",
    "text": "Issues with Linear Probability Model\n\nMain problem is predicted probabilities can go outside [0,1] interval\n\nSome chance of nonesense probabilities\n\nMainly a problem of predictions\nIn most economic applications, we care about the slope\n\nSo nonsense predictions are not a big problem"
  },
  {
    "objectID": "slides/limdep/index.html#issues-with-linear-probability-model-1",
    "href": "slides/limdep/index.html#issues-with-linear-probability-model-1",
    "title": "E655 - Econometrics",
    "section": "Issues with Linear Probability Model",
    "text": "Issues with Linear Probability Model\n\nThe model errors are necessarily heteroskedasticity\nThe population least squares regression of \\(y\\) on \\(w\\) is\n\n\\[y = \\beta_{0} +  w\\beta_{1} + u\\]\n\\[Var[u|w] = Var[y|w] = E[y^2|w] - E[y|w]^2\\]\n\nSince \\(y\\) is binary, \\(y^2 = y\\), so\n\n\\[Var[y|w] = E[y|w] - E[y|w]^2\\]\n\\[= E[y |w] (1-E[y|w])\\]"
  },
  {
    "objectID": "slides/limdep/index.html#regression-2",
    "href": "slides/limdep/index.html#regression-2",
    "title": "E655 - Econometrics",
    "section": "Regression",
    "text": "Regression\n\nWhat the above says is that regression still works when the treatment is binary\nCausal effects depend on same assumptions as before\nTo estimate, use OLS regression of \\(y\\) on \\(w\\)\nWhen \\(y\\) is binary, this is called the Linear Probability Model"
  },
  {
    "objectID": "slides/limdep/index.html#issues-with-linear-probability-model-2",
    "href": "slides/limdep/index.html#issues-with-linear-probability-model-2",
    "title": "E655 - Econometrics",
    "section": "Issues with Linear Probability Model",
    "text": "Issues with Linear Probability Model\n\nFinally \\(E[y|w] = Pr(y=1|w)\\), so\n\n\\[Var[u|w] = Pr(y=1|w) (1-Pr(y=1|w))\\]\n\nThis means that the variance of the error term is a function of \\(w\\)\nIt introduces heteroskedasticity into the model\nSolution: use heteroskedasticity robust standard errors"
  },
  {
    "objectID": "slides/limdep/index.html#linear-probability-model",
    "href": "slides/limdep/index.html#linear-probability-model",
    "title": "E655 - Econometrics",
    "section": "Linear Probability Model",
    "text": "Linear Probability Model\nPotential Outcomes\n\nStart with the same potential outcomes setup\n\n\\(y_{1}\\) is the outcome with treatment\n\\(y_{0}\\) is the outcome without treatment\n\\(w\\) is a binary variable with 1 denoting treatment, and 0 no treatment\n\nWe observe \\((y, w)\\), where\n\n\\[y = y_{0} + (y_{1} -y_{0})w\\]\n\nKey difference here is that \\(y_{1}\\) and \\(y_{0}\\) are binary\n\n\\[y_{0} \\in \\{0,1\\}\\] \\[y_{1} \\in \\{0,1\\}\\]"
  },
  {
    "objectID": "slides/limdep/index.html#linear-probability-model-1",
    "href": "slides/limdep/index.html#linear-probability-model-1",
    "title": "E655 - Econometrics",
    "section": "Linear Probability Model",
    "text": "Linear Probability Model\nRegression\n\nThe slope in a regression of \\(y\\) on \\(w\\) is\n\n\\[E(y|w=1) - E(y|w=0)\\] \\[= \\left [ E(y_{1}|w=1) - E(y_{0}|w=1) \\right ] + E(y_{0}|w=1) - E(y_{0}|w=0)\\]\n\nFirst part is ATT, second part is selection bias\nMechanics are the same as when we had continuous outcomes\nThere is a difference in interpretation\n\\(y\\) is a Bernoulli random variable,\n\n\\[E(y|w) = 1 \\times Pr(y=1|w) + 0 \\times Pr(y=0|w) = Pr(y=1|w)\\]"
  },
  {
    "objectID": "slides/limdep/index.html#linear-probability-model-2",
    "href": "slides/limdep/index.html#linear-probability-model-2",
    "title": "E655 - Econometrics",
    "section": "Linear Probability Model",
    "text": "Linear Probability Model\n\nSo you can restate the difference in observed means as\n\\[Pr(y=1|w=1) - Pr(y=1|w=0)\\] \\[= \\left [ Pr(y_{1}=1|w=1) - Pr(y_{0}=1|w=1) \\right ] + Pr(y_{0}=1|w=1) - Pr(y_{0}=1|w=0)\\]\nYou can interpret as the difference in response probabilities\nDifference in response probabilities is causal effect if\n\nIndependence of potential outcomes\nMean independence of potential outcomes\nConditional mean independence of potential outcomes"
  },
  {
    "objectID": "slides/limdep/index.html#linear-probability-model-3",
    "href": "slides/limdep/index.html#linear-probability-model-3",
    "title": "E655 - Econometrics",
    "section": "Linear Probability Model",
    "text": "Linear Probability Model\n\nWhat the above says is that regression still works when the treatment is binary\nCausal effects depend on same assumptions as before\nTo estimate, use OLS regression of \\(y\\) on \\(w\\)\nWhen \\(y\\) is binary, this is called the Linear Probability Model"
  },
  {
    "objectID": "slides/limdep/index.html#linear-probability-model-4",
    "href": "slides/limdep/index.html#linear-probability-model-4",
    "title": "E655 - Econometrics",
    "section": "Linear Probability Model",
    "text": "Linear Probability Model\nIssues with Linear Probability Model\n\nMain problem is predicted probabilities can go outside [0,1] interval\n\nSome chance of nonesense probabilities\n\nMainly a problem of predictions\nIn most economic applications, we care about the slope\n\nSo nonsense predictions are not a big problem"
  },
  {
    "objectID": "slides/limdep/index.html#linear-probability-model-5",
    "href": "slides/limdep/index.html#linear-probability-model-5",
    "title": "E655 - Econometrics",
    "section": "Linear Probability Model",
    "text": "Linear Probability Model\n\nThe model exhibits heteroskedasticity\nThe population least squares regression of \\(y\\) on \\(w\\) is\n\n\\[y = \\beta_{0} +  w\\beta_{1} + u\\]\n\nThe conditional variance of the error is\n\n\\[Var[u|w] = Var[y|w] = E[y^2|w] - E[y|w]^2\\]\n\nSince \\(y\\) is binary, \\(y^2 = y\\), so\n\n\\[Var[y|w] = E[y|w] - E[y|w]^2\\]\n\\[= E[y |w] (1-E[y|w])\\]"
  },
  {
    "objectID": "slides/limdep/index.html#nonlinear-models",
    "href": "slides/limdep/index.html#nonlinear-models",
    "title": "E655 - Econometrics",
    "section": "Nonlinear Models",
    "text": "Nonlinear Models\nBackground\n\nIn some cases we may want to fix the predicted probability issue\n\nIf you are doing prediction, for example\n\nOne way to do this is to feed the model through a CDF\nThis is often motivated with an index model\nSuppose we model some latent variable \\(y^*\\) as\n\n\\[y^* = \\beta_{0} + \\beta_{1}w + e\\]\n\nIt is some underlying continuous outcome driving our decisions"
  },
  {
    "objectID": "slides/limdep/index.html#background",
    "href": "slides/limdep/index.html#background",
    "title": "E655 - Econometrics",
    "section": "Background",
    "text": "Background\n\nIn some cases we may want to fix the predicted probability issue\n\nIf you are doing prediction, for example\n\nOne way to do this is to feed the model through a CDF\nThis is often motivated with an index model\nSuppose we model some latent variable \\(y^*\\) as\n\n\\[y^* = \\beta_{0} + \\beta_{1}w + e\\]\n\nIt is some underlying continuous outcome driving our decisions"
  },
  {
    "objectID": "slides/limdep/index.html#nonlinear-models-1",
    "href": "slides/limdep/index.html#nonlinear-models-1",
    "title": "E655 - Econometrics",
    "section": "Nonlinear Models",
    "text": "Nonlinear Models\n\nIssue is we do not observe \\(y^*\\)\nInstead, we observe the binary \\(y\\) where\n\n\\[y = 1\\{y^*&gt;0\\}\\]\n\nPlugging the model into this\n\n\\[y = 1\\{\\beta_{0} + \\beta_{1}w +e&gt;0\\}\\]\n\nThe probability that \\(y=1\\) is therefore\n\n\\[Pr(y=1|w) = Pr(\\beta_{0} + \\beta_{1}w +e&gt;0 |w)\\]"
  },
  {
    "objectID": "slides/limdep/index.html#nonlinear-models-2",
    "href": "slides/limdep/index.html#nonlinear-models-2",
    "title": "E655 - Econometrics",
    "section": "Nonlinear Models",
    "text": "Nonlinear Models\n\nThe random component is \\(e\\), so rearrange to isolate it\n\n\\[Pr(y=1|w) = Pr(e &gt; -\\beta_{0} - \\beta_{1}w |w)\\] \\[ =1 -  F(-\\beta_{0} - \\beta_{1}w)\\] \\[ =F(\\beta_{0} + \\beta_{1}w)\\]\n\n\\(F()\\) is the probability distribution of \\(e\\)\n\n\\(1 - F(-\\beta_{0} - \\beta_{1}w) = F(\\beta_{0} + \\beta_{1}w)\\) because \\(F()\\) is symmetric\n\nThe probability that \\(y\\) equals 1 depends on\n\nTreatment status \\(w\\)\nThe distribution of \\(e\\)\n\nDifferent choices for \\(F()\\) distribution lead to different models"
  },
  {
    "objectID": "slides/limdep/index.html#linear-probability-model-6",
    "href": "slides/limdep/index.html#linear-probability-model-6",
    "title": "E655 - Econometrics",
    "section": "Linear Probability Model",
    "text": "Linear Probability Model\n\nFinally \\(E[y|w] = Pr(y=1|w)\\), so\n\n\\[Var[u|w] = Pr(y=1|w) (1-Pr(y=1|w))\\]\n\nThis means that the variance of the error term is a function of \\(w\\)\nIt introduces heteroskedasticity into the model\nSolution: use heteroskedasticity robust standard errors"
  },
  {
    "objectID": "slides/limdep/index.html#nonlinear-models-3",
    "href": "slides/limdep/index.html#nonlinear-models-3",
    "title": "E655 - Econometrics",
    "section": "Nonlinear Models",
    "text": "Nonlinear Models\nProbit Model\n\nAssuming \\(e \\sim \\mathcal{N}(0,\\sigma^{2}_{e})\\) leads to the Probit Model\n\n\\[Pr(y=1|w) = \\Phi \\left(\\frac{\\beta_{0} + \\beta_{1}w}{\\sigma^{2}_{e}} \\right)\\]\n\nwhere\n\n\\[\\Phi (z) =  \\int_{-\\infty}^{z} \\frac{1}{\\sqrt{2\\pi}} e^{\\frac{-v^2}{2}}\\,dv\\]\n\nBecause \\(\\Phi(.)\\) is a CDF, \\(Pr(y=1|w)\\) is always between 0 and 1\n\nThis solves the predicted probability problem"
  },
  {
    "objectID": "slides/limdep/index.html#nonlinear-models-4",
    "href": "slides/limdep/index.html#nonlinear-models-4",
    "title": "E655 - Econometrics",
    "section": "Nonlinear Models",
    "text": "Nonlinear Models\n\nThe difference in probabilities between treatment and control is\n\n\\[Pr(y=1|w = 1) - Pr(y=1|w=0)\\] \\[=  \\Phi \\left(\\frac{\\beta_{0} + \\beta_{1}}{\\sigma^{2}_{e}} \\right) - \\Phi \\left(\\frac{\\beta_{0}}{\\sigma^{2}_{e}}  \\right)\\]\n\nNotice that \\(\\beta_{1}\\) does not equal the difference in response probabilities\n\nThey are the slopes in the index model\nThe index model parameters are not usually of interest\n\nTo get the difference in response probabilities, feed parameters into the CDF first\nIn nonlinear models, parameters are not “marginal effects”\n\nYou need to separately compute them after estimating the model"
  },
  {
    "objectID": "slides/limdep/index.html#linear-probability-model-7",
    "href": "slides/limdep/index.html#linear-probability-model-7",
    "title": "E655 - Econometrics",
    "section": "Linear Probability Model",
    "text": "Linear Probability Model"
  },
  {
    "objectID": "slides/limdep/index.html#visualize-binary-choice-models",
    "href": "slides/limdep/index.html#visualize-binary-choice-models",
    "title": "E655 - Econometrics",
    "section": "Visualize Binary Choice Models",
    "text": "Visualize Binary Choice Models"
  },
  {
    "objectID": "slides/limdep/index.html#nonlinear-models-5",
    "href": "slides/limdep/index.html#nonlinear-models-5",
    "title": "E655 - Econometrics",
    "section": "Nonlinear Models",
    "text": "Nonlinear Models\n\nIn models with more variables and where they are continuous\n\n\\[Pr(y=1|\\mathbf{x}) = \\Phi \\left(\\frac{\\mathbf{x}\\boldsymbol{\\beta}}{\\sigma^{2}_{e}} \\right)\\]\n\nThe marginal effect for continuous variable \\(x_{j}\\)\n\n\\[\\frac{\\partial Pr(y=1|\\mathbf{x})}{\\partial x_{j}} = \\phi \\left(\\frac{\\mathbf{x}\\boldsymbol{\\beta}}{\\sigma^{2}_{e}} \\right) \\frac{\\beta_{j}}{\\sigma^{2}_{e}}\\]\n\nThis is a function of the entire vector \\(\\mathbf{x}\\)\n\nYou need to specify their values to get the marginal effect\nNormally people hold them at the mean\nIn theory you can get a distribution of marginal effects"
  },
  {
    "objectID": "slides/limdep/index.html#nonlinear-models-6",
    "href": "slides/limdep/index.html#nonlinear-models-6",
    "title": "E655 - Econometrics",
    "section": "Nonlinear Models",
    "text": "Nonlinear Models\nLogit Model\n\nAssuming \\(e \\sim \\text{Logistic}(0,\\sigma^{2}_{e})\\) leads to the Logit Model\n\n\\[Pr(y=1|w) = \\Lambda \\left(\\frac{\\beta_{0} + \\beta_{1}w}{\\sigma^{2}_{e}} \\right)\\]\n\nwhere\n\\[\\Lambda (z) =  \\frac{e^z}{1+e^z}\\]\nAgain, because \\(\\Lambda(.)\\) is a CDF, \\(Pr(y=1|w)\\) is always between 0 and 1"
  },
  {
    "objectID": "slides/limdep/index.html#nonlinear-models-7",
    "href": "slides/limdep/index.html#nonlinear-models-7",
    "title": "E655 - Econometrics",
    "section": "Nonlinear Models",
    "text": "Nonlinear Models\n\nThe observed difference in probabilities is\n\n\\[Pr(y=1|w = 1) - Pr(y=1|w=0)\\] \\[=  \\Lambda \\left(\\frac{\\beta_{0} + \\beta_{1}}{\\sigma^{2}_{e}} \\right) - \\Lambda \\left(\\frac{\\beta_{0}}{\\sigma^{2}_{e}}  \\right)\\]\n\nIn models with more variables and where they are continuous\n\n\\[Pr(y=1|\\mathbf{x}) = \\Lambda \\left(\\frac{\\mathbf{x}\\boldsymbol{\\beta}}{\\sigma^{2}_{e}} \\right)\\]"
  },
  {
    "objectID": "slides/limdep/index.html#nonlinear-models-8",
    "href": "slides/limdep/index.html#nonlinear-models-8",
    "title": "E655 - Econometrics",
    "section": "Nonlinear Models",
    "text": "Nonlinear Models\n\nThe marginal effect for continuous variable \\(x_{j}\\)\n\n\\[\\frac{\\partial Pr(y=1|\\mathbf{x})}{\\partial x_{j}} = \\Lambda \\left(\\frac{\\mathbf{x}\\boldsymbol{\\beta}}{\\sigma^{2}_{e}} \\right) \\left( 1-\\Lambda \\left(\\frac{\\mathbf{x}\\boldsymbol{\\beta}}{\\sigma^{2}_{e}} \\right) \\right)\\frac{\\beta_{j}}{\\sigma^{2}_{e}}\\]\n\nAgain, this is a function of the full set of variables"
  },
  {
    "objectID": "slides/limdep/index.html#nonlinear-models-9",
    "href": "slides/limdep/index.html#nonlinear-models-9",
    "title": "E655 - Econometrics",
    "section": "Nonlinear Models",
    "text": "Nonlinear Models\nEstimation of Probit and Logit\n\nBoth models usually estimated by Maximum Likelihood\nMethod maximizes the probability of getting our sample by choosing parameters\n\nTheLikelihood Function is the function of the parameters given the data\n\nThe probability distribution of \\(y_i\\) is\n\n\\[f(y_i| \\mathbf{x_{i}};\\boldsymbol{\\beta})= F \\left(\\frac{\\mathbf{x_{i}}\\boldsymbol{\\beta}}{\\sigma^{2}_{e}} \\right)^{y_i} \\left(1- F \\left(\\frac{\\mathbf{x_{i}}\\boldsymbol{\\beta}}{\\sigma^{2}_{e}} \\right) \\right) ^{1-y_{i}}\\]"
  },
  {
    "objectID": "slides/limdep/index.html#nonlinear-models-10",
    "href": "slides/limdep/index.html#nonlinear-models-10",
    "title": "E655 - Econometrics",
    "section": "Nonlinear Models",
    "text": "Nonlinear Models\n\nThe joint probability of observing the all the \\(y_{i}\\) in the data is\n\n\\[f(\\mathbf{y}| \\mathbf{X};\\boldsymbol{\\beta})=\\Pi_{i=1}^n F \\left(\\frac{\\mathbf{x_{i}}\\boldsymbol{\\beta}}{\\sigma^{2}_{e}} \\right)^{y_{i}}  \\left(1- F \\left(\\frac{\\mathbf{x_{i}}\\boldsymbol{\\beta}}{\\sigma^{2}_{e}} \\right) \\right) ^{1-y_{i}}\\]\n\nThe Likelihood Function recasts as a function of the parameters given the data\n\n\\[\\mathcal{L}(\\boldsymbol{\\beta}|\\mathbf{y}, \\mathbf{X})=\\Pi_{i=1}^n F \\left(\\frac{\\mathbf{x_{i}}\\boldsymbol{\\beta}}{\\sigma^{2}_{e}} \\right)^{y_{i}}  \\left(1- F \\left(\\frac{\\mathbf{x_{i}}\\boldsymbol{\\beta}}{\\sigma^{2}_{e}} \\right) \\right) ^{1-y_{i}}\\]"
  },
  {
    "objectID": "slides/limdep/index.html#nonlinear-models-11",
    "href": "slides/limdep/index.html#nonlinear-models-11",
    "title": "E655 - Econometrics",
    "section": "Nonlinear Models",
    "text": "Nonlinear Models\n\nBoth models usually estimated by Maximum Likelihood\nMethod maximizes the joint probability of \\(y\\) values conditional on \\(\\mathbf{x}\\)\n\nThis is called the Likelihood Function\n\nIn the case of a binary \\(y\\), the likelihood function is\n\n\\[f[y| \\mathbf{x};\\boldsymbol{\\beta}]=P[Y_{1} = y_{1}, Y_{2} = y_{2}, \\ldots, Y_{n} = y_{n}|\\mathbf{x_{i}};\\boldsymbol{\\beta}]\\] \\[=\\Pi_{y_{i}=1}F \\left(\\frac{\\mathbf{x_{i}}\\boldsymbol{\\beta}}{\\sigma^{2}_{e}} \\right) \\Pi_{y_{i}=0} \\left[1-F \\left(\\frac{\\mathbf{x_{i}}\\boldsymbol{\\beta}}{\\sigma^{2}_{e}} \\right) \\right]\\] \\[=\\Pi_{i=1}^{n} F \\left(\\frac{\\mathbf{x_{i}}\\boldsymbol{\\beta}}{\\sigma^{2}_{e}} \\right)^{y_{i}} \\left[1-F \\left(\\frac{\\mathbf{x_{i}}\\boldsymbol{\\beta}}{\\sigma^{2}_{e}} \\right)\\right] ^{1-y_{i}}\\]"
  },
  {
    "objectID": "slides/limdep/index.html#nonlinear-models-12",
    "href": "slides/limdep/index.html#nonlinear-models-12",
    "title": "E655 - Econometrics",
    "section": "Nonlinear Models",
    "text": "Nonlinear Models\n\nResearchers usually focus on the log of the likelihood instead\n\nIt is a monotonic (increasing) transformation of the likelihood\nThe same parameter vector solves both versions\nLog likelihoods are easier to work with\n\nLog Likelihood \\[ln\\mathcal{L}(\\boldsymbol{\\beta}|\\mathbf{y}, \\mathbf{X})= \\sum_{i=1}^{N}\\{ y_{i}lnF \\left(\\frac{\\mathbf{x_{i}}\\boldsymbol{\\beta}}{\\sigma^{2}_{e}} \\right)+  (1-y_{i})ln (1-F \\left(\\frac{\\mathbf{x_{i}}\\boldsymbol{\\beta}}{\\sigma^{2}_{e}} \\right))  \\}\\]\nTo solve this equation, you need numerical methods\n\nA grid search algorithm that finds the maximum value"
  },
  {
    "objectID": "slides/limdep/index.html#nonlinear-models-13",
    "href": "slides/limdep/index.html#nonlinear-models-13",
    "title": "E655 - Econometrics",
    "section": "Nonlinear Models",
    "text": "Nonlinear Models\n\nIn ML environments, the estimated variance of \\(\\boldsymbol{\\hat{\\beta}}\\) is estimated as the negative of the expected value of the Hessian (information matrix) \\[\\hat{Var}(\\boldsymbol{\\hat{\\beta}}) = -E[(\\frac{\\partial^2 lnL}{\\partial\\boldsymbol{\\hat{\\beta}} \\partial \\boldsymbol{\\hat{\\beta}^{'}}})^{-1}]\\] \\[= (\\sum_{i=1}^{n} \\frac{f(\\mathbf{x_{i}^{'}}\\boldsymbol{\\hat{\\beta}})^2 }{ F(\\mathbf{x_{i}^{'}}\\boldsymbol{\\hat{\\beta}})(1- F(\\mathbf{x_{i}^{'}}\\boldsymbol{\\hat{\\beta}}) ) }  \\mathbf{x_{i}x_{i}^{'}} )^{-1}\\]\nwhere \\(F(.)\\) is either the Normal or Logistic CDF, and \\(f(.)\\) is the associated PDF"
  },
  {
    "objectID": "slides/limdep/index.html#nonlinear-models-14",
    "href": "slides/limdep/index.html#nonlinear-models-14",
    "title": "E655 - Econometrics",
    "section": "Nonlinear Models",
    "text": "Nonlinear Models"
  },
  {
    "objectID": "slides/limdep/index.html#nonlinear-models-15",
    "href": "slides/limdep/index.html#nonlinear-models-15",
    "title": "E655 - Econometrics",
    "section": "Nonlinear Models",
    "text": "Nonlinear Models\nHypothesis Testing in Probit and Logit\n\nSimple tests for coefficient significance is done by the usual \\(t\\)-test method\n\nAssume \\(\\boldsymbol{\\hat{\\beta}}\\) has normal distribution (asymptotically)\nTest statistic \\(Z = \\frac{\\hat{\\beta}_{k}}{\\hat{SE}(\\hat{\\beta}_{k})}\\)"
  },
  {
    "objectID": "slides/limdep/index.html#nonlinear-models-16",
    "href": "slides/limdep/index.html#nonlinear-models-16",
    "title": "E655 - Econometrics",
    "section": "Nonlinear Models",
    "text": "Nonlinear Models\n\nMore complicated tests done using one of 3 methods:\n\nLikelihood Ratio (LR) Test\n\nTest statistic \\(LR = 2[ln\\hat{L}_{U} - ln\\hat{L}_{R}]\\)\n\\(ln\\hat{L}_{R}\\) is log likelihood evaluated at restricted parameter vector\n\nWald (W) Test\n\nTest statistic \\(W = \\hat{g}^{'}[\\hat{G}\\hat{Var}(\\boldsymbol{\\hat{\\beta}})\\hat{G}^{'}]\\hat{g}\\)\n\\(\\hat{g}\\) is a vector of restrictions evaluated at \\(\\boldsymbol{\\hat{\\beta}}\\)\n\\(\\hat{G}\\) is the derivative of a vector of restrictions evaluated at \\(\\boldsymbol{\\hat{\\beta}}\\)\n\nLagrange Multiplier (LM) Test\n\nTest statistic \\(LM = \\hat{d}^{'}[\\hat{Var}(\\boldsymbol{\\hat{\\beta}})]\\hat{d}\\)\n\\(\\hat{d}\\) is the derivative of \\(lnL\\) evaluated at restricted \\(\\boldsymbol{\\hat{\\beta}}\\)\n\n\nRestrictions can be linear or non-linear"
  },
  {
    "objectID": "slides/limdep/index.html#nonlinear-models-17",
    "href": "slides/limdep/index.html#nonlinear-models-17",
    "title": "E655 - Econometrics",
    "section": "Nonlinear Models",
    "text": "Nonlinear Models"
  },
  {
    "objectID": "slides/limdep/index.html#nonlinear-models-18",
    "href": "slides/limdep/index.html#nonlinear-models-18",
    "title": "E655 - Econometrics",
    "section": "Nonlinear Models",
    "text": "Nonlinear Models\nGoodness of Fit in Probit and Logit\n\nConfusion Matrix\n\n\n\n\nActual\n\n\n\n\n\n\nPredicted\n0\n1\nTotal\n\n\n0\n# Correct 0\n# Incorrect 1\n# Pred 0\n\n\n1\n# Incorrect 0\n#Correct 1\n# Pred 1\n\n\nTotal\n# True 0\n# True 1\n\n\n\n\nPseudo-\\(R^{2}\\)\n\nMcFadden \\(\\rightarrow\\) \\(R^{2} = 1 - \\frac{ln\\hat{L}_{U}}{ln\\hat{L}_{0}}\\)\n\n\\(ln\\hat{L}_{0}\\) is log-likelihood with no explanatory variables\n\nOthers are possible, but goodness of fit is not incredibly important"
  },
  {
    "objectID": "content/limdep.html",
    "href": "content/limdep.html",
    "title": "Limited Dependent Variables",
    "section": "",
    "text": "Fixed Effects\n\nAP1 Chapter 5\nC Chapter 8\nCT Chapter 21\nHA Chapter 17\nHK Chapter 16\nW1 Chapter 14\nW2 Chapter 10"
  },
  {
    "objectID": "content/limdep.html#readings",
    "href": "content/limdep.html#readings",
    "title": "Limited Dependent Variables",
    "section": "",
    "text": "Fixed Effects\n\nAP1 Chapter 5\nC Chapter 8\nCT Chapter 21\nHA Chapter 17\nHK Chapter 16\nW1 Chapter 14\nW2 Chapter 10"
  },
  {
    "objectID": "content/limdep.html#slides",
    "href": "content/limdep.html#slides",
    "title": "Limited Dependent Variables",
    "section": "Slides",
    "text": "Slides\nThe slides are embedded in this page, and you can scroll through them with the arrow keys. If you prefer you can instead pop them out in a new window"
  },
  {
    "objectID": "content/limdep.html#sample-r-code",
    "href": "content/limdep.html#sample-r-code",
    "title": "Limited Dependent Variables",
    "section": "Sample R Code",
    "text": "Sample R Code\nThe code below goes through an exercise estimating with various panel data approaches under scenarios where the unobserved effect is or is not correlated with the main independent variable, and whether strict exogeneity holds.\n EC655panel.R"
  },
  {
    "objectID": "slides/limdep/index.html#introduction-2",
    "href": "slides/limdep/index.html#introduction-2",
    "title": "E655 - Econometrics",
    "section": "Introduction",
    "text": "Introduction\n\nArises when a continuous dependent variable is limited in its range\n\nCensoring\n\nIncome is top-coded at some level for privacy\n\nCorner Solutions\n\nSpending on consumer durables limited below by 0\n\nIncidental Truncation\n\nWage is not observed for people who do not work\n\n\nYou can sometimes use OLS depending on context\nWe will cover models for censoring and corner solutions"
  },
  {
    "objectID": "slides/limdep/index.html#tobit-model",
    "href": "slides/limdep/index.html#tobit-model",
    "title": "E655 - Econometrics",
    "section": "Tobit Model",
    "text": "Tobit Model\nLatent Variable\n\nWe again appeal to a latent variable model\n\n\\[y^{*} =  \\beta_{0} + \\beta_{1}w + e\\]\n\nSuppose the observed \\(y\\) is\n\n\\[y = max \\{ 0,y^* \\}\\]\n\nThis would be the case for things like consumer purchases\n\nYou spend zero or some positive amount\nIt is naturally bounded below by zero"
  },
  {
    "objectID": "slides/limdep/index.html#tobit-model-1",
    "href": "slides/limdep/index.html#tobit-model-1",
    "title": "E655 - Econometrics",
    "section": "Tobit Model",
    "text": "Tobit Model\n\nBecause it is either zero or positive, the expected value of \\(y\\) is\n\n\\[E[y|w] = E[y|y&gt;0,w]Pr[y&gt;0|w]\\]\n\nTaking the difference in the observed \\(y\\), we get\n\n\\[E[y|w = 1] -  E[y|w = 0]\\] \\[= E[y|y&gt;0,w=1]Pr[y&gt;0|w=1] - E[y|y&gt;0,w=0]Pr[y&gt;0|w=0]\\] \\[=(Pr[y&gt;0|w=1]-Pr[y&gt;0|w=1]) E[y|y&gt;0,w = 1]\\] \\[+ (E[y|y&gt;0,w = 1]  - E[y|y&gt;0,w = 0]) Pr[y&gt;0|w=0]\\]"
  },
  {
    "objectID": "slides/limdep/index.html#tobit-model-2",
    "href": "slides/limdep/index.html#tobit-model-2",
    "title": "E655 - Econometrics",
    "section": "Tobit Model",
    "text": "Tobit Model\n\nThere are two key pieces\n\nParticipation effect\nConditional on Positive effect\n\nIn terms of potential outcomes\n\n\\[E[y|w = 1] -  E[y|w = 0]\\] \\[= E[y_1|w = 1] -  E[y_0|w = 0]\\] \\[= E[y_1|w = 1] -  E[y_0|w = 1] + E[y_0|w = 1] -  E[y_0|w = 0]\\]\n\nThe limited dependent variable does not change causal interpretation\n\nAs long as potential outcome \\(y_{0}\\) is mean independent of treatment"
  },
  {
    "objectID": "slides/limdep/index.html#tobit-model-3",
    "href": "slides/limdep/index.html#tobit-model-3",
    "title": "E655 - Econometrics",
    "section": "Tobit Model",
    "text": "Tobit Model\nConditional on Positive\n\nIn some contexts people run regressions with just the positive outcomes\n\nIf you wanted to analyze participation decision separately\n\nDifference in observed \\(y\\) for this group is biased if under random assignment\n\n\\[E[y|y&gt;0,w = 1] -  E[y|y&gt;0, w = 0]\\] \\[= E[y_1|y_1&gt;0] -  E[y_0|y_0&gt;0]\\] \\[= E[y_1|y_1&gt;0] - E[y_0|y_1&gt;0] +  E[y_0|y_1&gt;0] -E[y_0|y_0&gt;0]\\]\n\nThe treatment changes who has positive values of potential outcomes\n\nMore subtle form of bias\n\nYou cannot interpret conditional on positive effects as causal"
  },
  {
    "objectID": "slides/limdep/index.html#tobit-model-4",
    "href": "slides/limdep/index.html#tobit-model-4",
    "title": "E655 - Econometrics",
    "section": "Tobit Model",
    "text": "Tobit Model\nModel\n\nThis model is used in the context of censoring and corner solutions\nWe have data on a random sample\nThe outcome is limited in its range\nThere is a mass of observations at 1 or more values\n\nUsually zeroes\nSometimes some upper amount, like income\n\nUsing OLS may be a bad strategy depending on your goals\n\nCan produce predicted values outside the limited range"
  },
  {
    "objectID": "slides/limdep/index.html#tobit-model-5",
    "href": "slides/limdep/index.html#tobit-model-5",
    "title": "E655 - Econometrics",
    "section": "Tobit Model",
    "text": "Tobit Model\n\nThe Tobit model starts with the latent variable model\n\n\\[y^{*} = \\mathbf{x}\\boldsymbol{\\beta} + e, \\text{ where } e \\sim N(0,\\sigma^2_{e})\\] \\[y = \\text{max}(0,y^{*})\\]\n\nThe conditional expectation of interest depends on context\n\nCensored data\n\n\\(E[y^{*}|\\mathbf{x}]\\)\n\\(y^{*}\\) usually has meaning when data are censored\n\nCorner Solutions\n\n\\(E[y|\\mathbf{x}]\\) and \\(E[y|y&gt;0, \\mathbf{x}]\\)\n\\(y_{i}^{*}\\) usually has no meaning for corner solutions\nThis is the most common situation"
  },
  {
    "objectID": "slides/limdep/index.html#tobit-model-6",
    "href": "slides/limdep/index.html#tobit-model-6",
    "title": "E655 - Econometrics",
    "section": "Tobit Model",
    "text": "Tobit Model\nEstimation\n\nEstimate this model by maximum likelihood\nThe likelihood function has two pieces\nWhen \\(y_{i} = 0\\)\n\n\\[Pr(y_{i} = 0| \\mathbf{x}) = Pr(y_{i}^{*}&lt;0 |\\mathbf{x})\\] \\[= Pr(\\mathbf{x}\\boldsymbol{\\beta} +e&lt;0 |\\mathbf{x})\\]"
  },
  {
    "objectID": "slides/limdep/index.html#tobit-model-7",
    "href": "slides/limdep/index.html#tobit-model-7",
    "title": "E655 - Econometrics",
    "section": "Tobit Model",
    "text": "Tobit Model\n\nDue to symmetry in the distribution of \\(e\\)\n\n\\[= Pr(e&gt;\\mathbf{x}\\boldsymbol{\\beta}  |\\mathbf{x})\\] \\[= Pr(\\frac{e}{\\sigma_{e}}&gt;\\frac{\\mathbf{x}\\boldsymbol{\\beta}}{\\sigma_{e}}  |\\mathbf{x})\\]\n\\[= 1-\\Phi\\left (  \\frac{\\mathbf{x}\\boldsymbol{\\beta}}{\\sigma_{e}}  \\right)\\]"
  },
  {
    "objectID": "slides/limdep/index.html#tobit-model-8",
    "href": "slides/limdep/index.html#tobit-model-8",
    "title": "E655 - Econometrics",
    "section": "Tobit Model",
    "text": "Tobit Model\n\nWhen \\(y_{i} &gt; 0\\)\n\n\\[f(y_{i} | y_{i}&gt;0, \\mathbf{x}) = \\frac{1}{\\sigma_{e}} \\phi \\left ( \\frac{ y_{i} - \\mathbf{x}\\boldsymbol{\\beta}}{\\sigma_{e}}    \\right )\\]\n\nCombining terms, we can form the likelihood function\n\n\\[\\mathcal{L}(\\boldsymbol{\\beta}|\\mathbf{y}, \\mathbf{X}) =\\Pi_{y_{i}=0} \\left(1-\\Phi\\left (  \\frac{\\mathbf{x}\\boldsymbol{\\beta}}{\\sigma_{e}}  \\right) \\right ) \\Pi_{y_{i}&gt;0} \\left( \\frac{1}{\\sigma_{e}} \\phi \\left ( \\frac{ y_{i} - \\mathbf{x}\\boldsymbol{\\beta}}{\\sigma_{e}}    \\right ) \\right)\\]"
  },
  {
    "objectID": "slides/limdep/index.html#tobit-model-9",
    "href": "slides/limdep/index.html#tobit-model-9",
    "title": "E655 - Econometrics",
    "section": "Tobit Model",
    "text": "Tobit Model\n\nThe log likelihood is\n\n\\[ln\\mathcal{L}(\\boldsymbol{\\beta}|\\mathbf{y}, \\mathbf{X}) =\\sum_{y_{i}=0} ln \\left(1-\\Phi\\left (  \\frac{\\mathbf{x}\\boldsymbol{\\beta}}{\\sigma_{e}}  \\right) \\right )  + \\sum_{y_{i}&gt;0} ln\\left( \\frac{1}{\\sigma_{e}} \\phi \\left ( \\frac{ y_{i} - \\mathbf{x}\\boldsymbol{\\beta}}{\\sigma_{e}}    \\right ) \\right)\\]\n\nMaximize this function by choosing the parameter vector \\(\\boldsymbol{\\beta}\\) and \\(\\sigma_{e}\\)"
  },
  {
    "objectID": "slides/limdep/index.html#tobit-model-10",
    "href": "slides/limdep/index.html#tobit-model-10",
    "title": "E655 - Econometrics",
    "section": "Tobit Model",
    "text": "Tobit Model\n\nMarginal effects will depend on the context of our estimation\n\nCensored data \\[\\frac{\\partial E[y^{*}|\\mathbf{x}]}{\\partial x_{k}} = \\beta_{k}\\]\n\nIn a Tobit with censored data, you can interpret the slope directly\n\nCorner Solutions\n\\(\\frac{\\partial E[y|\\mathbf{x}]}{\\partial x_{k}} = \\Phi(\\frac{ \\mathbf{x}\\boldsymbol{\\beta} }{\\sigma})\\beta_{k}\\)\n\\(\\frac{\\partial E[y| y&gt;0,\\mathbf{x}]}{\\partial x_{k}} = \\{1-\\lambda(\\frac{ \\mathbf{x}\\boldsymbol{\\beta} }{\\sigma})[\\frac{ \\mathbf{x}\\boldsymbol{\\beta} }{\\sigma} + \\lambda(\\frac{ \\mathbf{x}\\boldsymbol{\\beta} }{\\sigma})] \\}\\beta_{k}\\)\n\nWith corner solutions it depends on what you want\nYou may want slope for random person, or conditional on \\(y&gt;0\\)"
  },
  {
    "objectID": "slides/limdep/index.html#tobit-model-11",
    "href": "slides/limdep/index.html#tobit-model-11",
    "title": "E655 - Econometrics",
    "section": "Tobit Model",
    "text": "Tobit Model\nIssues with Tobit Model\n\nIt must be possible for the dependent variable to take values near the limit\n\nExample: not the case with consumer durables\nYou either spend zero or a large amount\n\nIntensive and Extensive margins have same parameters\n\nMeans the model is relatively inflexible\nCan be solved by modelling each separately\n\nNormality assumption\nCare must be taken in interpreting the coefficients\n\nDo we care about the effect of \\(x_{k}\\) on \\(y\\) or \\(y^{*}\\)?"
  },
  {
    "objectID": "slides/limdep/index.html",
    "href": "slides/limdep/index.html",
    "title": "\nLimited Dependent Variables\n",
    "section": "",
    "text": "Limited Dependent Variables"
  },
  {
    "objectID": "syllabus.html#hawk-walk-the-wellness-centre-and-the-student-food-bank",
    "href": "syllabus.html#hawk-walk-the-wellness-centre-and-the-student-food-bank",
    "title": "EC313 Syllabus",
    "section": "Hawk Walk, the Wellness Centre, and the Student Food Bank",
    "text": "Hawk Walk, the Wellness Centre, and the Student Food Bank\n\nMulti-campus Resources\n\nStudent Rights Advisory Committee (studentsrights@wlu.ca): The Student Rights Advisory Committee exists to provide you with information about your rights when it comes to landlord-tenant issues or academic appeals. While in no way legal representation, it can help to inform you about your options to make difficult situations easier to navigate. ·\nEmpower Me - Mental Health Resources provided by Dialogue: Empower Me is a mental health and wellness service that seeks to contribute to a resilient student community by supporting existing on-campus and community mental health resources. Empower Me has a number of professionals with various domains of expertise, including psychology, psychotherapy, social work, nutrition, etc., to support you and respond effectively to diverse needs. You can access services via telephone, videoconference, or in-person. Empower Me is: available 24/7, 365 days a year, confidential, multilingual, culturally sensitive, gender-inclusive, and faith inclusive.\nThe Essentials - Legal Care Program: The Essentials, Legal Care Program allows students to access a legal consultation service. Students are free to consult a duly certified lawyer regarding any legal questions. Upon filling out the Support Form, students can expect a response from legal counsel within approximately 48 hours (business days) about next steps and assistance that is required to navigate housing disputes, employment disputes, disputes with an academic institution, and public notaries. Students can also seek legal representation when their case qualifies for further counsel.\n\n\n\nKitchener/Waterloo Resources:\n\nEmergency Response Team | ert@wlu.ca: The Emergency Response Team provides medical assistance to students on campus. ERT can be booked for on-site event support by filling out the online booking request form on their website.\nHawk Walk | 519.886.3668 | walkw@wlu.ca| Hawk Walk is a volunteer operated safe walk-home service, available daily during evening hours. Teams of two radio-dispatched volunteers are available on request to escort students to and from campus as well as to off-campus destinations. Hawk Walk can be found on the 2nd floor of the Fred Nichols Campus Centre next to the Dean of Students Office.\nFood Bank | foodbank@wlu.ca | Food Bank provides food parcels to cater to the nutritional and dietary needs of students. All students are eligible to use this service, regardless of circumstance or financial situation. Request a package at https://www.yourstudentsunion.ca/food-bank"
  },
  {
    "objectID": "slides/ols/index.html",
    "href": "slides/ols/index.html",
    "title": "\nOrdinary Least Squares\n",
    "section": "",
    "text": "Ordinary Least Squares"
  },
  {
    "objectID": "content/introtopf.html",
    "href": "content/introtopf.html",
    "title": "Introduction to Public Finance",
    "section": "",
    "text": "RTTWS Chapter 1",
    "crumbs": [
      "Content",
      "Course content",
      "Intro to Public Finance"
    ]
  },
  {
    "objectID": "content/introtopf.html#readings",
    "href": "content/introtopf.html#readings",
    "title": "Introduction to Public Finance",
    "section": "",
    "text": "RTTWS Chapter 1",
    "crumbs": [
      "Content",
      "Course content",
      "Intro to Public Finance"
    ]
  },
  {
    "objectID": "content/introtopf.html#slides",
    "href": "content/introtopf.html#slides",
    "title": "Introduction to Public Finance",
    "section": "Slides",
    "text": "Slides\nThe slides are embedded in this page, and you can scroll through them with the arrow keys. If you prefer you can instead pop them out in a new window",
    "crumbs": [
      "Content",
      "Course content",
      "Intro to Public Finance"
    ]
  },
  {
    "objectID": "slides/intro/index.html#goals-of-this-section-1",
    "href": "slides/intro/index.html#goals-of-this-section-1",
    "title": "EC313 - Taxation",
    "section": "Goals of This Section",
    "text": "Goals of This Section\n\nDefine Public Economics\nGive broad overview of Canada’s government and public finance framework\nMeasure the “size” of government\nOverview of government revenues and expenses"
  },
  {
    "objectID": "slides/intro/index.html#defining-public-economics",
    "href": "slides/intro/index.html#defining-public-economics",
    "title": "EC313 - Taxation",
    "section": "Defining Public Economics",
    "text": "Defining Public Economics\n\nPublic Economics is the study of the role of government in the economy\n\nIt examines how government policies affect economic efficiency, income distribution, and overall welfare\n\nConcerned with the microeconomic aspects of the economy\n\nHow government actions affect individual and firm behavior\nMacroeconomic functions of government (fiscal policy, monetary policy) are in separate fields\n\nAttempts to answer three key questions:\n\nWhen should the government interevene in the economy?\nWhat is the effect of these interventions?\nWhy do they choose to intervene in this way?"
  },
  {
    "objectID": "slides/intro/index.html#when-should-the-government-intervene",
    "href": "slides/intro/index.html#when-should-the-government-intervene",
    "title": "EC313 - Taxation",
    "section": "When Should the Government Intervene?",
    "text": "When Should the Government Intervene?\n\nMarket Failures: Situations where the free market does not allocate resources efficiently\n\nPublic goods: goods that are non-excludable and non-rivalrous (e.g., national defense, public parks)\nExternalities: costs or benefits that affect third parties not involved in a transaction (e.g., pollution)\nImperfect competition: markets dominated by a few firms, leading to monopolies or oligopolies\nAssymetric information: situations where one party has more or better information than the other (e.g., used car market)\nIrrational behaviour: situations where individuals do not make rational decisions (e.g., addiction, procrastination)"
  },
  {
    "objectID": "slides/intro/index.html#effects-of-alternative-interventions",
    "href": "slides/intro/index.html#effects-of-alternative-interventions",
    "title": "EC313 - Taxation",
    "section": "Effects of Alternative Interventions",
    "text": "Effects of Alternative Interventions\n\nCompetitive markets (in theory) generate an efficient allocation of resources\n\nAllocation is Pareto Efficient: no one can be made better off without making someone else worse off\nSubject to specific assumptions\nCalled the First Fundamental Theorem of Welfare Economics\n\nBut that allocation is not always equitable\n\nSome people may get significantly more resources than others"
  },
  {
    "objectID": "slides/intro/index.html#effects-of-alternative-interventions-1",
    "href": "slides/intro/index.html#effects-of-alternative-interventions-1",
    "title": "EC313 - Taxation",
    "section": "Effects of Alternative Interventions",
    "text": "Effects of Alternative Interventions\n\nGovernment can intervene to redistribute resources\nIn theory, it can do this without reducing efficiency\n\nThrough transfers of initial wealth\nCalled the Second Fundamental Theorem of Welfare Economics\n\nIn reality, government intervenes with taxes and transfers that may reduce efficiency\n\nTaxes can distort incentives and lead to inefficiencies\nCreates an efficiency-equity trade-off"
  },
  {
    "objectID": "slides/intro/index.html#why-do-governments-intervene-in-particular-ways",
    "href": "slides/intro/index.html#why-do-governments-intervene-in-particular-ways",
    "title": "EC313 - Taxation",
    "section": "Why Do Governments Intervene in Particular Ways?",
    "text": "Why Do Governments Intervene in Particular Ways?\n\nPolitical Economy: a field of economics that studies the interaction between politics and economics\n\nHow do politics and economics drive policy and economic outcomes?\nDepends on economic system, political system, norms, etc.\nSome example research papers:\n\n” Do Leaders Matter? National Leadership Growth Since World War II”\n“Why Do Developing Countries Tax So Little?”\n“Voting Technology, Political Responsiveness, and Infant Health: Evidence from Brazil”\n\n\nPublic choice: a subset of political economy that applies economic principles to political decision-making\n\nUses a rational choice framework (e.g. utility maximization) to study political decisions\nStudies very similar topics to political economy as a whole"
  },
  {
    "objectID": "slides/intro/index.html#normative-vs.-positive-economics",
    "href": "slides/intro/index.html#normative-vs.-positive-economics",
    "title": "EC313 - Taxation",
    "section": "Normative vs. Positive Economics",
    "text": "Normative vs. Positive Economics\n\nPositive Economics: the study of how things are\n\nWhat are the effects of a carbon tax on gasoline consumption\nHow do income taxes affect labour supply\nPrimarily an empirical field\nMost research in public economics is positive economics\n\nNormative Economics: the study of how things should be\n\nShould the government impose a carbon tax on gasoline?\nShould income taxes be progressive or flat?\nKey difference with positive economics is that it involves value judgements\nPrimarily a theoretical field"
  },
  {
    "objectID": "slides/intro/index.html#some-current-research-topics-in-public-economics",
    "href": "slides/intro/index.html#some-current-research-topics-in-public-economics",
    "title": "EC313 - Taxation",
    "section": "Some Current Research Topics in Public Economics",
    "text": "Some Current Research Topics in Public Economics\n\nPublic economics is a broad research field with significant overlap with other fields like Labour, Education, Health Economics\nSome of the research paper titles from the most recent NBER Public Economics meeting:\n\n“Paternalistic Social Assistance: Evidence and Implications from Cash vs. In-Kind Transfers”\n“Health Impacts of Federal Pandemic Aid to State and Local Governments”\n“The Racial Penalty in Job Ladder Transitions”\n“Behavioral Responses to Estate Taxation: Evidence from Taiwan”\n“The Big Economic Consequences of Small Financial Shocks: Evidence from Minor Car Crashes”"
  },
  {
    "objectID": "slides/intro/index.html#introduction",
    "href": "slides/intro/index.html#introduction",
    "title": "EC313 - Taxation",
    "section": "Introduction",
    "text": "Introduction\n\nIn this section we discuss basics of Canada’s public finance system\nBroad overview, not comprehensive\nWe cover\n\nHistory\nResponsibilities of each level of government"
  },
  {
    "objectID": "slides/intro/index.html#history",
    "href": "slides/intro/index.html#history",
    "title": "EC313 - Taxation",
    "section": "History",
    "text": "History\n\nTax and spending powers come from the Constitution Act, 1982\n\nAmends the British North America (BNA) Act, 1867\nStructure and powers of government are the same in both acts\nConstitution act adds elements like the Charter of Rights and Freedoms\n\nConstitution act specifies federal and provincial responsibilities\n\nFederal: items that are common to all provinces\nProvincial: items that are specific to each province\n\nMunicipal responsibilities are not outlined in constitution\n\nThey are delegated by the provinces\nMeans lots of differences across provinces in the way municipalities operate"
  },
  {
    "objectID": "slides/intro/index.html#federal-government",
    "href": "slides/intro/index.html#federal-government",
    "title": "EC313 - Taxation",
    "section": "Federal Government",
    "text": "Federal Government\n\nKey areas of federal responsibility as outlined in the constitution:\n\nDirect and indirect taxation\nNational defence\nNavigation and shipping (e.g marine shipping)\nRegulation of trade and commerce (e.g. trade disputes, tariffs)\nCriminal justice system\nMoney and banking\nCensus\nCitizenship\nPostal service"
  },
  {
    "objectID": "slides/intro/index.html#federal-government-1",
    "href": "slides/intro/index.html#federal-government-1",
    "title": "EC313 - Taxation",
    "section": "Federal Government",
    "text": "Federal Government\n\nThe federal government raises revenue mainly through direct and indirect taxes\n\nDirect tax: paid by directly to the taxing authority that cannot be shifted to another entity\n\ne.g. income, estate, capital gains, property tax\n\nIndirect tax: paid indirectly through an intermediary that can pass it to another entity\n\ne.g. sales tax (HST/GST), tariff"
  },
  {
    "objectID": "slides/intro/index.html#effects-of-alternative-interventions-2",
    "href": "slides/intro/index.html#effects-of-alternative-interventions-2",
    "title": "EC313 - Taxation",
    "section": "Effects of Alternative Interventions",
    "text": "Effects of Alternative Interventions\n\nDirect Effects: Immediate impact of government policies on individuals and firms, without changes in their behaviour\nExamples:\n\nA carbon tax on gasoline raises revenue from drivers\nIncome taxes raise revenue from workers\nCorporate taxes raise revenue from firms\nTariffs raise revenue from imports\nA tax credit for charitable giving reduces government revenue"
  },
  {
    "objectID": "slides/intro/index.html#effects-of-alternative-interventions-3",
    "href": "slides/intro/index.html#effects-of-alternative-interventions-3",
    "title": "EC313 - Taxation",
    "section": "Effects of Alternative Interventions",
    "text": "Effects of Alternative Interventions\n\nIndirect (Unintended) Effects: Effects of government policies due to changes in behaviour of individuals and firms\nExamples:\n\nA carbon tax on gasoline may lead drivers to use public transit more\nIncome taxes may lead workers to work fewer hours\nCorporate taxes may lead firms to invest less or move to a different jurisdiction\nTariffs may lead consumers to buy fewer imported goods\nA tax credit for charitable giving may lead individuals to donate more\n\nMuch of current research in public economics focuses on these indirect effects"
  },
  {
    "objectID": "slides/intro/index.html#federal-government-2",
    "href": "slides/intro/index.html#federal-government-2",
    "title": "EC313 - Taxation",
    "section": "Federal Government",
    "text": "Federal Government\n\nThe federal government has broad taxing and spending powers\nAt the time of confederation, most revenue came from tariffs (customs duties)\nNow the majority comes from personal and corporate income taxes and sales taxes\n\n\nFigure: Composition of Canadian Federal Revenues"
  },
  {
    "objectID": "slides/intro/index.html#provincial-government",
    "href": "slides/intro/index.html#provincial-government",
    "title": "EC313 - Taxation",
    "section": "Provincial Government",
    "text": "Provincial Government\n\nKey areas of federal responsibility as outlined in the constitution:\n\nDirect taxation within the province (note: not indirect taxation)\nPrisons\nHospitals\nMunicipalities\nEducation\nNatural resources\nIncorporation of companies"
  },
  {
    "objectID": "slides/intro/index.html#provincial-government-1",
    "href": "slides/intro/index.html#provincial-government-1",
    "title": "EC313 - Taxation",
    "section": "Provincial Government",
    "text": "Provincial Government\n\nProvincial government can only levy direct taxes\n\nMainly income and property tax\nCourts have defined retail sales taxes and excise taxes on tobacco and gasoline as direct taxes (for some reason)\n\nAt confederation, most revenue came from federal government transfers to provinces\n\nVery little from direct taxation\n\nNow, taxes account for 50% of revenues\n\nRest is federal transfers, sales of goods and services, fines/fees, natural resources"
  },
  {
    "objectID": "slides/intro/index.html#introduction-1",
    "href": "slides/intro/index.html#introduction-1",
    "title": "EC313 - Taxation",
    "section": "Introduction",
    "text": "Introduction\n\nPoliticians often quibble over the size of government\n\nConservatives prefer smaller government\nLiberals tend to prefer larger government\n\nThere are different ways to measure its size\n\nExpenditures (total or as fraction of GDP)\nRevenues (total or as fraction of GDP)\nGovernment employment\nNumber of regulations\n\nMost common is to measure using annual expenditures"
  },
  {
    "objectID": "slides/intro/index.html#classification-of-expenditures",
    "href": "slides/intro/index.html#classification-of-expenditures",
    "title": "EC313 - Taxation",
    "section": "Classification of Expenditures",
    "text": "Classification of Expenditures\n\nCan classify government expenditures into three types\n\nPurchases of goods and services\n\nGovernment buys many goods/services\nExamples: Military equipment, buildings, consulting services, professional training\n\nTransfers of income to people, businesses, other governments\n\nExamples: HST rebate, Canada Pension Plan, Canada Child Benefit\n\nInterest payments\n\nGovernment borrows to spend when revenues are insufficient\nDoes this by issuing bonds\nInterest payments are due on that borrowing"
  },
  {
    "objectID": "slides/intro/index.html#statistics-on-expenditures",
    "href": "slides/intro/index.html#statistics-on-expenditures",
    "title": "EC313 - Taxation",
    "section": "Statistics on Expenditures",
    "text": "Statistics on Expenditures\n\nFigure: Canadian Government Expenditures"
  },
  {
    "objectID": "slides/intro/index.html#statistics-on-expenditures-1",
    "href": "slides/intro/index.html#statistics-on-expenditures-1",
    "title": "EC313 - Taxation",
    "section": "Statistics on Expenditures",
    "text": "Statistics on Expenditures\n\nFigure: International Government Expenditures"
  },
  {
    "objectID": "slides/intro/index.html#statistics-on-expenditures-2",
    "href": "slides/intro/index.html#statistics-on-expenditures-2",
    "title": "EC313 - Taxation",
    "section": "Statistics on Expenditures",
    "text": "Statistics on Expenditures"
  },
  {
    "objectID": "slides/intro/index.html#statistics-on-expenditures-3",
    "href": "slides/intro/index.html#statistics-on-expenditures-3",
    "title": "EC313 - Taxation",
    "section": "Statistics on Expenditures",
    "text": "Statistics on Expenditures"
  },
  {
    "objectID": "slides/intro/index.html#statistics-on-expenditures-4",
    "href": "slides/intro/index.html#statistics-on-expenditures-4",
    "title": "EC313 - Taxation",
    "section": "Statistics on Expenditures",
    "text": "Statistics on Expenditures"
  },
  {
    "objectID": "slides/intro/index.html#statistics-on-expenditures-5",
    "href": "slides/intro/index.html#statistics-on-expenditures-5",
    "title": "EC313 - Taxation",
    "section": "Statistics on Expenditures",
    "text": "Statistics on Expenditures"
  },
  {
    "objectID": "slides/intro/index.html#difficulties-counting-expenditures",
    "href": "slides/intro/index.html#difficulties-counting-expenditures",
    "title": "EC313 - Taxation",
    "section": "Difficulties Counting Expenditures",
    "text": "Difficulties Counting Expenditures\n\nSome expenditures are not easy to count\nLoan guarantees (e.g student loans) and contingent commitments (e.g CPP)\n\nGovernment is committed to spend at some point in the future\nAmounts of these commitments are not fully known\nUse accrual accounting to budget\n\nRegulations\n\nImpose costs on individuals/businesses\nThese costs do not appear in government budget"
  },
  {
    "objectID": "slides/intro/index.html#difficulties-counting-expenditures-1",
    "href": "slides/intro/index.html#difficulties-counting-expenditures-1",
    "title": "EC313 - Taxation",
    "section": "Difficulties Counting Expenditures",
    "text": "Difficulties Counting Expenditures\n\nTax expenditure\n\nIndirect spending through reductions in taxes owing\nExamples: charitable giving tax credit, partial taxation of capital gains, zero rating groceries\nNot reflected in budget\n\nCapital investments\n\nCapital goods (e.g. machines) are consumed slowly over time\nTypically large value in year they are purchased\nGives mistaken impression of significant government involvement in economy"
  },
  {
    "objectID": "slides/intro/index.html#federal-revenues",
    "href": "slides/intro/index.html#federal-revenues",
    "title": "EC313 - Taxation",
    "section": "Federal Revenues",
    "text": "Federal Revenues\n\nTotal is about $498 billion in 2024\n\nProjected to be $545 billion in 2028\n\n84% is raised through taxes\n\nPersonal income tax: 50%\nCorporate income tax: 13%\nGoods and services tax (GST): 11%\nOther taxes: 10%\n\nSmaller amount through non-tax sources\n\nEmployment insurance premiums: 7%\nOther reveue (e.g. crown corporations, investments): 9%"
  },
  {
    "objectID": "slides/intro/index.html#federal-expenditures",
    "href": "slides/intro/index.html#federal-expenditures",
    "title": "EC313 - Taxation",
    "section": "Federal Expenditures",
    "text": "Federal Expenditures\n\nTotal is about $535 billion in 2024\n\nProjected to be $608 billion in 2028\n\n50% transfers to individuals or governments\n\nTransfers to individuals: Old age security, employment insurance, Canada pension plan, etc.\nTransfers to governments: grants for health, social services, equalization, etc.\n\n41% direct expenditures\n\nNational defence\nRCMP\nParks\nBorder services\netc."
  },
  {
    "objectID": "slides/intro/index.html#visualization",
    "href": "slides/intro/index.html#visualization",
    "title": "EC313 - Taxation",
    "section": "Visualization",
    "text": "Visualization\n\nFigure: Federal Government Revenues and Spending"
  },
  {
    "objectID": "slides/intro/index.html#federal-revenues-1",
    "href": "slides/intro/index.html#federal-revenues-1",
    "title": "EC313 - Taxation",
    "section": "Federal Revenues",
    "text": "Federal Revenues"
  },
  {
    "objectID": "slides/intro/index.html#provincial-revenues",
    "href": "slides/intro/index.html#provincial-revenues",
    "title": "EC313 - Taxation",
    "section": "Provincial Revenues",
    "text": "Provincial Revenues\n\nTotal revenue from 2019 is about $450 billion\n\nSum across all provinces\n\n57% comes from taxes\n\nPersonal income tax: 25%\nSales tax: 15%\nCorporate income tax: 8%\nOther taxes (payroll, property, fuel, tobacco): 9%\n\n20% comes from federal transfers\n23% comes from other sources\n\nSales of goods/services\nFines and fees\nCrown corporations"
  },
  {
    "objectID": "slides/intro/index.html#provincial-expenditures",
    "href": "slides/intro/index.html#provincial-expenditures",
    "title": "EC313 - Taxation",
    "section": "Provincial Expenditures",
    "text": "Provincial Expenditures\n\nTotal spending from 2019 is about $473 billion\n92% for program expenditures\n\nHealth care: 36%\nOther: 20%\nSocial services: 15%\nEducation: 13%\nPost-secondary: 7%\n\nRemaining 8% is for interest on debt"
  },
  {
    "objectID": "slides/intro/index.html#municipal-territorial-indigenous-governments-1",
    "href": "slides/intro/index.html#municipal-territorial-indigenous-governments-1",
    "title": "EC313 - Taxation",
    "section": "Municipal, Territorial, Indigenous Governments",
    "text": "Municipal, Territorial, Indigenous Governments\n\nMunicipal governments\n\nRely heavily on property taxes, transfers from provincial governments\nSpend mainly on local services (e.g. police, fire, roads, parks)\n\nTerritorial governments\n\nPowers delegated by federal government\nRely heavily on transfers from federal government\nSpend on similar things to provincial governments\n\nIndigenous governments\n\nMany governed by the Indian Act\nIncreasingly self-governing\nCan raise some independent revenue"
  },
  {
    "objectID": "slides/intro/index.html#introduction-2",
    "href": "slides/intro/index.html#introduction-2",
    "title": "EC313 - Taxation",
    "section": "Introduction",
    "text": "Introduction\n\nFederal government collects half of all government revenue\n\nSpends only one third\n\nProvinces and municipalities collect other half government revenue\n\nSpend two thirds\n\nImbalance is addressed through fiscal transfers\n\nFederal government transfers money to provinces and municipalities\nProvinces also transfer money to municipalities\n\nTransfers can be conditional or unconditional\n\nConditional: must be spent on specific programs\nUnconditional: can be spent on anything"
  },
  {
    "objectID": "slides/intro/index.html#transfers-and-constitutional-responsibilities",
    "href": "slides/intro/index.html#transfers-and-constitutional-responsibilities",
    "title": "EC313 - Taxation",
    "section": "Transfers and Constitutional Responsibilities",
    "text": "Transfers and Constitutional Responsibilities\n\nConstitution Act outlines responsibilities of federal and provincial governments\nConditional federal transfers do not violate constitution\n\nFederal government not providing services directly\nProvinces can choose to participate\nNevertheless controversial\n\nNoteworthy unconditional grant is equalization\n\nProvides funds to provinces that have below average ability to raise revenue\nFormula has been a matter of debate for years"
  },
  {
    "objectID": "slides/intro/index.html#summary-1",
    "href": "slides/intro/index.html#summary-1",
    "title": "EC313 - Taxation",
    "section": "Summary",
    "text": "Summary\n\nPublic economics is the study of the role of government in the economy\nGovernment intervenes to correct market failures and redistribute resources\nGovernments are structured in Canada according to the Constitution Act\nFederal government has broad taxing and spending powers\nProvincial governments have more limited taxing powers\nGovernment size can be measured in several ways, most commonly by expenditures\nSpending has increased significantly over time, but is more stable as share of GDP\nSources of spending and revenues differ by level of government\nThere are significant transfers between governments"
  },
  {
    "objectID": "slides/intro/index.html#references-1",
    "href": "slides/intro/index.html#references-1",
    "title": "EC313 - Taxation",
    "section": "References",
    "text": "References\n\nRosen, Harvey S., and Lindsay M. Tedds, and Trevor Tombe, and Jean-Francois Wen, and Tracy Snoddon. Public Finance in Canada. 6th Canadian edition. McGraw-Hill Ryerson, 2023.\nGruber, Jonathan. Public Finance and Public Policy. 7th edition. Worth Publishers, 2022.\nFinances of the Nation. https://financesofthenation.ca/"
  },
  {
    "objectID": "syllabus.html#course-structure",
    "href": "syllabus.html#course-structure",
    "title": "EC313 Syllabus",
    "section": "Course Structure",
    "text": "Course Structure\n\nLectures\nThe scheduling details of the course are as follows\n\n\n\nSection\nTime\nLocation\n\n\n\n\nA\nTR 4:00-5:20pm\nLH2066\n\n\n\n\n\nOffice Hours\nI strongly encourage you to come to office hours if you need clarification about anything in the course.  Students are often nervous or intimidated at the idea of one-one-one discussions with their instructor.  Don’t be.  It’s a casual discussion where I will answer whatever questions you have without any judgement.\nOffice hours are remote only, unless you really wish to meet in person. Please sign up for a time here. Timeslots are 15-mins each, and you can book up to two for each office hours session depending on how much you need to discuss. When you book, the system will automatically enter a time into my calendar, and it will stay there unless you cancel. It also produces reminder emails to make sure neither of us forgets."
  },
  {
    "objectID": "slides/incidence/index.html#goals-of-this-section-1",
    "href": "slides/incidence/index.html#goals-of-this-section-1",
    "title": "EC313 - Taxation",
    "section": "Goals of This Section",
    "text": "Goals of This Section\n\nOutline different types of taxes\nDiscuss different between statutory and economic incidence of a tax\nShow how tax incidence depends on elasticities of supply and demand\nExpand on tax incidence in various markets"
  },
  {
    "objectID": "slides/incidence/index.html#introduction",
    "href": "slides/incidence/index.html#introduction",
    "title": "EC313 - Taxation",
    "section": "Introduction",
    "text": "Introduction\n\nThere are many different types of taxes\nTaxes can have different goals\n\nRaise revenue for government spending\nChange behaviour of individuals or firms\nRedistribute resources\n\nThey can also have different bases, structures, and rates\n\nBase: what is being taxed (e.g. income, consumption, property)\nStructure: how the tax is applied (e.g. progressive, regressive, flat)\nRate: how much is being taxed (e.g. percentage, fixed amount)\n\nBelow we cover some of the most common types of taxes"
  },
  {
    "objectID": "slides/incidence/index.html#taxes-on-income",
    "href": "slides/incidence/index.html#taxes-on-income",
    "title": "EC313 - Taxation",
    "section": "Taxes on Income",
    "text": "Taxes on Income\n\nIncome Tax: tax on income earned during the year\nCan be levied on individuals or corporations\nFor individuals, includes but not limited to\n\nLabour market earnings\nCapital gains\nInvestment income (e.g. from dividends, interest, property)\nPensions and retirement income (e.g. RRSPs)\nSome government benefits (e.g. employment insurance)\nOther taxable benefits (e.g. premiums paid by employer for group life insurance)"
  },
  {
    "objectID": "slides/incidence/index.html#taxes-on-income-1",
    "href": "slides/incidence/index.html#taxes-on-income-1",
    "title": "EC313 - Taxation",
    "section": "Taxes on Income",
    "text": "Taxes on Income\n\nFor corporations, includes but not limited to\n\nActive business income from sales or goods and services\nInvestment income\nCapital gains\nSome government grants\nDepends on the size of your business\n\nSmall business pay a lower rate"
  },
  {
    "objectID": "slides/incidence/index.html#payroll-taxes",
    "href": "slides/incidence/index.html#payroll-taxes",
    "title": "EC313 - Taxation",
    "section": "Payroll Taxes",
    "text": "Payroll Taxes\n\nPayroll Taxes: taxes levied on employment income\n\nPaid by both employers and employees\n\nUsed to finance social insurance and public pension programs\n\nExamples: Employment Insurance (EI), Canada Pension Plan (CPP), worker compensation\n\nPayroll taxes vary by province\n\nSome charge a health tax (e.g. BC Employer Health Tax)\nManitoba charges a levy for health and postsecondary education\n\nThese are different from the general income tax"
  },
  {
    "objectID": "slides/incidence/index.html#consumption-taxes",
    "href": "slides/incidence/index.html#consumption-taxes",
    "title": "EC313 - Taxation",
    "section": "Consumption Taxes",
    "text": "Consumption Taxes\n\nConsumption Tax: a tax paid on consumption of goods and services\nTaxes generally charged by a seller at point of sale\n\nThey remit these funds to the government\n\nExamples:\n\nSales tax (e.g. GST, HST, PST)\nExcise taxes (e.g. gasoline, alcohol, tobacco)\nTariffs (tax on imports)"
  },
  {
    "objectID": "slides/incidence/index.html#wealth-taxes",
    "href": "slides/incidence/index.html#wealth-taxes",
    "title": "EC313 - Taxation",
    "section": "Wealth Taxes",
    "text": "Wealth Taxes\n\nWealth Taxes: taxes on the value of an asset\nTypical wealth taxes include\n\nProperty tax (tax on value of land/buildings)\nEstate tax (tax on value of estate at death)\nGeneral wealth tax (tax on total value of assets owned)\n\nEstate taxes and general wealth taxes are not used in Canada\nProperty taxes are a major source of revenue for municipal governments"
  },
  {
    "objectID": "slides/incidence/index.html#introduction-1",
    "href": "slides/incidence/index.html#introduction-1",
    "title": "EC313 - Taxation",
    "section": "Introduction",
    "text": "Introduction\n\nThe question of who “pays” a tax is more complicated than it seems\nExample: in Canada, there is a federal $0.10/litre tax on gasoline\n\nGasoline stations include this in their price\nThey remit the tax to the government\nDoes the seller or the consumer pay?\n\nThis section will clarify who pays a tax\nSeparate between statutory and economic incidence of a tax\nMy view: this is the most important concept we teach in this program"
  },
  {
    "objectID": "slides/incidence/index.html#statutory-vs-economic-incidence-of-a-tax-1",
    "href": "slides/incidence/index.html#statutory-vs-economic-incidence-of-a-tax-1",
    "title": "EC313 - Taxation",
    "section": "Statutory vs Economic Incidence of a Tax",
    "text": "Statutory vs Economic Incidence of a Tax\n\nStatutory Incidence: who is legally responsible for paying the tax to the government\n\nIn the gasoline tax example, the statutory incidence is on the gasoline station\n\nThey send a cheque to the government\n\n\nEconomic Incidence: the change in real income brought about by the tax\n\nIn the gasoline tax example, the economic incidence can be shared between the gasoline station and the consumer\n\nThe gasoline station may less revenue per litre sold\nThe consumer may pay a higher price per litre purchased"
  },
  {
    "objectID": "slides/incidence/index.html#statutory-vs-economic-incidence-of-a-tax-2",
    "href": "slides/incidence/index.html#statutory-vs-economic-incidence-of-a-tax-2",
    "title": "EC313 - Taxation",
    "section": "Statutory vs Economic Incidence of a Tax",
    "text": "Statutory vs Economic Incidence of a Tax\n\nExample: $0.10/litre tax on gasoline\n\nBefore tax is imposed, suppose price is $1.00/litre\n\nConsumers pay $1.00/litre, gas station receives $1.00/litre\n\nThen government levies $0.10/litre tax on gasoline station\n\nSuppose gasoline station raises price to $1.10/litre\nConsumer pays $1.10/litre\nGas station keeps $1.00/litre, remits $0.10/litre to government\n\nIn this case, the consumer bears the entire economic incidence of the tax\n\nGasoline station receives same revenue per litre as before tax\nConsumer pays $0.10/litre more than before tax"
  },
  {
    "objectID": "slides/incidence/index.html#statutory-vs-economic-incidence-of-a-tax-3",
    "href": "slides/incidence/index.html#statutory-vs-economic-incidence-of-a-tax-3",
    "title": "EC313 - Taxation",
    "section": "Statutory vs Economic Incidence of a Tax",
    "text": "Statutory vs Economic Incidence of a Tax\n\nExample 2: $0.10/litre tax on gasoline\n\nSame $0.10/litre tax on gas station\n\nSuppose gas station raises price to $1.05/litre\nConsumer pays $1.05/litre\nGas station keeps $0.95/litre, remits $0.10/litre to government\n\nIn this case, the consumer and gas station share the economic incidence of the tax\n\nGas station receives $0.05/litre less than before tax\nConsumer pays $0.05/litre more than before tax"
  },
  {
    "objectID": "slides/incidence/index.html#statutory-vs-economic-incidence-of-a-tax-4",
    "href": "slides/incidence/index.html#statutory-vs-economic-incidence-of-a-tax-4",
    "title": "EC313 - Taxation",
    "section": "Statutory vs Economic Incidence of a Tax",
    "text": "Statutory vs Economic Incidence of a Tax\n\nKey lesson is that statutory incidence does not determine economic incidence\n\nIn example, statutory incidence is always on the gas station\nEconomic incidence depends on how much of the tax is passed on to consumers in the form of higher prices\nGas station could pass on all, some, or none of the tax to consumers\n\nStatutory incidence says nothing about economic incidence\nTo determine economic incidence, we need to look at underlying economic forces"
  },
  {
    "objectID": "slides/incidence/index.html#unit-tax-on-commodities",
    "href": "slides/incidence/index.html#unit-tax-on-commodities",
    "title": "EC313 - Taxation",
    "section": "Unit Tax on Commodities",
    "text": "Unit Tax on Commodities\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\nTake gasoline tax example one more time\nOn right is demand and supply of litres of gasoline\nWithout tax, price and quantity are determined where demand and supply are equal\n\nPrice is \\(P_{0}\\)\nQuantity is \\(Q_{0}\\)"
  },
  {
    "objectID": "slides/incidence/index.html#unit-tax-on-commodities-1",
    "href": "slides/incidence/index.html#unit-tax-on-commodities-1",
    "title": "EC313 - Taxation",
    "section": "Unit Tax on Commodities",
    "text": "Unit Tax on Commodities\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\nNow government levies a per unit tax \\(t\\) (e.g. $0.10/litre) on gasoline\nTax is levied on sellers (statutory incidence)\nThis shifts the supply curve up by the amount of the tax\n\nNew supply curve is \\(S'\\)\nAt each quantity, sellers want to charge \\(t\\) more to cover the tax\n\nNew equilibrium is where \\(S'\\) intersects \\(D\\)"
  },
  {
    "objectID": "slides/incidence/index.html#references-1",
    "href": "slides/incidence/index.html#references-1",
    "title": "EC313 - Taxation",
    "section": "References",
    "text": "References\n\nRosen, Harvey S., and Lindsay M. Tedds, and Trevor Tombe, and Jean-Francois Wen, and Tracy Snoddon. Public Finance in Canada. 6th Canadian edition. McGraw-Hill Ryerson, 2023.\nGruber, Jonathan. Public Finance and Public Policy. 7th edition. Worth Publishers, 2022.\nFinances of the Nation. https://financesofthenation.ca/"
  },
  {
    "objectID": "slides/incidence/index.html#unit-tax-on-commodities-2",
    "href": "slides/incidence/index.html#unit-tax-on-commodities-2",
    "title": "EC313 - Taxation",
    "section": "Unit Tax on Commodities",
    "text": "Unit Tax on Commodities\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\nThe tax introduces a tax wedge\n\nDifference between what consumers pay and what producers receive from a transaction\n\nConsumers pay the equilibrium price \\(P_{g}'\\)\n\nPrice includes the tax\n\nProducers receive \\(P_{n}' = P_{g}' - t\\)\n\nThey remit \\(t\\) for every unit sold\n\nQuantity falls to \\(Q'_{1}\\)"
  },
  {
    "objectID": "slides/incidence/index.html#unit-tax-on-commodities-3",
    "href": "slides/incidence/index.html#unit-tax-on-commodities-3",
    "title": "EC313 - Taxation",
    "section": "Unit Tax on Commodities",
    "text": "Unit Tax on Commodities\n\nIn example above, economic incidence is shared equally between consumers and producers\n\nConsumers pay \\(P_{g}' - P_{0}\\) more than before tax\nProducers receive \\(P_{0} - P_{n}'\\) less than before tax\nThese amounts are equal\n\nEqual economic incidence is specific to this example because supply and demand have the same slope\nIn general, economic incidence depends on the elasticities of supply and demand\n\nA more elastic demand curve means consumers bear less of the economic incidence\n\nHigher elasticity means consumers can switch to other goods when price changes\n\nA more elastic supply curve means producers bear less of the economic incidence\n\nA firm with higher elasticity can alter production easily when prices change"
  },
  {
    "objectID": "slides/incidence/index.html#unit-tax-on-commodities-4",
    "href": "slides/incidence/index.html#unit-tax-on-commodities-4",
    "title": "EC313 - Taxation",
    "section": "Unit Tax on Commodities",
    "text": "Unit Tax on Commodities\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\nGraph to the right shows a more inelastic demand curve\nAfter tax consumers pay \\(P_{g}'\\)\nProducers receive \\(P_{n}' = P_{g}' - t\\)\nBut \\(P_{g}' - P_{0}\\) is now larger than \\(P_{0} - P_{n}'\\)\n\nInelastic demand means consumers less able to substitute\nThey absorb more of the economic incidence"
  },
  {
    "objectID": "slides/incidence/index.html#unit-tax-on-commodities-5",
    "href": "slides/incidence/index.html#unit-tax-on-commodities-5",
    "title": "EC313 - Taxation",
    "section": "Unit Tax on Commodities",
    "text": "Unit Tax on Commodities\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\nIn extreme with perfectly inelastic demand, consumers bear entire economic incidence\n\nPerfect inelastic demand means complete inability to substitute\n\nAfter tax consumers pay \\(P_{g}' = P_{0} + t\\)\nProducers receive \\(P_{n}' = P_{g}' - t = P_{0}\\)\nNo change in quantity\n\nSince consumers demand \\(Q_{0} = Q'_{1}\\) at any price"
  },
  {
    "objectID": "slides/incidence/index.html#unit-tax-on-commodities-6",
    "href": "slides/incidence/index.html#unit-tax-on-commodities-6",
    "title": "EC313 - Taxation",
    "section": "Unit Tax on Commodities",
    "text": "Unit Tax on Commodities\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\nNow imagine a more inelasrtic supply curve\n\nFirms less able to adjust quantities when prices change\n\nAfter tax consumers pay \\(P_{g}'\\)\nProducers receive \\(P_{n}' = P_{g}' - t\\)\n\\(P_{0} - P_{n}'\\) is larger than \\(P_{g}' - P_{0}\\)\n\nFirms absorb more of the economic incidence\nThey are less able to adjust production to avoid the tax"
  },
  {
    "objectID": "slides/incidence/index.html#unit-tax-on-commodities---graphical",
    "href": "slides/incidence/index.html#unit-tax-on-commodities---graphical",
    "title": "EC313 - Taxation",
    "section": "Unit Tax on Commodities - Graphical",
    "text": "Unit Tax on Commodities - Graphical\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\nTake gasoline tax example one more time\nOn right is demand and supply of litres of gasoline\nWithout tax, price and quantity are determined where demand and supply are equal\n\nPrice is \\(P_{0}\\)\nQuantity is \\(Q_{0}\\)"
  },
  {
    "objectID": "slides/incidence/index.html#unit-tax-on-commodities---graphical-1",
    "href": "slides/incidence/index.html#unit-tax-on-commodities---graphical-1",
    "title": "EC313 - Taxation",
    "section": "Unit Tax on Commodities - Graphical",
    "text": "Unit Tax on Commodities - Graphical\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\nNow government levies a per unit tax \\(t\\) (e.g. $0.10/litre) on gasoline\nTax is levied on sellers (statutory incidence)\nThis shifts the supply curve up by the amount of the tax\n\nNew supply curve is \\(S'\\)\nAt each quantity, sellers want to charge \\(t\\) more to cover the tax\n\nNew equilibrium is where \\(S'\\) intersects \\(D\\)"
  },
  {
    "objectID": "slides/incidence/index.html#unit-tax-on-commodities---graphical-2",
    "href": "slides/incidence/index.html#unit-tax-on-commodities---graphical-2",
    "title": "EC313 - Taxation",
    "section": "Unit Tax on Commodities - Graphical",
    "text": "Unit Tax on Commodities - Graphical\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\nThe tax introduces a tax wedge\n\nDifference between what consumers pay and what producers receive from a transaction\n\nConsumers pay the equilibrium price \\(P_{g}'\\)\n\nPrice includes the tax\n\nProducers receive \\(P_{n}' = P_{g}' - t\\)\n\nThey remit \\(t\\) for every unit sold\n\nQuantity falls to \\(Q'_{1}\\)"
  },
  {
    "objectID": "slides/incidence/index.html#unit-tax-on-commodities---graphical-3",
    "href": "slides/incidence/index.html#unit-tax-on-commodities---graphical-3",
    "title": "EC313 - Taxation",
    "section": "Unit Tax on Commodities - Graphical",
    "text": "Unit Tax on Commodities - Graphical\n\nIn example above, economic incidence is shared equally between consumers and producers\n\nConsumers pay \\(P_{g}' - P_{0}\\) more than before tax\nProducers receive \\(P_{0} - P_{n}'\\) less than before tax\nThese amounts are equal\n\nEqual economic incidence is specific to this example because supply and demand have the same slope\nIn general, economic incidence depends on the elasticities of supply and demand\n\nA more elastic demand curve means consumers bear less of the economic incidence\n\nHigher elasticity means consumers can switch to other goods when price changes\n\nA more elastic supply curve means producers bear less of the economic incidence\n\nA firm with higher elasticity can alter production easily when prices change"
  },
  {
    "objectID": "slides/incidence/index.html#unit-tax-on-commodities---graphical-4",
    "href": "slides/incidence/index.html#unit-tax-on-commodities---graphical-4",
    "title": "EC313 - Taxation",
    "section": "Unit Tax on Commodities - Graphical",
    "text": "Unit Tax on Commodities - Graphical\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\nGraph to the right shows a more inelastic demand curve\nAfter tax consumers pay \\(P_{g}'\\)\nProducers receive \\(P_{n}' = P_{g}' - t\\)\nBut \\(P_{g}' - P_{0}\\) is now larger than \\(P_{0} - P_{n}'\\)\n\nInelastic demand means consumers less able to substitute\nThey absorb more of the economic incidence"
  },
  {
    "objectID": "slides/incidence/index.html#unit-tax-on-commodities---graphical-5",
    "href": "slides/incidence/index.html#unit-tax-on-commodities---graphical-5",
    "title": "EC313 - Taxation",
    "section": "Unit Tax on Commodities - Graphical",
    "text": "Unit Tax on Commodities - Graphical\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\nIn extreme with perfectly inelastic demand, consumers bear entire economic incidence\n\nPerfect inelastic demand means complete inability to substitute\n\nAfter tax consumers pay \\(P_{g}' = P_{0} + t\\)\nProducers receive \\(P_{n}' = P_{g}' - t = P_{0}\\)\nNo change in quantity\n\nSince consumers demand \\(Q_{0} = Q'_{1}\\) at any price"
  },
  {
    "objectID": "slides/incidence/index.html#unit-tax-on-commodities---graphical-6",
    "href": "slides/incidence/index.html#unit-tax-on-commodities---graphical-6",
    "title": "EC313 - Taxation",
    "section": "Unit Tax on Commodities - Graphical",
    "text": "Unit Tax on Commodities - Graphical\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\nNow imagine a more inelasrtic supply curve\n\nFirms less able to adjust quantities when prices change\n\nAfter tax consumers pay \\(P_{g}'\\)\nProducers receive \\(P_{n}' = P_{g}' - t\\)\n\\(P_{0} - P_{n}'\\) is larger than \\(P_{g}' - P_{0}\\)\n\nFirms absorb more of the economic incidence\nThey are less able to adjust production to avoid the tax"
  },
  {
    "objectID": "slides/incidence/index.html#unit-tax-on-commodities---math",
    "href": "slides/incidence/index.html#unit-tax-on-commodities---math",
    "title": "EC313 - Taxation",
    "section": "Unit Tax on Commodities - Math",
    "text": "Unit Tax on Commodities - Math\n\nWe can show the same result mathematically\nUse linear inverse demand and supply curves with clean numbers\n\n\\[\\text{Demand: } P_{d}=14-Q_{d},\\quad \\text{Supply: } P_{s}=2+Q_{s}\\]\n\nEquilibrium without tax is where \\(P_{d}=P_{s} = P_{0}\\), \\(Q_{d}=Q_{s}= Q_{0}\\)\n\n\\[ 14-Q_{0}=2+Q_{0} \\] \\[ 12 = 2Q_{0} \\Rightarrow Q_{0}=6 \\] - Sub \\(Q_{0}\\) into either equation to get \\(P_{0}\\)\n\\[ P_{0} = 14 - 6 = 8 \\]"
  },
  {
    "objectID": "slides/incidence/index.html#references",
    "href": "slides/incidence/index.html#references",
    "title": "EC313 - Taxation",
    "section": "References",
    "text": "References\n\nRosen, Harvey S., and Lindsay M. Tedds, and Trevor Tombe, and Jean-Francois Wen, and Tracy Snoddon. Public Finance in Canada. 6th Canadian edition. McGraw-Hill Ryerson, 2023.\nGruber, Jonathan. Public Finance and Public Policy. 7th edition. Worth Publishers, 2022.\nFinances of the Nation. https://financesofthenation.ca/"
  },
  {
    "objectID": "slides/incidence/index.html#unit-tax-on-commodities---math-1",
    "href": "slides/incidence/index.html#unit-tax-on-commodities---math-1",
    "title": "EC313 - Taxation",
    "section": "Unit Tax on Commodities - Math",
    "text": "Unit Tax on Commodities - Math\n\nNow introduce a per unit tax \\(t=4\\) on sellers\nIn equilibrium, \\(P_{d} = P_{s} + t\\) and \\(Q_{d} = Q_{s} = Q_{1}\\)\n\nThere is a wedge between what consumers pay and what producers receive\n\nSubstituting in the equations for demand and supply\n\n\\[ 14 - Q_{1} = 2 + Q_{1} + 4 \\] \\[ 14 - Q_{1} = 6 + Q_{1} \\Rightarrow Q_{1} = 4 \\] - Sub \\(Q_{1}\\) into either equation to get \\(P_{d}\\) or \\(P_{s}\\)\n\\[ P_{d} = 14 - 4 = 10 \\] \\[ P_{s} = 2 + 4 = 6 \\]"
  },
  {
    "objectID": "slides/incidence/index.html#unit-tax-on-commodities---math-2",
    "href": "slides/incidence/index.html#unit-tax-on-commodities---math-2",
    "title": "EC313 - Taxation",
    "section": "Unit Tax on Commodities - Math",
    "text": "Unit Tax on Commodities - Math\n\nKey things to take away when the tax is introduced\n\nQuantity falls from \\(Q_{0}=6\\) to \\(Q_{1}=4\\)\nConsumers pay \\(P_{d}=10\\), which is \\(10-8=2\\) more than before tax\nProducers receive \\(P_{s}=6\\), which is \\(8-6=2\\) less than before tax\nEconomic incidence is shared equally between consumers and producers\n\nExample is specific to when demand and supply have the same slope\nIn general, economic incidence with linear demand and supply and a unit tax depends on elasticities of supply and demand\n\n\\[ \\Delta P_{c} = P_{c} - P_{0} = \\frac{\\varepsilon_s}{\\varepsilon_s + |\\varepsilon_d|}t, \\quad \\Delta P_{s}= P_{0} - P_{s} = \\frac{|\\varepsilon_d|}{\\varepsilon_s + |\\varepsilon_d|}t\\]\n\n\\(\\varepsilon_s = \\frac{dQ_s}{dP_s}\\frac{P}{Q}\\) is elasticity of supply and \\(\\varepsilon_d = \\frac{dQ_d}{dP_c}\\frac{P}{Q}\\) is elasticity of demand"
  },
  {
    "objectID": "slides/incidence/index.html",
    "href": "slides/incidence/index.html",
    "title": "\nTax Incidence\n",
    "section": "",
    "text": "Tax Incidence"
  },
  {
    "objectID": "slides/incidence/index.html#unit-tax-on-sellers---graphical",
    "href": "slides/incidence/index.html#unit-tax-on-sellers---graphical",
    "title": "EC313 - Taxation",
    "section": "Unit Tax on Sellers - Graphical",
    "text": "Unit Tax on Sellers - Graphical\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\nTake gasoline tax example one more time\nOn right is demand and supply of litres of gasoline\nWithout tax, price and quantity are determined where demand and supply are equal\n\nPrice is \\(P_{0}\\)\nQuantity is \\(Q_{0}\\)"
  },
  {
    "objectID": "slides/incidence/index.html#unit-tax-on-sellers---graphical-1",
    "href": "slides/incidence/index.html#unit-tax-on-sellers---graphical-1",
    "title": "EC313 - Taxation",
    "section": "Unit Tax on Sellers - Graphical",
    "text": "Unit Tax on Sellers - Graphical\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\nNow government levies a per unit tax \\(t\\) (e.g. $0.10/litre) on gasoline\nTax is levied on sellers (statutory incidence)\nThis shifts the supply curve up by the amount of the tax\n\nNew supply curve is \\(S'\\)\nAt each quantity, sellers want to charge \\(t\\) more to cover the tax\n\nNew equilibrium is where \\(S'\\) intersects \\(D\\)\n\nDetermines price paid by consumers"
  },
  {
    "objectID": "slides/incidence/index.html#unit-tax-on-sellers---graphical-2",
    "href": "slides/incidence/index.html#unit-tax-on-sellers---graphical-2",
    "title": "EC313 - Taxation",
    "section": "Unit Tax on Sellers - Graphical",
    "text": "Unit Tax on Sellers - Graphical\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\nThe tax introduces a tax wedge\n\nDifference between what consumers pay and what producers receive from a transaction\n\nConsumers pay the equilibrium price \\(P_{c}'\\)\n\nPrice includes the tax\n\nProducers receive \\(P_{s}' = P_{c}' - t\\)\n\nThey remit \\(t\\) for every unit sold\n\nQuantity falls to \\(Q'_{1}\\)"
  },
  {
    "objectID": "slides/incidence/index.html#unit-tax-on-sellers---graphical-3",
    "href": "slides/incidence/index.html#unit-tax-on-sellers---graphical-3",
    "title": "EC313 - Taxation",
    "section": "Unit Tax on Sellers - Graphical",
    "text": "Unit Tax on Sellers - Graphical\n\nIn example above, economic incidence is shared equally between consumers and producers\n\nConsumers pay \\(P_{c}' - P_{0}\\) more than before tax\nProducers receive \\(P_{0} - P_{s}'\\) less than before tax\nThese amounts are equal\n\nEqual economic incidence is specific to this example because supply and demand have the same slope\nIn general, economic incidence depends on the elasticities of supply and demand\n\nA more elastic demand curve means consumers bear less of the economic incidence\n\nHigher elasticity means consumers can switch to other goods when price changes\n\nA more elastic supply curve means producers bear less of the economic incidence\n\nA firm with higher elasticity can alter production easily when prices change"
  },
  {
    "objectID": "slides/incidence/index.html#unit-tax-on-sellers---graphical-4",
    "href": "slides/incidence/index.html#unit-tax-on-sellers---graphical-4",
    "title": "EC313 - Taxation",
    "section": "Unit Tax on Sellers - Graphical",
    "text": "Unit Tax on Sellers - Graphical\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\nGraph to the right shows a more inelastic demand curve\nAfter tax consumers pay \\(P_{c}'\\)\nProducers receive \\(P_{s}' = P_{c}' - t\\)\nBut \\(P_{c}' - P_{0}\\) is now larger than \\(P_{0} - P_{s}'\\)\n\nInelastic demand means consumers less able to substitute\nThey absorb more of the economic incidence"
  },
  {
    "objectID": "slides/incidence/index.html#unit-tax-on-sellers---graphical-5",
    "href": "slides/incidence/index.html#unit-tax-on-sellers---graphical-5",
    "title": "EC313 - Taxation",
    "section": "Unit Tax on Sellers - Graphical",
    "text": "Unit Tax on Sellers - Graphical\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\nIn extreme with perfectly inelastic demand, consumers bear entire economic incidence\n\nPerfect inelastic demand means complete inability to substitute\n\nAfter tax consumers pay \\(P_{c}' = P_{0} + t\\)\nProducers receive \\(P_{s}' = P_{c}' - t = P_{0}\\)\nNo change in quantity\n\nSince consumers demand \\(Q_{0} = Q'_{1}\\) at any price"
  },
  {
    "objectID": "slides/incidence/index.html#unit-tax-on-sellers---graphical-6",
    "href": "slides/incidence/index.html#unit-tax-on-sellers---graphical-6",
    "title": "EC313 - Taxation",
    "section": "Unit Tax on Sellers - Graphical",
    "text": "Unit Tax on Sellers - Graphical\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\nNow imagine a more inelastic supply curve\n\nFirms less able to adjust quantities when prices change\n\nAfter tax consumers pay \\(P_{c}'\\)\nProducers receive \\(P_{s}' = P_{c}' - t\\)\n\\(P_{0} - P_{s}'\\) is larger than \\(P_{c}' - P_{0}\\)\n\nFirms absorb more of the economic incidence\nThey are less able to adjust production to avoid the tax"
  },
  {
    "objectID": "slides/incidence/index.html#unit-tax-on-sellers---math",
    "href": "slides/incidence/index.html#unit-tax-on-sellers---math",
    "title": "EC313 - Taxation",
    "section": "Unit Tax on Sellers - Math",
    "text": "Unit Tax on Sellers - Math\n\nWe can show the same result mathematically\nUse linear inverse demand and supply curves with clean numbers\n\n\\[\\text{Demand: } P_{c}=14-Q_{c},\\quad \\text{Supply: } P_{s}=2+Q_{s}\\]\n\nEquilibrium without tax is where \\(P_{s}=P_{c} = P_{0}\\), \\(Q_{c}=Q_{s}= Q_{0}\\)\n\n\\[ 14-Q_{0}=2+Q_{0} \\] \\[ 12 = 2Q_{0} \\Rightarrow Q_{0}=6 \\] - Sub \\(Q_{0}\\) into either equation to get \\(P_{0}\\)\n\\[ P_{0} = 14 - 6 = 8 \\]"
  },
  {
    "objectID": "slides/incidence/index.html#unit-tax-on-sellers---math-1",
    "href": "slides/incidence/index.html#unit-tax-on-sellers---math-1",
    "title": "EC313 - Taxation",
    "section": "Unit Tax on Sellers - Math",
    "text": "Unit Tax on Sellers - Math\n\nNow introduce a per unit tax \\(t=4\\) on sellers\nIn equilibrium, \\(P_{s} + t = P_{c}\\) and \\(Q_{c} = Q_{s} = Q_{1}\\)\n\nThere is a wedge between what consumers pay and what producers receive\n\nSubstituting in the equations for demand and supply\n\n\\[ 14 - Q_{1}  = 2 + Q_{1} + 4\\] \\[ 14 - Q_{1} = 6 + Q_{1} \\Rightarrow Q_{1} = 4 \\]\n\nSub \\(Q_{1}\\) into either equation to get \\(P_{c}\\) or \\(P_{s}\\)\n\n\\[ P_{c} = 14 - 4 = 10 \\] \\[ P_{s} = 2 + 4 = 6 \\]"
  },
  {
    "objectID": "slides/incidence/index.html#unit-tax-on-sellers---math-2",
    "href": "slides/incidence/index.html#unit-tax-on-sellers---math-2",
    "title": "EC313 - Taxation",
    "section": "Unit Tax on Sellers - Math",
    "text": "Unit Tax on Sellers - Math\n\nKey things to take away when the tax is introduced\n\nQuantity falls from \\(Q_{0}=6\\) to \\(Q_{1}=4\\)\nConsumers pay \\(P_{c}=10\\), which is \\(10-8=2\\) more than before tax\nProducers receive \\(P_{s}=6\\), which is \\(8-6=2\\) less than before tax\nEconomic incidence is shared equally between consumers and producers\n\nExample is specific to when demand and supply have the same slope\nIn general, economic incidence with linear demand and supply and a unit tax depends on elasticities of supply and demand\n\n\\[ \\Delta P_{c} = P_{c} - P_{0} = \\frac{\\varepsilon_s}{\\varepsilon_s + |\\varepsilon_d|}t, \\quad \\Delta P_{s}= P_{0} - P_{s} = \\frac{|\\varepsilon_d|}{\\varepsilon_s + |\\varepsilon_d|}t\\]\n\n\\(\\varepsilon_s = \\frac{dQ_s}{dP_s}\\frac{P}{Q}\\) is elasticity of supply and \\(\\varepsilon_d = \\frac{dQ_d}{dP_c}\\frac{P}{Q}\\) is elasticity of demand"
  },
  {
    "objectID": "slides/incidence/index.html#unit-tax-on-buyers---graphical",
    "href": "slides/incidence/index.html#unit-tax-on-buyers---graphical",
    "title": "EC313 - Taxation",
    "section": "Unit Tax on Buyers - Graphical",
    "text": "Unit Tax on Buyers - Graphical\n\nMore rarely, taxes are levied on buyers of goods and services\nWe can use the same graphical tools to examine this case\nKey lesson is that economic incidence does not depend on whether the tax is levied on buyers or sellers"
  },
  {
    "objectID": "slides/incidence/index.html#unit-tax-on-buyers---graphical-1",
    "href": "slides/incidence/index.html#unit-tax-on-buyers---graphical-1",
    "title": "EC313 - Taxation",
    "section": "Unit Tax on Buyers - Graphical",
    "text": "Unit Tax on Buyers - Graphical\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\nNow government levies a per unit tax \\(t\\) (e.g. $0.10/litre) on gasoline\nAssume gas tax is levied on buyers (statutory incidence)\nThis shifts the demand curve down by the amount of the tax\n\nNew demand curve is \\(D'\\)\nAt each quantity, buyers want to pay \\(t\\) less to cover the tax\n\nNew equilibrium is where \\(S\\) intersects \\(D'\\)\n\nDetermines price received by the seller"
  },
  {
    "objectID": "slides/incidence/index.html#unit-tax-on-buyers---graphical-2",
    "href": "slides/incidence/index.html#unit-tax-on-buyers---graphical-2",
    "title": "EC313 - Taxation",
    "section": "Unit Tax on Buyers - Graphical",
    "text": "Unit Tax on Buyers - Graphical\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\nNotice that \\(P_{s}\\) and \\(P_{c}\\) are the same as when the tax was levied on sellers\n\nProducers receive \\(P_{s}\\)\nConsumers pay \\(P_{c} = P_{s} + t\\)\nQuantity falls to \\(Q_{1}\\)\n\nIn this case, the slopes are equal so the burden is shared\nChanges in elasticities affect economic burden in the same way"
  },
  {
    "objectID": "slides/incidence/index.html#unit-tax-on-buyers---math",
    "href": "slides/incidence/index.html#unit-tax-on-buyers---math",
    "title": "EC313 - Taxation",
    "section": "Unit Tax on Buyers - Math",
    "text": "Unit Tax on Buyers - Math\n\nThe math is exactly the same as when the tax is levied on sellers\n\n\\[\\text{Demand: } P_{c}=14-Q_{c},\\quad \\text{Supply: } P_{s}=2+Q_{s}\\]\n\nTax is \\(t=4\\) on buyers\nIn equilibrium, \\(P_{s} = P_{c} - t\\) and \\(Q_{c} = Q_{s} = Q_{1}\\)\nAlgebra is same as we did above, so we get the same results\n\n\\[ P_{c} = 10 \\] \\[ P_{s} = 6 \\]"
  },
  {
    "objectID": "slides/incidence/index.html#unit-taxes---takeaways",
    "href": "slides/incidence/index.html#unit-taxes---takeaways",
    "title": "EC313 - Taxation",
    "section": "Unit Taxes - Takeaways",
    "text": "Unit Taxes - Takeaways\n\nStatutory incidence does not determine economic incidence\nEconomic incidence depends on elasticities of supply and demand\n\nMore elastic demand means consumers bear less of the economic incidence\nMore elastic supply means producers bear less of the economic incidence\n\nEconomic incidence does not depend on whether the tax is levied on buyers or sellers"
  },
  {
    "objectID": "slides/incidence/index.html#ad-valorem-taxes",
    "href": "slides/incidence/index.html#ad-valorem-taxes",
    "title": "EC313 - Taxation",
    "section": "Ad Valorem Taxes",
    "text": "Ad Valorem Taxes\n\nSo far we have only considered unit taxes\n\nA fixed amount per unit sold (e.g. $0.10/litre)\n\nMore common are ad valorem taxes\n\nA percentage of the price (e.g. 13% HST on most goods and services)\n\nAd valorem taxes create a tax wedge that increases with the price\n\nHigher priced goods have a larger tax wedge\n\nAs before\n\nEconomic incidence depends on elasticities of supply and demand\nEconomic incidence does not depend on whether the tax is levied on buyers or sellers"
  },
  {
    "objectID": "slides/incidence/index.html#ad-valorem-taxes-1",
    "href": "slides/incidence/index.html#ad-valorem-taxes-1",
    "title": "EC313 - Taxation",
    "section": "Ad Valorem Taxes",
    "text": "Ad Valorem Taxes\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\nAnalysis is similar to unit tax except supply curve shifts up and becomes steeper\nIf tax is levied on buyers, demand curve shifts down and becomes flatter\nStill a wedge between what consumers pay and what producers receive\nEconomic burden on sellers decreases with supply elasticity\nEconomic burden on buyers decreases with demand elasticity"
  },
  {
    "objectID": "slides/incidence/index.html#unit-tax-on-a-monopolist",
    "href": "slides/incidence/index.html#unit-tax-on-a-monopolist",
    "title": "EC313 - Taxation",
    "section": "Unit Tax on a Monopolist",
    "text": "Unit Tax on a Monopolist\n\nSo far we have only considered perfectly competitive markets\nWhat happens when there is only one seller in the market?\nA tax increases marginal cost, so the monopolist produces less\nEffects of the tax are potentially different from competitive markets\n\nQuantity will fall\nPrice paid by consumers will rise\nBut, price received by the monopolist may rise or fall\n\nDepends on cost structure and demand elasticity"
  },
  {
    "objectID": "slides/incidence/index.html#unit-tax-on-a-monopolist-1",
    "href": "slides/incidence/index.html#unit-tax-on-a-monopolist-1",
    "title": "EC313 - Taxation",
    "section": "Unit Tax on a Monopolist",
    "text": "Unit Tax on a Monopolist\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\nGraph shows pre tax equilibrium in a monopoly\nATC curve omitted for graph clarity\nExample: market for movie tickets\n\nDominated by a couple of firms\nNot strictly a monopoly but close enough\n\nEquilibrium is where \\(MR = MC\\)\n\nPrice is \\(P_{0}\\)\nQuantity is \\(Q_{0}\\)"
  },
  {
    "objectID": "slides/incidence/index.html#unit-tax-on-a-monopolist-2",
    "href": "slides/incidence/index.html#unit-tax-on-a-monopolist-2",
    "title": "EC313 - Taxation",
    "section": "Unit Tax on a Monopolist",
    "text": "Unit Tax on a Monopolist\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\nGovernment levies a per unit tax \\(t\\) on each ticket sold\nThis shifts the cost curves up by the amount of the tax\n\nNew marginal cost is \\(MC'\\)\n\nEquilibrium is where \\(MR = MC'\\)\n\nPrice paid by consumers is \\(P_{c}\\)\nPrice received by monopolist is \\(P_{s} = P_{c} - t\\)\nQuantity is lower at \\(Q_{1}\\)\n\nConsumers bear more of the tax if\n\nDemand is inelastic\nMarginal cost is relatively flat"
  },
  {
    "objectID": "slides/incidence/index.html#introduction-2",
    "href": "slides/incidence/index.html#introduction-2",
    "title": "EC313 - Taxation",
    "section": "Introduction",
    "text": "Introduction\n\nSo far we have only considered taxes on goods and services\nTaxes can also be levied on factors of production\n\nLabour\nCapital\n\nTaxes affect prices paid for and received by those factors\n\nExample: payroll taxes affect wages paid and received\n\nTaxes also affect quantities of factors employed\nAnalysis is the same as taxes on goods and services\n\nOnly difference is that firms are buyers and households are sellers"
  },
  {
    "objectID": "slides/incidence/index.html#payroll-tax-on-workers",
    "href": "slides/incidence/index.html#payroll-tax-on-workers",
    "title": "EC313 - Taxation",
    "section": "Payroll Tax on Workers",
    "text": "Payroll Tax on Workers\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\nSuppose government levies a payroll tax \\(t\\) on workers\n\nExample: Employment Insurance (EI) premiums paid by employees\n\nThis shifts the supply curve of labour up by the amount of the tax\n\nAt each quantity, workers want to be paid \\(t\\) more to cover the tax\n\nCreates wedge between what workers are paid and what they keep\n\nFirms now pay \\(W_{f}\\)\nWorkers receive \\(W_{w} = W_{f} - t\\)"
  },
  {
    "objectID": "slides/incidence/index.html#payroll-tax-on-workers-1",
    "href": "slides/incidence/index.html#payroll-tax-on-workers-1",
    "title": "EC313 - Taxation",
    "section": "Payroll Tax on Workers",
    "text": "Payroll Tax on Workers\n\nIncidence again depends on supply and demand elasticity\nA more inelastic supply curve means workers bear more of the economic incidence\n\nThey are less able to change work hours when wages change\nMakes them stuck in a job, so they bear more of the tax\n\nA more inelastic demand curve means firms bear more of the economic incidence\n\nThey are less able to substitute between labour and other inputs\nMakes number of workers inflexible, so they bear more of the tax\n\nDoes not matter if tax is levied on workers or firms\n\nIn reality payroll taxes are often levied on both"
  },
  {
    "objectID": "content/incidence.html",
    "href": "content/incidence.html",
    "title": "Tax Incidence",
    "section": "",
    "text": "RTTWS Chapter 14",
    "crumbs": [
      "Content",
      "Course content",
      "Tax Incidence"
    ]
  },
  {
    "objectID": "content/incidence.html#readings",
    "href": "content/incidence.html#readings",
    "title": "Tax Incidence",
    "section": "",
    "text": "RTTWS Chapter 14",
    "crumbs": [
      "Content",
      "Course content",
      "Tax Incidence"
    ]
  },
  {
    "objectID": "content/incidence.html#slides",
    "href": "content/incidence.html#slides",
    "title": "Tax Incidence",
    "section": "Slides",
    "text": "Slides\nThe slides are embedded in this page, and you can scroll through them with the arrow keys. If you prefer you can instead pop them out in a new window",
    "crumbs": [
      "Content",
      "Course content",
      "Tax Incidence"
    ]
  }
]